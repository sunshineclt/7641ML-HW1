{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('../HW1_data/traffic/Casualties0514.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dataset.groupby(\"Casualty_Severity\").count()\n",
    "fatal_dataset = dataset[dataset[\"Casualty_Severity\"]==1]\n",
    "num_fatal = fatal_dataset.shape[0]\n",
    "serious_dataset = dataset[dataset[\"Casualty_Severity\"]==2].sample(n=num_fatal, random_state=35674, axis=0)\n",
    "slight_dataset = dataset[dataset[\"Casualty_Severity\"]==3].sample(n=num_fatal, random_state=25442, axis=0)\n",
    "dataset = pd.concat([fatal_dataset, serious_dataset, slight_dataset],axis=0)\n",
    "del fatal_dataset, serious_dataset, slight_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Casualty_Class</th>\n",
       "      <th>Sex_of_Casualty</th>\n",
       "      <th>Age_of_Casualty</th>\n",
       "      <th>Age_Band_of_Casualty</th>\n",
       "      <th>Casualty_Severity</th>\n",
       "      <th>Pedestrian_Location</th>\n",
       "      <th>Pedestrian_Movement</th>\n",
       "      <th>Car_Passenger</th>\n",
       "      <th>Bus_or_Coach_Passenger</th>\n",
       "      <th>Pedestrian_Road_Maintenance_Worker</th>\n",
       "      <th>Casualty_Type</th>\n",
       "      <th>Casualty_Home_Area_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1351455</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1740504</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998542</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800167</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1115993</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>59</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Casualty_Class  Sex_of_Casualty  Age_of_Casualty  \\\n",
       "1351455               1                1               26   \n",
       "1740504               2                2               32   \n",
       "1998542               3                1                5   \n",
       "800167                1                1               60   \n",
       "1115993               1                1               59   \n",
       "\n",
       "         Age_Band_of_Casualty  Casualty_Severity  Pedestrian_Location  \\\n",
       "1351455                     6                  3                    0   \n",
       "1740504                     6                  3                    0   \n",
       "1998542                     1                  3                    5   \n",
       "800167                      9                  2                    0   \n",
       "1115993                     9                  1                    0   \n",
       "\n",
       "         Pedestrian_Movement  Car_Passenger  Bus_or_Coach_Passenger  \\\n",
       "1351455                    0              0                       0   \n",
       "1740504                    0              1                       0   \n",
       "1998542                    4              0                       0   \n",
       "800167                     0              0                       0   \n",
       "1115993                    0              0                       0   \n",
       "\n",
       "         Pedestrian_Road_Maintenance_Worker  Casualty_Type  \\\n",
       "1351455                                  -1              1   \n",
       "1740504                                   0              9   \n",
       "1998542                                   0              0   \n",
       "800167                                   -1              1   \n",
       "1115993                                  -1              1   \n",
       "\n",
       "         Casualty_Home_Area_Type  \n",
       "1351455                        1  \n",
       "1740504                        1  \n",
       "1998542                        1  \n",
       "800167                         1  \n",
       "1115993                        1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset.drop([\"Accident_Index\", \"Vehicle_Reference\", \"Casualty_Reference\"], axis=1)\n",
    "dataset = dataset.sample(frac=1, axis=0)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(44297, 11)\n",
      "(11075, 11)\n",
      "(13844, 11)\n"
     ]
    }
   ],
   "source": [
    "# Prepare data for Decision Tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "X = dataset.drop([\"Casualty_Severity\"], axis=1)\n",
    "y = dataset[\"Casualty_Severity\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=6357)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=6357)\n",
    "del X, y\n",
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit end! \n",
      "Validation score:  0.43873589164785554\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import pydotplus as pydot\n",
    "from IPython.display import Image\n",
    "from sklearn.externals.six import StringIO\n",
    "from sklearn import tree\n",
    "\n",
    "# Vanilla Decision Tree\n",
    "dt = DecisionTreeClassifier(criterion=\"entropy\", random_state=4321)\n",
    "dt.fit(X_train, y_train)\n",
    "print(\"Fit end! \")\n",
    "dt_val_score = dt.score(X_val, y_val)\n",
    "print(\"Validation score: \", dt_val_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Post-prune Decision Tree \n",
    "# My own implementation based on https://stackoverflow.com/questions/49428469/pruning-decision-trees/49496027#49496027\n",
    "# Pruning based on validation score (if pruning a subtree gains better performance on validate set, then prune it)\n",
    "from sklearn.tree._tree import TREE_LEAF\n",
    "\n",
    "def prune_from_root(inner_tree, index):\n",
    "    global dt_val_score\n",
    "    memo = (inner_tree.children_left[index], inner_tree.children_right[index])\n",
    "    inner_tree.children_left[index] = TREE_LEAF\n",
    "    inner_tree.children_right[index] = TREE_LEAF\n",
    "    new_score = dt.score(X_val, y_val)\n",
    "    if new_score <= dt_val_score:\n",
    "        inner_tree.children_left[index] = memo[0]\n",
    "        inner_tree.children_right[index] = memo[1]\n",
    "    else:\n",
    "        dt_val_score = new_score\n",
    "\n",
    "    # if there are children, visit them as well\n",
    "    if inner_tree.children_left[index] != TREE_LEAF:\n",
    "        prune_from_root(inner_tree, inner_tree.children_left[index])\n",
    "        prune_from_root(inner_tree, inner_tree.children_right[index])\n",
    "\n",
    "def prune_from_leaf(inner_tree, index):\n",
    "    global dt_val_score\n",
    "    # if there are children, firstly visit them\n",
    "    if inner_tree.children_left[index] != TREE_LEAF:\n",
    "        prune_from_leaf(inner_tree, inner_tree.children_left[index])\n",
    "        prune_from_leaf(inner_tree, inner_tree.children_right[index])\n",
    "        memo = (inner_tree.children_left[index], inner_tree.children_right[index])\n",
    "        inner_tree.children_left[index] = TREE_LEAF\n",
    "        inner_tree.children_right[index] = TREE_LEAF\n",
    "        new_score = dt.score(X_val, y_val)\n",
    "        if new_score <= dt_val_score:\n",
    "            inner_tree.children_left[index] = memo[0]\n",
    "            inner_tree.children_right[index] = memo[1]\n",
    "        else:\n",
    "            dt_val_score = new_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no-prune validation score:  0.43873589164785554\n",
      "no-prune test score:  0.4460416064721179\n",
      "post-prune from root validation score:  0.4588713318284424\n",
      "post-prune from root test score:  0.46865067899451024\n"
     ]
    }
   ],
   "source": [
    "# prune from root\n",
    "dt = DecisionTreeClassifier(criterion=\"entropy\", random_state=4321)\n",
    "dt.fit(X_train, y_train)\n",
    "dt_val_score = dt.score(X_val, y_val)\n",
    "print(\"no-prune validation score: \", dt_val_score)\n",
    "print(\"no-prune test score: \", dt.score(X_test, y_test))\n",
    "prune_from_root(dt.tree_, 0)\n",
    "print(\"post-prune from root validation score: \", dt.score(X_val, y_val))\n",
    "print(\"post-prune from root test score: \", dt.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no-prune validation score:  0.43873589164785554\n",
      "no-prune test score:  0.4460416064721179\n",
      "post-prune from leaf validation score:  0.5398645598194131\n",
      "post-prune from leaf test score:  0.46850621207743426\n"
     ]
    }
   ],
   "source": [
    "# prune from leaf\n",
    "# create an identical decision tree to the previous one using the same random_state\n",
    "dt = DecisionTreeClassifier(criterion=\"entropy\", random_state=4321)\n",
    "dt.fit(X_train, y_train)\n",
    "dt_val_score = dt.score(X_val, y_val)\n",
    "print(\"no-prune validation score: \", dt_val_score)\n",
    "print(\"no-prune test score: \", dt.score(X_test, y_test))\n",
    "prune_from_leaf(dt.tree_, 0)\n",
    "print(\"post-prune from leaf validation score: \", dt.score(X_val, y_val))\n",
    "print(\"post-prune from leaf test score: \", dt.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================\n",
      "depth=1, post-prune=from root\n",
      "no-prune validation score:  0.4302483069977427\n",
      "no-prune test score:  0.43433978618896274\n",
      "post-prune from root validation score:  0.4302483069977427\n",
      "post-prune from root test score:  0.43433978618896274\n",
      "===================\n",
      "depth=1, post-prune=from leaf\n",
      "no-prune validation score:  0.4302483069977427\n",
      "no-prune test score:  0.43433978618896274\n",
      "post-prune from leaf validation score:  0.4302483069977427\n",
      "post-prune from leaf test score:  0.43433978618896274\n",
      "===================\n",
      "depth=2, post-prune=from root\n",
      "no-prune validation score:  0.43548532731376977\n",
      "no-prune test score:  0.4328951170182028\n",
      "post-prune from root validation score:  0.43548532731376977\n",
      "post-prune from root test score:  0.4328951170182028\n",
      "===================\n",
      "depth=2, post-prune=from leaf\n",
      "no-prune validation score:  0.43548532731376977\n",
      "no-prune test score:  0.4328951170182028\n",
      "post-prune from leaf validation score:  0.43548532731376977\n",
      "post-prune from leaf test score:  0.4328951170182028\n",
      "===================\n",
      "depth=3, post-prune=from root\n",
      "no-prune validation score:  0.46428893905191876\n",
      "no-prune test score:  0.4749349898873158\n",
      "post-prune from root validation score:  0.46428893905191876\n",
      "post-prune from root test score:  0.4749349898873158\n",
      "===================\n",
      "depth=3, post-prune=from leaf\n",
      "no-prune validation score:  0.46428893905191876\n",
      "no-prune test score:  0.4749349898873158\n",
      "post-prune from leaf validation score:  0.46428893905191876\n",
      "post-prune from leaf test score:  0.4749349898873158\n",
      "===================\n",
      "depth=4, post-prune=from root\n",
      "no-prune validation score:  0.47665914221218963\n",
      "no-prune test score:  0.48295290378503325\n",
      "post-prune from root validation score:  0.4767494356659142\n",
      "post-prune from root test score:  0.4817971684484253\n",
      "===================\n",
      "depth=4, post-prune=from leaf\n",
      "no-prune validation score:  0.47665914221218963\n",
      "no-prune test score:  0.48295290378503325\n",
      "post-prune from leaf validation score:  0.4767494356659142\n",
      "post-prune from leaf test score:  0.4817971684484253\n",
      "===================\n",
      "depth=5, post-prune=from root\n",
      "no-prune validation score:  0.4855079006772009\n",
      "no-prune test score:  0.4946547240681884\n",
      "post-prune from root validation score:  0.4860496613995485\n",
      "post-prune from root test score:  0.4932822883559665\n",
      "===================\n",
      "depth=5, post-prune=from leaf\n",
      "no-prune validation score:  0.4855079006772009\n",
      "no-prune test score:  0.4946547240681884\n",
      "post-prune from leaf validation score:  0.4860496613995485\n",
      "post-prune from leaf test score:  0.4932822883559665\n",
      "===================\n",
      "depth=6, post-prune=from root\n",
      "no-prune validation score:  0.4922799097065463\n",
      "no-prune test score:  0.5015891360878358\n",
      "post-prune from root validation score:  0.4930022573363431\n",
      "post-prune from root test score:  0.5\n",
      "===================\n",
      "depth=6, post-prune=from leaf\n",
      "no-prune validation score:  0.4922799097065463\n",
      "no-prune test score:  0.5015891360878358\n",
      "post-prune from leaf validation score:  0.49318284424379233\n",
      "post-prune from leaf test score:  0.499855533082924\n",
      "===================\n",
      "depth=7, post-prune=from root\n",
      "no-prune validation score:  0.490293453724605\n",
      "no-prune test score:  0.49891649812193006\n",
      "post-prune from root validation score:  0.49354401805869075\n",
      "post-prune from root test score:  0.5006501011268419\n",
      "===================\n",
      "depth=7, post-prune=from leaf\n",
      "no-prune validation score:  0.490293453724605\n",
      "no-prune test score:  0.49891649812193006\n",
      "post-prune from leaf validation score:  0.49381489841986453\n",
      "post-prune from leaf test score:  0.500072233458538\n",
      "===================\n",
      "depth=8, post-prune=from root\n",
      "no-prune validation score:  0.48993227990970656\n",
      "no-prune test score:  0.499422132331696\n",
      "post-prune from root validation score:  0.49399548532731374\n",
      "post-prune from root test score:  0.49956659924877206\n",
      "===================\n",
      "depth=8, post-prune=from leaf\n",
      "no-prune validation score:  0.48993227990970656\n",
      "no-prune test score:  0.499422132331696\n",
      "post-prune from leaf validation score:  0.49525959367945827\n",
      "post-prune from leaf test score:  0.49956659924877206\n",
      "===================\n",
      "depth=9, post-prune=from root\n",
      "no-prune validation score:  0.4883069977426637\n",
      "no-prune test score:  0.49631609361456225\n",
      "post-prune from root validation score:  0.49670428893905194\n",
      "post-prune from root test score:  0.5028171048829818\n",
      "===================\n",
      "depth=9, post-prune=from leaf\n",
      "no-prune validation score:  0.4883069977426637\n",
      "no-prune test score:  0.49631609361456225\n",
      "post-prune from leaf validation score:  0.4992325056433409\n",
      "post-prune from leaf test score:  0.500505634209766\n",
      "===================\n",
      "depth=10, post-prune=from root\n",
      "no-prune validation score:  0.4872234762979684\n",
      "no-prune test score:  0.49530482519503033\n",
      "post-prune from root validation score:  0.49516930022573363\n",
      "post-prune from root test score:  0.5032505056342098\n",
      "===================\n",
      "depth=10, post-prune=from leaf\n",
      "no-prune validation score:  0.4872234762979684\n",
      "no-prune test score:  0.49530482519503033\n",
      "post-prune from leaf validation score:  0.5009480812641084\n",
      "post-prune from leaf test score:  0.4985553308292401\n",
      "===================\n",
      "depth=11, post-prune=from root\n",
      "no-prune validation score:  0.48361173814898417\n",
      "no-prune test score:  0.49364345564865647\n",
      "post-prune from root validation score:  0.4944469525959368\n",
      "post-prune from root test score:  0.5\n",
      "===================\n",
      "depth=11, post-prune=from leaf\n",
      "no-prune validation score:  0.48361173814898417\n",
      "no-prune test score:  0.49364345564865647\n",
      "post-prune from leaf validation score:  0.503747178329571\n",
      "post-prune from leaf test score:  0.4971828951170182\n",
      "===================\n",
      "depth=12, post-prune=from root\n",
      "no-prune validation score:  0.47927765237020314\n",
      "no-prune test score:  0.4906818838485987\n",
      "post-prune from root validation score:  0.49589164785553047\n",
      "post-prune from root test score:  0.5005778676683039\n",
      "===================\n",
      "depth=12, post-prune=from leaf\n",
      "no-prune validation score:  0.47927765237020314\n",
      "no-prune test score:  0.4906818838485987\n",
      "post-prune from leaf validation score:  0.5079909706546275\n",
      "post-prune from leaf test score:  0.4960993932389483\n",
      "===================\n",
      "depth=13, post-prune=from root\n",
      "no-prune validation score:  0.4781038374717833\n",
      "no-prune test score:  0.4874313782143889\n",
      "post-prune from root validation score:  0.49688487584650115\n",
      "post-prune from root test score:  0.49949436579023404\n",
      "===================\n",
      "depth=13, post-prune=from leaf\n",
      "no-prune validation score:  0.4781038374717833\n",
      "no-prune test score:  0.4874313782143889\n",
      "post-prune from leaf validation score:  0.5121444695259594\n",
      "post-prune from leaf test score:  0.49479919098526437\n",
      "===================\n",
      "depth=14, post-prune=from root\n",
      "no-prune validation score:  0.4737697516930023\n",
      "no-prune test score:  0.48259173649234327\n",
      "post-prune from root validation score:  0.4914672686230248\n",
      "post-prune from root test score:  0.49241548685351055\n",
      "===================\n",
      "depth=14, post-prune=from leaf\n",
      "no-prune validation score:  0.4737697516930023\n",
      "no-prune test score:  0.48259173649234327\n",
      "post-prune from leaf validation score:  0.516117381489842\n",
      "post-prune from leaf test score:  0.4916209188095926\n",
      "===================\n",
      "depth=15, post-prune=from root\n",
      "no-prune validation score:  0.4672686230248307\n",
      "no-prune test score:  0.4755128575556198\n",
      "post-prune from root validation score:  0.48613995485327316\n",
      "post-prune from root test score:  0.4875758451314649\n",
      "===================\n",
      "depth=15, post-prune=from leaf\n",
      "no-prune validation score:  0.4672686230248307\n",
      "no-prune test score:  0.4755128575556198\n",
      "post-prune from leaf validation score:  0.52\n",
      "post-prune from leaf test score:  0.485914475585091\n",
      "===================\n",
      "depth=16, post-prune=from root\n",
      "no-prune validation score:  0.4654627539503386\n",
      "no-prune test score:  0.4709621496677261\n",
      "post-prune from root validation score:  0.48939051918735893\n",
      "post-prune from root test score:  0.49458249060965037\n",
      "===================\n",
      "depth=16, post-prune=from leaf\n",
      "no-prune validation score:  0.4654627539503386\n",
      "no-prune test score:  0.4709621496677261\n",
      "post-prune from leaf validation score:  0.5244243792325056\n",
      "post-prune from leaf test score:  0.4846865067899451\n",
      "===================\n",
      "depth=17, post-prune=from root\n",
      "no-prune validation score:  0.45914221218961626\n",
      "no-prune test score:  0.46568910719445245\n",
      "post-prune from root validation score:  0.48478555304740406\n",
      "post-prune from root test score:  0.48808147934123086\n",
      "===================\n",
      "depth=17, post-prune=from leaf\n",
      "no-prune validation score:  0.45914221218961626\n",
      "no-prune test score:  0.46568910719445245\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "post-prune from leaf validation score:  0.5272234762979684\n",
      "post-prune from leaf test score:  0.48129153423865934\n",
      "===================\n",
      "depth=18, post-prune=from root\n",
      "no-prune validation score:  0.45580135440180586\n",
      "no-prune test score:  0.46056053163825483\n",
      "post-prune from root validation score:  0.4817155756207675\n",
      "post-prune from root test score:  0.485842242126553\n",
      "===================\n",
      "depth=18, post-prune=from leaf\n",
      "no-prune validation score:  0.45580135440180586\n",
      "no-prune test score:  0.46056053163825483\n",
      "post-prune from leaf validation score:  0.531647855530474\n",
      "post-prune from leaf test score:  0.4775353943946836\n",
      "===================\n",
      "depth=19, post-prune=from root\n",
      "no-prune validation score:  0.4524604966139955\n",
      "no-prune test score:  0.458176827506501\n",
      "post-prune from root validation score:  0.4817155756207675\n",
      "post-prune from root test score:  0.485842242126553\n",
      "===================\n",
      "depth=19, post-prune=from leaf\n",
      "no-prune validation score:  0.4524604966139955\n",
      "no-prune test score:  0.458176827506501\n",
      "post-prune from leaf validation score:  0.5337246049661399\n",
      "post-prune from leaf test score:  0.4745015891360878\n",
      "===================\n",
      "depth=20, post-prune=from root\n",
      "no-prune validation score:  0.4461399548532731\n",
      "no-prune test score:  0.4543484542039873\n",
      "post-prune from root validation score:  0.4679909706546275\n",
      "post-prune from root test score:  0.47601849176538574\n",
      "===================\n",
      "depth=20, post-prune=from leaf\n",
      "no-prune validation score:  0.4461399548532731\n",
      "no-prune test score:  0.4543484542039873\n",
      "post-prune from leaf validation score:  0.535530474040632\n",
      "post-prune from leaf test score:  0.4731291534238659\n",
      "===================\n",
      "depth=21, post-prune=from root\n",
      "no-prune validation score:  0.44604966139954855\n",
      "no-prune test score:  0.4527593181161514\n",
      "post-prune from root validation score:  0.4679909706546275\n",
      "post-prune from root test score:  0.47601849176538574\n",
      "===================\n",
      "depth=21, post-prune=from leaf\n",
      "no-prune validation score:  0.44604966139954855\n",
      "no-prune test score:  0.4527593181161514\n",
      "post-prune from leaf validation score:  0.5360722347629797\n",
      "post-prune from leaf test score:  0.47226235192141\n",
      "===================\n",
      "depth=22, post-prune=from root\n",
      "no-prune validation score:  0.44650112866817154\n",
      "no-prune test score:  0.44994221323316963\n",
      "post-prune from root validation score:  0.4679909706546275\n",
      "post-prune from root test score:  0.47601849176538574\n",
      "===================\n",
      "depth=22, post-prune=from leaf\n",
      "no-prune validation score:  0.44650112866817154\n",
      "no-prune test score:  0.44994221323316963\n",
      "post-prune from leaf validation score:  0.5376975169300225\n",
      "post-prune from leaf test score:  0.4701675816238082\n",
      "===================\n",
      "depth=23, post-prune=from root\n",
      "no-prune validation score:  0.44623024830699776\n",
      "no-prune test score:  0.45037561398439757\n",
      "post-prune from root validation score:  0.4679909706546275\n",
      "post-prune from root test score:  0.47601849176538574\n",
      "===================\n",
      "depth=23, post-prune=from leaf\n",
      "no-prune validation score:  0.44623024830699776\n",
      "no-prune test score:  0.45037561398439757\n",
      "post-prune from leaf validation score:  0.5390519187358916\n",
      "post-prune from leaf test score:  0.4707454492921121\n",
      "===================\n",
      "depth=24, post-prune=from root\n",
      "no-prune validation score:  0.4427990970654628\n",
      "no-prune test score:  0.44820861022825775\n",
      "post-prune from root validation score:  0.4679909706546275\n",
      "post-prune from root test score:  0.47601849176538574\n",
      "===================\n",
      "depth=24, post-prune=from leaf\n",
      "no-prune validation score:  0.4427990970654628\n",
      "no-prune test score:  0.44820861022825775\n",
      "post-prune from leaf validation score:  0.5391422121896162\n",
      "post-prune from leaf test score:  0.4692285466628142\n",
      "===================\n",
      "depth=25, post-prune=from root\n",
      "no-prune validation score:  0.4418058690744921\n",
      "no-prune test score:  0.44770297601849174\n",
      "post-prune from root validation score:  0.4679909706546275\n",
      "post-prune from root test score:  0.47601849176538574\n",
      "===================\n",
      "depth=25, post-prune=from leaf\n",
      "no-prune validation score:  0.4418058690744921\n",
      "no-prune test score:  0.44770297601849174\n",
      "post-prune from leaf validation score:  0.5393227990970655\n",
      "post-prune from leaf test score:  0.4695897139555042\n",
      "===================\n",
      "depth=26, post-prune=from root\n",
      "no-prune validation score:  0.4396388261851016\n",
      "no-prune test score:  0.44661947414042186\n",
      "post-prune from root validation score:  0.4679909706546275\n",
      "post-prune from root test score:  0.47601849176538574\n",
      "===================\n",
      "depth=26, post-prune=from leaf\n",
      "no-prune validation score:  0.4396388261851016\n",
      "no-prune test score:  0.44661947414042186\n",
      "post-prune from leaf validation score:  0.5391422121896162\n",
      "post-prune from leaf test score:  0.47002311470673214\n",
      "===================\n",
      "depth=27, post-prune=from root\n",
      "no-prune validation score:  0.4388261851015801\n",
      "no-prune test score:  0.4468361745160358\n",
      "post-prune from root validation score:  0.4679909706546275\n",
      "post-prune from root test score:  0.47601849176538574\n",
      "===================\n",
      "depth=27, post-prune=from leaf\n",
      "no-prune validation score:  0.4388261851015801\n",
      "no-prune test score:  0.4468361745160358\n",
      "post-prune from leaf validation score:  0.5395033860045146\n",
      "post-prune from leaf test score:  0.46930078012135223\n",
      "===================\n",
      "depth=28, post-prune=from root\n",
      "no-prune validation score:  0.43954853273137695\n",
      "no-prune test score:  0.4459693730135799\n",
      "post-prune from root validation score:  0.4679909706546275\n",
      "post-prune from root test score:  0.47601849176538574\n",
      "===================\n",
      "depth=28, post-prune=from leaf\n",
      "no-prune validation score:  0.43954853273137695\n",
      "no-prune test score:  0.4459693730135799\n",
      "post-prune from leaf validation score:  0.5393227990970655\n",
      "post-prune from leaf test score:  0.46865067899451024\n",
      "===================\n",
      "depth=29, post-prune=from root\n",
      "no-prune validation score:  0.43927765237020316\n",
      "no-prune test score:  0.4459693730135799\n",
      "post-prune from root validation score:  0.4679909706546275\n",
      "post-prune from root test score:  0.47601849176538574\n",
      "===================\n",
      "depth=29, post-prune=from leaf\n",
      "no-prune validation score:  0.43927765237020316\n",
      "no-prune test score:  0.4459693730135799\n",
      "post-prune from leaf validation score:  0.5394130925507901\n",
      "post-prune from leaf test score:  0.46930078012135223\n",
      "*********************\n",
      "best_val=0.539503, best_val_depth=27, best_post_prune=from leaf\n"
     ]
    }
   ],
   "source": [
    "# pre prune + post prune\n",
    "best_val = 0\n",
    "best_val_depth = 0\n",
    "best_post_prune = \"\"\n",
    "for depth in range(1, 30):\n",
    "    dt = DecisionTreeClassifier(criterion=\"entropy\", max_depth=depth, random_state=4321)\n",
    "    dt.fit(X_train, y_train)\n",
    "    dt_val_score = dt.score(X_val, y_val)\n",
    "    print(\"===================\", \"depth=%d, post-prune=from root\" % depth, sep='\\n')\n",
    "    print(\"no-prune validation score: \", dt_val_score)\n",
    "    print(\"no-prune test score: \", dt.score(X_test, y_test))\n",
    "    prune_from_root(dt.tree_, 0)\n",
    "    val_score = dt.score(X_val, y_val)\n",
    "    print(\"post-prune from root validation score: \", val_score)\n",
    "    if val_score > best_val:\n",
    "        best_val = val_score\n",
    "        best_val_depth = depth\n",
    "        best_post_prune = \"from root\"\n",
    "    print(\"post-prune from root test score: \", dt.score(X_test, y_test))\n",
    "    \n",
    "    dt = DecisionTreeClassifier(criterion=\"entropy\", max_depth=depth, random_state=4321)\n",
    "    dt.fit(X_train, y_train)\n",
    "    dt_val_score = dt.score(X_val, y_val)\n",
    "    print(\"===================\", \"depth=%d, post-prune=from leaf\" % depth, sep='\\n')\n",
    "    print(\"no-prune validation score: \", dt_val_score)\n",
    "    print(\"no-prune test score: \", dt.score(X_test, y_test))\n",
    "    prune_from_leaf(dt.tree_, 0)\n",
    "    val_score = dt.score(X_val, y_val)\n",
    "    print(\"post-prune from leaf validation score: \", val_score)\n",
    "    if val_score >= best_val:\n",
    "        best_val = val_score\n",
    "        best_val_depth = depth\n",
    "        best_post_prune = \"from leaf\"\n",
    "    print(\"post-prune from leaf test score: \", dt.score(X_test, y_test))\n",
    "print(\"*********************\")\n",
    "print(\"best_val=%f, best_val_depth=%d, best_post_prune=%s\" % (best_val, best_val_depth, best_post_prune))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth=1, n_estimator=100, val_score=0.495711\n",
      "max_depth=1, n_estimator=200, val_score=0.498420\n",
      "max_depth=1, n_estimator=400, val_score=0.498420\n",
      "max_depth=1, n_estimator=1000, val_score=0.498691\n",
      "max_depth=2, n_estimator=100, val_score=0.496253\n",
      "max_depth=2, n_estimator=200, val_score=0.496524\n",
      "max_depth=2, n_estimator=400, val_score=0.496614\n",
      "max_depth=2, n_estimator=1000, val_score=0.494718\n",
      "max_depth=3, n_estimator=100, val_score=0.492641\n",
      "max_depth=3, n_estimator=200, val_score=0.490745\n",
      "max_depth=3, n_estimator=400, val_score=0.487404\n",
      "max_depth=3, n_estimator=1000, val_score=0.476840\n",
      "max_depth=4, n_estimator=100, val_score=0.482799\n",
      "max_depth=4, n_estimator=200, val_score=0.478555\n",
      "max_depth=4, n_estimator=400, val_score=0.467178\n",
      "max_depth=4, n_estimator=1000, val_score=0.456975\n",
      "max_depth=5, n_estimator=100, val_score=0.478104\n",
      "max_depth=5, n_estimator=200, val_score=0.466546\n",
      "max_depth=5, n_estimator=400, val_score=0.454086\n",
      "max_depth=5, n_estimator=1000, val_score=0.441264\n",
      "max_depth=6, n_estimator=100, val_score=0.459865\n",
      "max_depth=6, n_estimator=200, val_score=0.448668\n",
      "max_depth=6, n_estimator=400, val_score=0.439187\n",
      "max_depth=6, n_estimator=1000, val_score=0.440271\n",
      "max_depth=7, n_estimator=100, val_score=0.444695\n",
      "max_depth=7, n_estimator=200, val_score=0.444063\n",
      "max_depth=7, n_estimator=400, val_score=0.441084\n",
      "max_depth=7, n_estimator=1000, val_score=0.436298\n",
      "max_depth=8, n_estimator=100, val_score=0.440722\n",
      "max_depth=8, n_estimator=200, val_score=0.445418\n",
      "max_depth=8, n_estimator=400, val_score=0.439729\n",
      "max_depth=8, n_estimator=1000, val_score=0.438646\n",
      "max_depth=9, n_estimator=100, val_score=0.436659\n",
      "max_depth=9, n_estimator=200, val_score=0.440451\n",
      "max_depth=9, n_estimator=400, val_score=0.441806\n",
      "max_depth=9, n_estimator=1000, val_score=0.441716\n",
      "Best validation score:  0.49869074492099325\n",
      "Best depth:  1\n",
      "Best estimators:  1000\n",
      "Test score:  0.5017336030049119\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "best_val = 0\n",
    "best_depth = 0\n",
    "best_n_estimators = 0\n",
    "for depth in range(1, 10):\n",
    "    for n_estimators in [100, 200, 400, 1000]:\n",
    "        ada_dt = DecisionTreeClassifier(criterion=\"entropy\", max_depth=depth)\n",
    "        adaboost = AdaBoostClassifier(base_estimator=ada_dt, n_estimators=n_estimators)\n",
    "        adaboost.fit(X_train,y_train)\n",
    "        val_score = adaboost.score(X_val,y_val)\n",
    "        print(\"max_depth=%d, n_estimator=%d, val_score=%f\" % (depth, n_estimators, val_score))\n",
    "        if val_score > best_val:\n",
    "            best_val = val_score\n",
    "            best_depth = depth\n",
    "            best_n_estimators = n_estimators\n",
    "            \n",
    "print(\"Best validation score: \", best_val)\n",
    "print(\"Best depth: \", best_depth)\n",
    "print(\"Best estimators: \", best_n_estimators)\n",
    "ada_dt = DecisionTreeClassifier(criterion=\"entropy\", max_depth=best_depth)\n",
    "adaboost = AdaBoostClassifier(base_estimator=ada_dt, n_estimators=best_n_estimators)\n",
    "adaboost.fit(X_train,y_train)\n",
    "test_score = adaboost.score(X_test, y_test)\n",
    "print(\"Test score: \", test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score:  0.5020947702976019\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ada_dt = DecisionTreeClassifier(criterion=\"entropy\", max_depth=1)\n",
    "adaboost = AdaBoostClassifier(base_estimator=ada_dt, n_estimators=2000)\n",
    "adaboost.fit(X_train,y_train)\n",
    "test_score = adaboost.score(X_test, y_test)\n",
    "print(\"Test score: \", test_score)\n",
    "\n",
    "train_mid_error = []\n",
    "for mid_predict in adaboost.staged_predict(X_train):\n",
    "    train_mid_error.append(1 - accuracy_score(mid_predict, y_train))\n",
    "val_mid_error = []\n",
    "for mid_predict in adaboost.staged_predict(X_val):\n",
    "    val_mid_error.append(1 - accuracy_score(mid_predict, y_val))\n",
    "\n",
    "number_of_predict = len(val_mid_error)\n",
    "train_mid_error = train_mid_error[:number_of_predict]\n",
    "\n",
    "plt.plot(range(1, number_of_predict + 1),\n",
    "         val_mid_error, label='Validation')\n",
    "plt.plot(range(1, number_of_predict + 1),\n",
    "         train_mid_error, label='Train')\n",
    "plt.legend()\n",
    "plt.ylabel('Error')\n",
    "plt.xlabel('Number of Trees')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Casualty_Class</th>\n",
       "      <th>Sex_of_Casualty</th>\n",
       "      <th>Age_of_Casualty</th>\n",
       "      <th>Age_Band_of_Casualty</th>\n",
       "      <th>Casualty_Severity</th>\n",
       "      <th>Pedestrian_Location</th>\n",
       "      <th>Pedestrian_Movement</th>\n",
       "      <th>Car_Passenger</th>\n",
       "      <th>Bus_or_Coach_Passenger</th>\n",
       "      <th>Pedestrian_Road_Maintenance_Worker</th>\n",
       "      <th>Casualty_Type</th>\n",
       "      <th>Casualty_Home_Area_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2187726</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498445</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43972</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>9</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1062340</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489502</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Casualty_Class  Sex_of_Casualty  Age_of_Casualty  \\\n",
       "2187726               1                1               38   \n",
       "498445                1                1               27   \n",
       "43972                 1                1               24   \n",
       "1062340               1                1               12   \n",
       "489502                1                1               16   \n",
       "\n",
       "         Age_Band_of_Casualty  Casualty_Severity  Pedestrian_Location  \\\n",
       "2187726                     7                  1                    0   \n",
       "498445                      6                  3                    0   \n",
       "43972                       5                  2                    0   \n",
       "1062340                     3                  3                    0   \n",
       "489502                      4                  1                    0   \n",
       "\n",
       "         Pedestrian_Movement  Car_Passenger  Bus_or_Coach_Passenger  \\\n",
       "2187726                    0              0                       0   \n",
       "498445                     0              0                       0   \n",
       "43972                      0              0                       0   \n",
       "1062340                    0              0                       0   \n",
       "489502                     0              0                       0   \n",
       "\n",
       "         Pedestrian_Road_Maintenance_Worker  Casualty_Type  \\\n",
       "2187726                                   0              5   \n",
       "498445                                   -1              5   \n",
       "43972                                    -1              9   \n",
       "1062340                                  -1              1   \n",
       "489502                                   -1              2   \n",
       "\n",
       "         Casualty_Home_Area_Type  \n",
       "2187726                        2  \n",
       "498445                         1  \n",
       "43972                         -1  \n",
       "1062340                        1  \n",
       "489502                         2  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('../HW1_data/traffic/Casualties0514.csv')\n",
    "dataset.head()\n",
    "# dataset.groupby(\"Casualty_Severity\").count()\n",
    "fatal_dataset = dataset[dataset[\"Casualty_Severity\"]==1]\n",
    "num_fatal = fatal_dataset.shape[0]\n",
    "serious_dataset = dataset[dataset[\"Casualty_Severity\"]==2].sample(n=num_fatal, random_state=35674, axis=0)\n",
    "slight_dataset = dataset[dataset[\"Casualty_Severity\"]==3].sample(n=num_fatal, random_state=25442, axis=0)\n",
    "dataset = pd.concat([fatal_dataset, serious_dataset, slight_dataset],axis=0)\n",
    "del fatal_dataset, serious_dataset, slight_dataset\n",
    "dataset = dataset.drop([\"Accident_Index\", \"Vehicle_Reference\", \"Casualty_Reference\"], axis=1)\n",
    "dataset = dataset.sample(frac=1, axis=0)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age_of_Casualty</th>\n",
       "      <th>Casualty_Severity</th>\n",
       "      <th>Casualty_Class_1</th>\n",
       "      <th>Casualty_Class_2</th>\n",
       "      <th>Casualty_Class_3</th>\n",
       "      <th>Sex_of_Casualty_1</th>\n",
       "      <th>Sex_of_Casualty_2</th>\n",
       "      <th>Age_Band_of_Casualty_1</th>\n",
       "      <th>Age_Band_of_Casualty_2</th>\n",
       "      <th>Age_Band_of_Casualty_3</th>\n",
       "      <th>...</th>\n",
       "      <th>Casualty_Type_18</th>\n",
       "      <th>Casualty_Type_19</th>\n",
       "      <th>Casualty_Type_20</th>\n",
       "      <th>Casualty_Type_21</th>\n",
       "      <th>Casualty_Type_22</th>\n",
       "      <th>Casualty_Type_90</th>\n",
       "      <th>Casualty_Type_97</th>\n",
       "      <th>Casualty_Home_Area_Type_1</th>\n",
       "      <th>Casualty_Home_Area_Type_2</th>\n",
       "      <th>Casualty_Home_Area_Type_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2187726</th>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498445</th>\n",
       "      <td>27</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43972</th>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1062340</th>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489502</th>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  72 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Age_of_Casualty  Casualty_Severity  Casualty_Class_1  \\\n",
       "2187726               38                  1                 1   \n",
       "498445                27                  3                 1   \n",
       "43972                 24                  2                 1   \n",
       "1062340               12                  3                 1   \n",
       "489502                16                  1                 1   \n",
       "\n",
       "         Casualty_Class_2  Casualty_Class_3  Sex_of_Casualty_1  \\\n",
       "2187726                 0                 0                  1   \n",
       "498445                  0                 0                  1   \n",
       "43972                   0                 0                  1   \n",
       "1062340                 0                 0                  1   \n",
       "489502                  0                 0                  1   \n",
       "\n",
       "         Sex_of_Casualty_2  Age_Band_of_Casualty_1  Age_Band_of_Casualty_2  \\\n",
       "2187726                  0                       0                       0   \n",
       "498445                   0                       0                       0   \n",
       "43972                    0                       0                       0   \n",
       "1062340                  0                       0                       0   \n",
       "489502                   0                       0                       0   \n",
       "\n",
       "         Age_Band_of_Casualty_3            ...              Casualty_Type_18  \\\n",
       "2187726                       0            ...                             0   \n",
       "498445                        0            ...                             0   \n",
       "43972                         0            ...                             0   \n",
       "1062340                       1            ...                             0   \n",
       "489502                        0            ...                             0   \n",
       "\n",
       "         Casualty_Type_19  Casualty_Type_20  Casualty_Type_21  \\\n",
       "2187726                 0                 0                 0   \n",
       "498445                  0                 0                 0   \n",
       "43972                   0                 0                 0   \n",
       "1062340                 0                 0                 0   \n",
       "489502                  0                 0                 0   \n",
       "\n",
       "         Casualty_Type_22  Casualty_Type_90  Casualty_Type_97  \\\n",
       "2187726                 0                 0                 0   \n",
       "498445                  0                 0                 0   \n",
       "43972                   0                 0                 0   \n",
       "1062340                 0                 0                 0   \n",
       "489502                  0                 0                 0   \n",
       "\n",
       "         Casualty_Home_Area_Type_1  Casualty_Home_Area_Type_2  \\\n",
       "2187726                          0                          1   \n",
       "498445                           1                          0   \n",
       "43972                            0                          0   \n",
       "1062340                          1                          0   \n",
       "489502                           0                          1   \n",
       "\n",
       "         Casualty_Home_Area_Type_3  \n",
       "2187726                          0  \n",
       "498445                           0  \n",
       "43972                            0  \n",
       "1062340                          0  \n",
       "489502                           0  \n",
       "\n",
       "[5 rows x 72 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for col in [\"Casualty_Class\", \"Sex_of_Casualty\", \"Age_Band_of_Casualty\", \"Pedestrian_Location\", \"Pedestrian_Movement\", \"Car_Passenger\", \"Bus_or_Coach_Passenger\", \"Pedestrian_Road_Maintenance_Worker\", \"Casualty_Type\", \"Casualty_Home_Area_Type\"]: \n",
    "    need_remove_non = False\n",
    "    if dataset[col].min() < 0:\n",
    "        need_remove_non = True\n",
    "    dataset = pd.concat([dataset,pd.get_dummies(dataset[col], prefix=col)],axis=1).drop([col],axis=1)\n",
    "    if need_remove_non:\n",
    "        dataset = dataset.drop([col+\"_-1\"], axis=1)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Age_of_Casualty', 'Casualty_Severity', 'Casualty_Class_1',\n",
       "       'Casualty_Class_2', 'Casualty_Class_3', 'Sex_of_Casualty_1',\n",
       "       'Sex_of_Casualty_2', 'Age_Band_of_Casualty_1', 'Age_Band_of_Casualty_2',\n",
       "       'Age_Band_of_Casualty_3', 'Age_Band_of_Casualty_4',\n",
       "       'Age_Band_of_Casualty_5', 'Age_Band_of_Casualty_6',\n",
       "       'Age_Band_of_Casualty_7', 'Age_Band_of_Casualty_8',\n",
       "       'Age_Band_of_Casualty_9', 'Age_Band_of_Casualty_10',\n",
       "       'Age_Band_of_Casualty_11', 'Pedestrian_Location_0',\n",
       "       'Pedestrian_Location_1', 'Pedestrian_Location_2',\n",
       "       'Pedestrian_Location_3', 'Pedestrian_Location_4',\n",
       "       'Pedestrian_Location_5', 'Pedestrian_Location_6',\n",
       "       'Pedestrian_Location_7', 'Pedestrian_Location_8',\n",
       "       'Pedestrian_Location_9', 'Pedestrian_Location_10',\n",
       "       'Pedestrian_Movement_0', 'Pedestrian_Movement_1',\n",
       "       'Pedestrian_Movement_2', 'Pedestrian_Movement_3',\n",
       "       'Pedestrian_Movement_4', 'Pedestrian_Movement_5',\n",
       "       'Pedestrian_Movement_6', 'Pedestrian_Movement_7',\n",
       "       'Pedestrian_Movement_8', 'Pedestrian_Movement_9', 'Car_Passenger_0',\n",
       "       'Car_Passenger_1', 'Car_Passenger_2', 'Bus_or_Coach_Passenger_0',\n",
       "       'Bus_or_Coach_Passenger_1', 'Bus_or_Coach_Passenger_2',\n",
       "       'Bus_or_Coach_Passenger_3', 'Bus_or_Coach_Passenger_4',\n",
       "       'Pedestrian_Road_Maintenance_Worker_0',\n",
       "       'Pedestrian_Road_Maintenance_Worker_1',\n",
       "       'Pedestrian_Road_Maintenance_Worker_2', 'Casualty_Type_0',\n",
       "       'Casualty_Type_1', 'Casualty_Type_2', 'Casualty_Type_3',\n",
       "       'Casualty_Type_4', 'Casualty_Type_5', 'Casualty_Type_8',\n",
       "       'Casualty_Type_9', 'Casualty_Type_10', 'Casualty_Type_11',\n",
       "       'Casualty_Type_16', 'Casualty_Type_17', 'Casualty_Type_18',\n",
       "       'Casualty_Type_19', 'Casualty_Type_20', 'Casualty_Type_21',\n",
       "       'Casualty_Type_22', 'Casualty_Type_90', 'Casualty_Type_97',\n",
       "       'Casualty_Home_Area_Type_1', 'Casualty_Home_Area_Type_2',\n",
       "       'Casualty_Home_Area_Type_3'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = dataset.drop([\"Casualty_Severity\"], axis=1)\n",
    "y = dataset[\"Casualty_Severity\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(69216, 71)\n",
      "(69216,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(44297, 71)\n",
      "(11075, 71)\n",
      "(13844, 71)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=6357)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=6357)\n",
    "del X, y\n",
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age_of_Casualty</th>\n",
       "      <th>Casualty_Class_1</th>\n",
       "      <th>Casualty_Class_2</th>\n",
       "      <th>Casualty_Class_3</th>\n",
       "      <th>Sex_of_Casualty_1</th>\n",
       "      <th>Sex_of_Casualty_2</th>\n",
       "      <th>Age_Band_of_Casualty_1</th>\n",
       "      <th>Age_Band_of_Casualty_2</th>\n",
       "      <th>Age_Band_of_Casualty_3</th>\n",
       "      <th>Age_Band_of_Casualty_4</th>\n",
       "      <th>...</th>\n",
       "      <th>Casualty_Type_18</th>\n",
       "      <th>Casualty_Type_19</th>\n",
       "      <th>Casualty_Type_20</th>\n",
       "      <th>Casualty_Type_21</th>\n",
       "      <th>Casualty_Type_22</th>\n",
       "      <th>Casualty_Type_90</th>\n",
       "      <th>Casualty_Type_97</th>\n",
       "      <th>Casualty_Home_Area_Type_1</th>\n",
       "      <th>Casualty_Home_Area_Type_2</th>\n",
       "      <th>Casualty_Home_Area_Type_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>44297.000000</td>\n",
       "      <td>44297.000000</td>\n",
       "      <td>44297.000000</td>\n",
       "      <td>44297.000000</td>\n",
       "      <td>44297.000000</td>\n",
       "      <td>44297.000000</td>\n",
       "      <td>44297.000000</td>\n",
       "      <td>44297.000000</td>\n",
       "      <td>44297.000000</td>\n",
       "      <td>44297.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>44297.000000</td>\n",
       "      <td>44297.000000</td>\n",
       "      <td>44297.000000</td>\n",
       "      <td>44297.000000</td>\n",
       "      <td>44297.000000</td>\n",
       "      <td>44297.00000</td>\n",
       "      <td>44297.000000</td>\n",
       "      <td>44297.000000</td>\n",
       "      <td>44297.000000</td>\n",
       "      <td>44297.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>37.622503</td>\n",
       "      <td>0.613879</td>\n",
       "      <td>0.198614</td>\n",
       "      <td>0.187507</td>\n",
       "      <td>0.667133</td>\n",
       "      <td>0.332709</td>\n",
       "      <td>0.014493</td>\n",
       "      <td>0.021356</td>\n",
       "      <td>0.043276</td>\n",
       "      <td>0.145021</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.019098</td>\n",
       "      <td>0.002732</td>\n",
       "      <td>0.007066</td>\n",
       "      <td>0.000384</td>\n",
       "      <td>0.00596</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>0.622299</td>\n",
       "      <td>0.090029</td>\n",
       "      <td>0.122627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>20.874821</td>\n",
       "      <td>0.486864</td>\n",
       "      <td>0.398961</td>\n",
       "      <td>0.390322</td>\n",
       "      <td>0.471245</td>\n",
       "      <td>0.471189</td>\n",
       "      <td>0.119513</td>\n",
       "      <td>0.144569</td>\n",
       "      <td>0.203480</td>\n",
       "      <td>0.352126</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006719</td>\n",
       "      <td>0.136872</td>\n",
       "      <td>0.052194</td>\n",
       "      <td>0.083763</td>\n",
       "      <td>0.019587</td>\n",
       "      <td>0.07697</td>\n",
       "      <td>0.010624</td>\n",
       "      <td>0.484818</td>\n",
       "      <td>0.286226</td>\n",
       "      <td>0.328012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>34.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>51.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>99.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows  71 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Age_of_Casualty  Casualty_Class_1  Casualty_Class_2  Casualty_Class_3  \\\n",
       "count     44297.000000      44297.000000      44297.000000      44297.000000   \n",
       "mean         37.622503          0.613879          0.198614          0.187507   \n",
       "std          20.874821          0.486864          0.398961          0.390322   \n",
       "min          -1.000000          0.000000          0.000000          0.000000   \n",
       "25%          21.000000          0.000000          0.000000          0.000000   \n",
       "50%          34.000000          1.000000          0.000000          0.000000   \n",
       "75%          51.000000          1.000000          0.000000          0.000000   \n",
       "max          99.000000          1.000000          1.000000          1.000000   \n",
       "\n",
       "       Sex_of_Casualty_1  Sex_of_Casualty_2  Age_Band_of_Casualty_1  \\\n",
       "count       44297.000000       44297.000000            44297.000000   \n",
       "mean            0.667133           0.332709                0.014493   \n",
       "std             0.471245           0.471189                0.119513   \n",
       "min             0.000000           0.000000                0.000000   \n",
       "25%             0.000000           0.000000                0.000000   \n",
       "50%             1.000000           0.000000                0.000000   \n",
       "75%             1.000000           1.000000                0.000000   \n",
       "max             1.000000           1.000000                1.000000   \n",
       "\n",
       "       Age_Band_of_Casualty_2  Age_Band_of_Casualty_3  Age_Band_of_Casualty_4  \\\n",
       "count            44297.000000            44297.000000            44297.000000   \n",
       "mean                 0.021356                0.043276                0.145021   \n",
       "std                  0.144569                0.203480                0.352126   \n",
       "min                  0.000000                0.000000                0.000000   \n",
       "25%                  0.000000                0.000000                0.000000   \n",
       "50%                  0.000000                0.000000                0.000000   \n",
       "75%                  0.000000                0.000000                0.000000   \n",
       "max                  1.000000                1.000000                1.000000   \n",
       "\n",
       "                 ...              Casualty_Type_18  Casualty_Type_19  \\\n",
       "count            ...                  44297.000000      44297.000000   \n",
       "mean             ...                      0.000045          0.019098   \n",
       "std              ...                      0.006719          0.136872   \n",
       "min              ...                      0.000000          0.000000   \n",
       "25%              ...                      0.000000          0.000000   \n",
       "50%              ...                      0.000000          0.000000   \n",
       "75%              ...                      0.000000          0.000000   \n",
       "max              ...                      1.000000          1.000000   \n",
       "\n",
       "       Casualty_Type_20  Casualty_Type_21  Casualty_Type_22  Casualty_Type_90  \\\n",
       "count      44297.000000      44297.000000      44297.000000       44297.00000   \n",
       "mean           0.002732          0.007066          0.000384           0.00596   \n",
       "std            0.052194          0.083763          0.019587           0.07697   \n",
       "min            0.000000          0.000000          0.000000           0.00000   \n",
       "25%            0.000000          0.000000          0.000000           0.00000   \n",
       "50%            0.000000          0.000000          0.000000           0.00000   \n",
       "75%            0.000000          0.000000          0.000000           0.00000   \n",
       "max            1.000000          1.000000          1.000000           1.00000   \n",
       "\n",
       "       Casualty_Type_97  Casualty_Home_Area_Type_1  Casualty_Home_Area_Type_2  \\\n",
       "count      44297.000000               44297.000000               44297.000000   \n",
       "mean           0.000113                   0.622299                   0.090029   \n",
       "std            0.010624                   0.484818                   0.286226   \n",
       "min            0.000000                   0.000000                   0.000000   \n",
       "25%            0.000000                   0.000000                   0.000000   \n",
       "50%            0.000000                   1.000000                   0.000000   \n",
       "75%            0.000000                   1.000000                   0.000000   \n",
       "max            1.000000                   1.000000                   1.000000   \n",
       "\n",
       "       Casualty_Home_Area_Type_3  \n",
       "count               44297.000000  \n",
       "mean                    0.122627  \n",
       "std                     0.328012  \n",
       "min                     0.000000  \n",
       "25%                     0.000000  \n",
       "50%                     0.000000  \n",
       "75%                     0.000000  \n",
       "max                     1.000000  \n",
       "\n",
       "[8 rows x 71 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first_layer=100, activation=identity, val_score=0.479910\n",
      "first_layer=100, activation=logistic, val_score=0.499594\n",
      "first_layer=100, activation=tanh, val_score=0.499774\n",
      "first_layer=100, activation=relu, val_score=0.500677\n",
      "first_layer=100, second_layer=100, activation=identity, val_score=0.496795\n",
      "first_layer=100, second_layer=100, activation=logistic, val_score=0.501129\n",
      "first_layer=100, second_layer=100, activation=tanh, val_score=0.487946\n",
      "first_layer=100, second_layer=100, activation=relu, val_score=0.483883\n",
      "first_layer=100, second_layer=200, activation=identity, val_score=0.489120\n",
      "first_layer=100, second_layer=200, activation=logistic, val_score=0.501851\n",
      "first_layer=100, second_layer=200, activation=tanh, val_score=0.499594\n",
      "first_layer=100, second_layer=200, activation=relu, val_score=0.487133\n",
      "first_layer=100, second_layer=300, activation=identity, val_score=0.472957\n",
      "first_layer=100, second_layer=300, activation=logistic, val_score=0.489120\n",
      "first_layer=100, second_layer=300, activation=tanh, val_score=0.501129\n",
      "first_layer=100, second_layer=300, activation=relu, val_score=0.496433\n",
      "first_layer=200, activation=identity, val_score=0.449120\n",
      "first_layer=200, activation=logistic, val_score=0.495892\n",
      "first_layer=200, activation=tanh, val_score=0.500587\n",
      "first_layer=200, activation=relu, val_score=0.486501\n",
      "first_layer=200, second_layer=100, activation=identity, val_score=0.485779\n",
      "first_layer=200, second_layer=100, activation=logistic, val_score=0.500767\n",
      "first_layer=200, second_layer=100, activation=tanh, val_score=0.500135\n",
      "first_layer=200, second_layer=100, activation=relu, val_score=0.486772\n",
      "first_layer=200, second_layer=200, activation=identity, val_score=0.492731\n",
      "first_layer=200, second_layer=200, activation=logistic, val_score=0.501670\n",
      "first_layer=200, second_layer=200, activation=tanh, val_score=0.500497\n",
      "first_layer=200, second_layer=200, activation=relu, val_score=0.496343\n",
      "first_layer=200, second_layer=300, activation=identity, val_score=0.494266\n",
      "first_layer=200, second_layer=300, activation=logistic, val_score=0.499865\n",
      "first_layer=200, second_layer=300, activation=tanh, val_score=0.502483\n",
      "first_layer=200, second_layer=300, activation=relu, val_score=0.501670\n",
      "first_layer=300, activation=identity, val_score=0.484876\n",
      "first_layer=300, activation=logistic, val_score=0.498871\n",
      "first_layer=300, activation=tanh, val_score=0.500135\n",
      "first_layer=300, activation=relu, val_score=0.492641\n",
      "first_layer=300, second_layer=100, activation=identity, val_score=0.497246\n",
      "first_layer=300, second_layer=100, activation=logistic, val_score=0.500677\n",
      "first_layer=300, second_layer=100, activation=tanh, val_score=0.501219\n",
      "first_layer=300, second_layer=100, activation=relu, val_score=0.481264\n",
      "first_layer=300, second_layer=200, activation=identity, val_score=0.497156\n",
      "first_layer=300, second_layer=200, activation=logistic, val_score=0.499413\n",
      "first_layer=300, second_layer=200, activation=tanh, val_score=0.500677\n",
      "first_layer=300, second_layer=200, activation=relu, val_score=0.476117\n",
      "first_layer=300, second_layer=300, activation=identity, val_score=0.497427\n",
      "first_layer=300, second_layer=300, activation=logistic, val_score=0.500316\n",
      "first_layer=300, second_layer=300, activation=tanh, val_score=0.490113\n",
      "first_layer=300, second_layer=300, activation=relu, val_score=0.472777\n",
      "0.5024830699774266\n",
      "(200, 300)\n",
      "tanh\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5018058364634499"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "best_val = 0\n",
    "best_layer = (0)\n",
    "best_activation = \"\"\n",
    "for first_layer in range(100, 301, 100):\n",
    "    for activation in ['identity', 'logistic', 'tanh', 'relu']:\n",
    "        mlp = MLPClassifier(hidden_layer_sizes=(first_layer), activation=activation, max_iter=1000)\n",
    "        mlp.fit(X_train, y_train)\n",
    "        val_score = mlp.score(X_val, y_val)\n",
    "        print(\"first_layer=%d, activation=%s, val_score=%f\" % (first_layer, activation, val_score))\n",
    "        if val_score > best_val:\n",
    "            best_val = val_score\n",
    "            best_layer = (first_layer)\n",
    "            best_activation = activation\n",
    "    for second_layer in range(100, 301, 100):\n",
    "        for activation in ['identity', 'logistic', 'tanh', 'relu']:\n",
    "            mlp = MLPClassifier(hidden_layer_sizes=(first_layer, second_layer), activation=activation, max_iter=1000)\n",
    "            mlp.fit(X_train, y_train)\n",
    "            val_score = mlp.score(X_val, y_val)\n",
    "            print(\"first_layer=%d, second_layer=%d, activation=%s, val_score=%f\" % (first_layer, second_layer, activation, val_score))\n",
    "            if val_score > best_val:\n",
    "                best_val = val_score\n",
    "                best_layer = (first_layer, second_layer)\n",
    "                best_activation = activation\n",
    "\n",
    "print(best_val)\n",
    "print(best_layer)\n",
    "print(best_activation)\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(best_layer), activation=best_activation, max_iter=1000)\n",
    "mlp.fit(X_train, y_train)\n",
    "mlp.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C=0.017016, val_score=0.503025\n",
      "C=0.009832, val_score=0.503567\n",
      "C=0.030914, val_score=0.502573\n",
      "C=0.022152, val_score=0.502935\n",
      "C=123.472334, val_score=0.341580\n",
      "C=30.268342, val_score=0.341038\n",
      "C=30.769953, val_score=0.361625\n",
      "C=35.780220, val_score=0.331648\n",
      "C=0.679693, val_score=0.496975\n",
      "C=22.344992, val_score=0.401986\n",
      "C=0.552051, val_score=0.386637\n",
      "C=2.928661, val_score=0.428533\n",
      "C=6.792751, val_score=0.373815\n",
      "C=1.680424, val_score=0.358736\n",
      "C=107.719136, val_score=0.326953\n",
      "C=0.531973, val_score=0.393318\n",
      "C=0.893940, val_score=0.458420\n",
      "C=0.010707, val_score=0.503386\n",
      "C=0.016990, val_score=0.502844\n",
      "C=1.646754, val_score=0.482619\n",
      "C=3.243688, val_score=0.467720\n",
      "C=0.010618, val_score=0.503567\n",
      "C=4.975460, val_score=0.353499\n",
      "C=0.062937, val_score=0.502664\n",
      "C=5.851849, val_score=0.377517\n",
      "C=30.596189, val_score=0.417788\n",
      "C=0.022831, val_score=0.502754\n",
      "C=0.111749, val_score=0.503205\n",
      "C=27.370081, val_score=0.458962\n",
      "C=39.521140, val_score=0.469977\n",
      "C=0.856100, val_score=0.430880\n",
      "C=78.430274, val_score=0.369391\n",
      "C=0.105863, val_score=0.476388\n",
      "C=2.701365, val_score=0.492641\n",
      "C=110.409716, val_score=0.347720\n",
      "C=0.029726, val_score=0.503928\n",
      "C=7.768340, val_score=0.422844\n",
      "C=32.065507, val_score=0.429797\n",
      "C=0.303804, val_score=0.474582\n",
      "C=8.295939, val_score=0.393499\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f82f0c4f550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best validation score:  0.5039277652370203\n",
      "Best C:  0.029725770708089135\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from random import random\n",
    "\n",
    "best_val = 0\n",
    "best_C = 0\n",
    "all_C_val_score = []\n",
    "all_C = []\n",
    "for i in range(40):\n",
    "    log_C = random() * 10 - 5\n",
    "    C = np.exp(log_C)\n",
    "    clf = svm.LinearSVC(C=C, multi_class=\"ovr\")\n",
    "    clf.fit(X_train,y_train)\n",
    "    val_score = clf.score(X_val,y_val)\n",
    "    print(\"C=%f, val_score=%f\" % (C, val_score))\n",
    "    if val_score > best_val:\n",
    "        best_val = val_score\n",
    "        best_C = C\n",
    "    all_C.append(C)\n",
    "    all_C_val_score.append(val_score)\n",
    "\n",
    "plt.scatter(all_C, all_C_val_score)\n",
    "plt.show()\n",
    "print(\"Best validation score: \", best_val)\n",
    "print(\"Best C: \", best_C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score:  0.49776076278532216\n"
     ]
    }
   ],
   "source": [
    "clf = svm.LinearSVC(C=best_C, multi_class=\"ovr\")\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"Test score: \", clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=-1, n_neighbors=9, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=9, n_jobs=-1)\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.44604966139954855"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n=1, weights=uniform, metric=euclidean, val_score=0.406050\n",
      "n=1, weights=uniform, metric=manhattan, val_score=0.406501\n",
      "n=1, weights=uniform, metric=chebyshev, val_score=0.397111\n",
      "n=1, weights=uniform, metric=minkowski, val_score=0.406050\n",
      "n=1, weights=distance, metric=euclidean, val_score=0.406050\n",
      "n=1, weights=distance, metric=manhattan, val_score=0.406501\n",
      "n=1, weights=distance, metric=chebyshev, val_score=0.397111\n",
      "n=1, weights=distance, metric=minkowski, val_score=0.406050\n",
      "n=2, weights=uniform, metric=euclidean, val_score=0.401716\n",
      "n=2, weights=uniform, metric=manhattan, val_score=0.401716\n",
      "n=2, weights=uniform, metric=chebyshev, val_score=0.391874\n",
      "n=2, weights=uniform, metric=minkowski, val_score=0.401716\n",
      "n=2, weights=distance, metric=euclidean, val_score=0.397833\n",
      "n=2, weights=distance, metric=manhattan, val_score=0.398104\n",
      "n=2, weights=distance, metric=chebyshev, val_score=0.392415\n",
      "n=2, weights=distance, metric=minkowski, val_score=0.397833\n",
      "n=3, weights=uniform, metric=euclidean, val_score=0.422483\n",
      "n=3, weights=uniform, metric=manhattan, val_score=0.423296\n",
      "n=3, weights=uniform, metric=chebyshev, val_score=0.404334\n",
      "n=3, weights=uniform, metric=minkowski, val_score=0.422483\n",
      "n=3, weights=distance, metric=euclidean, val_score=0.415530\n",
      "n=3, weights=distance, metric=manhattan, val_score=0.415621\n",
      "n=3, weights=distance, metric=chebyshev, val_score=0.407223\n",
      "n=3, weights=distance, metric=minkowski, val_score=0.415530\n",
      "n=4, weights=uniform, metric=euclidean, val_score=0.431964\n",
      "n=4, weights=uniform, metric=manhattan, val_score=0.431783\n",
      "n=4, weights=uniform, metric=chebyshev, val_score=0.407223\n",
      "n=4, weights=uniform, metric=minkowski, val_score=0.431964\n",
      "n=4, weights=distance, metric=euclidean, val_score=0.424831\n",
      "n=4, weights=distance, metric=manhattan, val_score=0.423928\n",
      "n=4, weights=distance, metric=chebyshev, val_score=0.411377\n",
      "n=4, weights=distance, metric=minkowski, val_score=0.424831\n",
      "n=5, weights=uniform, metric=euclidean, val_score=0.431061\n",
      "n=5, weights=uniform, metric=manhattan, val_score=0.431332\n",
      "n=5, weights=uniform, metric=chebyshev, val_score=0.404063\n",
      "n=5, weights=uniform, metric=minkowski, val_score=0.431061\n",
      "n=5, weights=distance, metric=euclidean, val_score=0.421129\n",
      "n=5, weights=distance, metric=manhattan, val_score=0.422032\n",
      "n=5, weights=distance, metric=chebyshev, val_score=0.409391\n",
      "n=5, weights=distance, metric=minkowski, val_score=0.421129\n",
      "n=6, weights=uniform, metric=euclidean, val_score=0.440451\n",
      "n=6, weights=uniform, metric=manhattan, val_score=0.440542\n",
      "n=6, weights=uniform, metric=chebyshev, val_score=0.415079\n",
      "n=6, weights=uniform, metric=minkowski, val_score=0.440451\n",
      "n=6, weights=distance, metric=euclidean, val_score=0.431422\n",
      "n=6, weights=distance, metric=manhattan, val_score=0.431874\n",
      "n=6, weights=distance, metric=chebyshev, val_score=0.417246\n",
      "n=6, weights=distance, metric=minkowski, val_score=0.431422\n",
      "n=7, weights=uniform, metric=euclidean, val_score=0.447133\n",
      "n=7, weights=uniform, metric=manhattan, val_score=0.447404\n",
      "n=7, weights=uniform, metric=chebyshev, val_score=0.419052\n",
      "n=7, weights=uniform, metric=minkowski, val_score=0.447133\n",
      "n=7, weights=distance, metric=euclidean, val_score=0.436027\n",
      "n=7, weights=distance, metric=manhattan, val_score=0.436388\n",
      "n=7, weights=distance, metric=chebyshev, val_score=0.422393\n",
      "n=7, weights=distance, metric=minkowski, val_score=0.436027\n",
      "n=8, weights=uniform, metric=euclidean, val_score=0.449752\n",
      "n=8, weights=uniform, metric=manhattan, val_score=0.450023\n",
      "n=8, weights=uniform, metric=chebyshev, val_score=0.423386\n",
      "n=8, weights=uniform, metric=minkowski, val_score=0.449752\n",
      "n=8, weights=distance, metric=euclidean, val_score=0.437743\n",
      "n=8, weights=distance, metric=manhattan, val_score=0.436298\n",
      "n=8, weights=distance, metric=chebyshev, val_score=0.423928\n",
      "n=8, weights=distance, metric=minkowski, val_score=0.437743\n",
      "n=9, weights=uniform, metric=euclidean, val_score=0.446050\n",
      "n=9, weights=uniform, metric=manhattan, val_score=0.445959\n",
      "n=9, weights=uniform, metric=chebyshev, val_score=0.420497\n",
      "n=9, weights=uniform, metric=minkowski, val_score=0.446050\n",
      "n=9, weights=distance, metric=euclidean, val_score=0.433499\n",
      "n=9, weights=distance, metric=manhattan, val_score=0.435395\n",
      "n=9, weights=distance, metric=chebyshev, val_score=0.422032\n",
      "n=9, weights=distance, metric=minkowski, val_score=0.433499\n",
      "n=10, weights=uniform, metric=euclidean, val_score=0.451919\n",
      "n=10, weights=uniform, metric=manhattan, val_score=0.451828\n",
      "n=10, weights=uniform, metric=chebyshev, val_score=0.422844\n",
      "n=10, weights=uniform, metric=minkowski, val_score=0.451919\n",
      "n=10, weights=distance, metric=euclidean, val_score=0.437381\n",
      "n=10, weights=distance, metric=manhattan, val_score=0.437833\n",
      "n=10, weights=distance, metric=chebyshev, val_score=0.424831\n",
      "n=10, weights=distance, metric=minkowski, val_score=0.437381\n",
      "n=11, weights=uniform, metric=euclidean, val_score=0.457427\n",
      "n=11, weights=uniform, metric=manhattan, val_score=0.457878\n",
      "n=11, weights=uniform, metric=chebyshev, val_score=0.427178\n",
      "n=11, weights=uniform, metric=minkowski, val_score=0.457427\n",
      "n=11, weights=distance, metric=euclidean, val_score=0.441625\n",
      "n=11, weights=distance, metric=manhattan, val_score=0.441445\n",
      "n=11, weights=distance, metric=chebyshev, val_score=0.428984\n",
      "n=11, weights=distance, metric=minkowski, val_score=0.441625\n",
      "n=12, weights=uniform, metric=euclidean, val_score=0.455350\n",
      "n=12, weights=uniform, metric=manhattan, val_score=0.455440\n",
      "n=12, weights=uniform, metric=chebyshev, val_score=0.421490\n",
      "n=12, weights=uniform, metric=minkowski, val_score=0.455350\n",
      "n=12, weights=distance, metric=euclidean, val_score=0.439458\n",
      "n=12, weights=distance, metric=manhattan, val_score=0.439819\n",
      "n=12, weights=distance, metric=chebyshev, val_score=0.425282\n",
      "n=12, weights=distance, metric=minkowski, val_score=0.439458\n",
      "n=13, weights=uniform, metric=euclidean, val_score=0.453815\n",
      "n=13, weights=uniform, metric=manhattan, val_score=0.453454\n",
      "n=13, weights=uniform, metric=chebyshev, val_score=0.418691\n",
      "n=13, weights=uniform, metric=minkowski, val_score=0.453815\n",
      "n=13, weights=distance, metric=euclidean, val_score=0.439097\n",
      "n=13, weights=distance, metric=manhattan, val_score=0.440181\n",
      "n=13, weights=distance, metric=chebyshev, val_score=0.423115\n",
      "n=13, weights=distance, metric=minkowski, val_score=0.439097\n",
      "n=14, weights=uniform, metric=euclidean, val_score=0.454718\n",
      "n=14, weights=uniform, metric=manhattan, val_score=0.453454\n",
      "n=14, weights=uniform, metric=chebyshev, val_score=0.421761\n",
      "n=14, weights=uniform, metric=minkowski, val_score=0.454718\n",
      "n=14, weights=distance, metric=euclidean, val_score=0.439729\n",
      "n=14, weights=distance, metric=manhattan, val_score=0.439639\n",
      "n=14, weights=distance, metric=chebyshev, val_score=0.425372\n",
      "n=14, weights=distance, metric=minkowski, val_score=0.439729\n",
      "n=15, weights=uniform, metric=euclidean, val_score=0.456704\n",
      "n=15, weights=uniform, metric=manhattan, val_score=0.455982\n",
      "n=15, weights=uniform, metric=chebyshev, val_score=0.421941\n",
      "n=15, weights=uniform, metric=minkowski, val_score=0.456704\n",
      "n=15, weights=distance, metric=euclidean, val_score=0.442619\n",
      "n=15, weights=distance, metric=manhattan, val_score=0.443883\n",
      "n=15, weights=distance, metric=chebyshev, val_score=0.427810\n",
      "n=15, weights=distance, metric=minkowski, val_score=0.442619\n",
      "n=16, weights=uniform, metric=euclidean, val_score=0.460316\n",
      "n=16, weights=uniform, metric=manhattan, val_score=0.460135\n",
      "n=16, weights=uniform, metric=chebyshev, val_score=0.423386\n",
      "n=16, weights=uniform, metric=minkowski, val_score=0.460316\n",
      "n=16, weights=distance, metric=euclidean, val_score=0.443883\n",
      "n=16, weights=distance, metric=manhattan, val_score=0.444334\n",
      "n=16, weights=distance, metric=chebyshev, val_score=0.429255\n",
      "n=16, weights=distance, metric=minkowski, val_score=0.443883\n",
      "n=17, weights=uniform, metric=euclidean, val_score=0.462754\n",
      "n=17, weights=uniform, metric=manhattan, val_score=0.461761\n",
      "n=17, weights=uniform, metric=chebyshev, val_score=0.430339\n",
      "n=17, weights=uniform, metric=minkowski, val_score=0.462754\n",
      "n=17, weights=distance, metric=euclidean, val_score=0.445959\n",
      "n=17, weights=distance, metric=manhattan, val_score=0.445508\n",
      "n=17, weights=distance, metric=chebyshev, val_score=0.431242\n",
      "n=17, weights=distance, metric=minkowski, val_score=0.445959\n",
      "n=18, weights=uniform, metric=euclidean, val_score=0.461038\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n=18, weights=uniform, metric=manhattan, val_score=0.461670\n",
      "n=18, weights=uniform, metric=chebyshev, val_score=0.429436\n",
      "n=18, weights=uniform, metric=minkowski, val_score=0.461038\n",
      "n=18, weights=distance, metric=euclidean, val_score=0.445056\n",
      "n=18, weights=distance, metric=manhattan, val_score=0.445959\n",
      "n=18, weights=distance, metric=chebyshev, val_score=0.430880\n",
      "n=18, weights=distance, metric=minkowski, val_score=0.445056\n",
      "n=19, weights=uniform, metric=euclidean, val_score=0.464831\n",
      "n=19, weights=uniform, metric=manhattan, val_score=0.466095\n",
      "n=19, weights=uniform, metric=chebyshev, val_score=0.425914\n",
      "n=19, weights=uniform, metric=minkowski, val_score=0.464831\n",
      "n=19, weights=distance, metric=euclidean, val_score=0.448668\n",
      "n=19, weights=distance, metric=manhattan, val_score=0.449029\n",
      "n=19, weights=distance, metric=chebyshev, val_score=0.432867\n",
      "n=19, weights=distance, metric=minkowski, val_score=0.448668\n",
      "Best validation score:  0.46609480812641085\n",
      "Best n:  19\n",
      "Best weights method:  uniform\n",
      "Best distance metric:  manhattan\n"
     ]
    }
   ],
   "source": [
    "best_val = 0\n",
    "best_n = 0\n",
    "best_weights = \"\"\n",
    "best_metric = \"\"\n",
    "for n in range(1,20):\n",
    "    for weights in [\"uniform\", \"distance\"]:\n",
    "        for metric in [\"euclidean\", \"manhattan\", \"chebyshev\", \"minkowski\"]:\n",
    "            knn = KNeighborsClassifier(n_neighbors=n, weights=weights, metric=metric, n_jobs=-1)\n",
    "            knn.fit(X_train,y_train)\n",
    "            val_score = knn.score(X_val, y_val)\n",
    "            print(\"n=%d, weights=%s, metric=%s, val_score=%f\" % (n, weights, metric, val_score))\n",
    "            if val_score > best_val:\n",
    "                best_val = val_score\n",
    "                best_n = n\n",
    "                best_weights = weights\n",
    "                best_metric = metric\n",
    "print(\"Best validation score: \", best_val)\n",
    "print(\"Best n: \", best_n)\n",
    "print(\"Best weights method: \", best_weights)\n",
    "print(\"Best distance metric: \", best_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score:  0.46850621207743426\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=best_n, weights=best_weights, metric=best_metric, n_jobs=-1)\n",
    "knn.fit(X_train,y_train)\n",
    "print(\"Test score: \", knn.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (19,) and (29,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-18bebcb9822f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m plt.plot(range(1,20),error_rate,color='blue', linestyle='dashed', marker='o',\n\u001b[0;32m----> 9\u001b[0;31m          markerfacecolor='red', markersize=5)\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Error Rate vs. K Value'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'K'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/7641ML/lib/python3.6/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   3361\u001b[0m                       mplDeprecation)\n\u001b[1;32m   3362\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3363\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3364\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3365\u001b[0m         \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwashold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/7641ML/lib/python3.6/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1865\u001b[0m                         \u001b[0;34m\"the Matplotlib list!)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlabel_namer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1866\u001b[0m                         RuntimeWarning, stacklevel=2)\n\u001b[0;32m-> 1867\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1868\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1869\u001b[0m         inner.__doc__ = _add_data_doc(inner.__doc__,\n",
      "\u001b[0;32m//anaconda/envs/7641ML/lib/python3.6/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1526\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_alias_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1527\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1528\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1529\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0mlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/7641ML/lib/python3.6/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_grab_next_args\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    404\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 406\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mseg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    407\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mseg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/7641ML/lib/python3.6/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs)\u001b[0m\n\u001b[1;32m    381\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex_of\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 383\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_xy_from_xy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommand\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'plot'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/7641ML/lib/python3.6/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_xy_from_xy\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m             raise ValueError(\"x and y must have same first dimension, but \"\n\u001b[0;32m--> 242\u001b[0;31m                              \"have shapes {} and {}\".format(x.shape, y.shape))\n\u001b[0m\u001b[1;32m    243\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m             raise ValueError(\"x and y can be no greater than 2-D, but have \"\n",
      "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (19,) and (29,)"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "error_rate = []\n",
    "for n in range(1,50):\n",
    "    knn = KNeighborsClassifier(n_neighbors=n, weights=\"uniform\", metric=\"manhattan\", n_jobs=-1)\n",
    "    knn.fit(X_train,y_train)\n",
    "    pred_i = knn.predict(X_val)\n",
    "    error_rate.append(np.mean(pred_i != y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmsAAAGDCAYAAAB0s1eWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAIABJREFUeJzs3Xl0VPX9//HnmxBEEhcQ3BIEF3CLFDQmVutaBaKIiUsrftXi2o1aW1vBFkVBK1itda9Qta64oEHExij+6lYFCSYqEaOICwEtUUTNsCXh8/vjM5EhJCEhM3NnJq/HOXMm986dO++Z9hxeflZzziEiIiIiialL0AWIiIiISMsU1kREREQSmMKaiIiISAJTWBMRERFJYAprIiIiIglMYU1EREQkgSmsiYikODNzZrZP0HWIyNZRWBORFpnZJ2a2xsxqIx63x7mGY8xsQ/izvzOzKjM7rx3vv9rMHoplje1lZqPN7LWI4+3N7L9m9qSZpTe59m4ze6CZewwys3Vm1iseNYtIcBTWRGRLTnbOZUY8xjR3kZl1bcu51rRy/XLnXCawPfA7YJqZ7dueeycqM+sJzAE+BX7qnKtrcsm/gFPNLKPJ+XOB2c65lbGvUkSCpLAmIlsl3Dr0XzO72cxWAle3cK6LmY03s0/NbIWZPWBmO4Tv0T/cRXeBmX0G/L/WPtN5/wZWAoMiarnFzJaa2bdmtsDMjgyfHw78CfhpuGXu7fD5HczsHjP73MyWmdm1ZpbWzHfcPdyy2Cvi3BAz+9LM0s1sHzN72cy+CZ97rJ2/Ye/wd64EznbO1Tfznd8AlgGnRbwvDTgLuD98nGdmb5jZqvB3ut3MurXwmS+Z2YURx01b+fYzsxfMbGW4FfMn7flOIhJ9Cmsi0hH5wBJgZ+C6Fs6NDj+OBfYCMoGmXalHA/sDw1r7sHDwGwn0BhZHvDQfGAz0Ah4BnjCz7s6554C/AI+FWwV/EL7+fqAe2AcYAgwFLqQJ59xy4A0ighI+JM0It4BNAp4HegLZwG2t1d9EL+BlYB5wvnNuQyvXPoBvSWt0PJAOlISPG/Atjr2BHwI/Bn7VjloACLfevYD/DXcGRgF3mtmB7b2XiESPwpqIbMnMcItN4+OiiNeWO+duc87VO+fWtHDu/4C/OeeWOOdqgSuAM5t0eV7tnAtF3KOp3c1sFbAGKAZ+75wrb3zROfeQc+6r8GfeBGwDNNtNama7AAXApeHPXAHcDJzZwmc/gg8tmJmFr3sk/Fod0A/Y3Tm31jn3WvO3aFZfYCBwn9vyJs0PAkebWXb4+FzgkcYuU+fcAufc3PD3/wS4Gx+A22sE8Ilz7r7wvd4CngRO34p7iUiUKKyJyJYUOud2jHhMi3htaTPXNz23O348VqNPga7ALlu4T6Tlzrkd8WPWbgWOi3zRzC4zs0Xh7shVwA74Vqbm9MO3Sn3eGEDx4WbnFq6fAfzQzHYHjgIc8Gr4tcsBA940s0ozO38L3yPS28AfgBIzG9Lahc65z4BXgLPNLBMoJNwFCmBmA81stpl9YWbf4lsTW/r+rekH5EeGc3zY3nUr7iUiUdKuwb8iIk001yLU9NxyfAhotAe+C/J/+K7Dlu6z+Y2dW2dmY4EqMyt0zs0Mj08bi+/6q3TObTCzr/Ehqrl7LwXWAb2bGyPWzGeuMrPngZ/gu2qnN7aEOee+AC4CMLMfAXPM7BXn3OIWb7jpvW8xs22AF8zsGOfcwlYuvx8YB3wOfBxu9Wp0F1AOjHLOfWdml9Jya1gI6BFxHBnElgIvO+dOaEv9IhIfalkTkVibDvzOzPYMtwo1jiHbYlBqjnNuPXATcFX41Hb48FcDdDWzq/AtcI3+B/Q3sy7h93+OH2d2U3jJjC5mtreZtdZt+Ai+6/E0NnaBYmZnRHRNfo0Phg3t/D43ALfgg15rM1yfxHedXkNEq1rYdsC3QK2Z7Qf8spX7VOBnl/Ywv/baBRGvzQYGmtk54QkU6WZ2qJnt357vJCLRpbAmIlvyjG26zlpxO99/L37M1SvAx8Ba4DcdrOleYA8zOxkoxQ+0/wDfxbqWTbtVnwg/f2Vmja1R5wLdgPfwIWsGsFsrnzcLGAD8zzn3dsT5Q4F5ZlYbvua3zrmPAcLdov/Xli/jnJsE/BN40cz2buGaEBsD28NNXv4DfuLDd8A0oLVZqTcD6/Eh9v7IeznnvsNPtjgT3yL6BTAFPwZQRAJiWx7XKiIiIiJBUcuaiIiISAJTWBMRERFJYAprIiIiIglMYU1EREQkgSmsiYiIiCSwlFkUt3fv3q5///5BlyEiIiKyRQsWLPjSOdenLdemTFjr378/ZWVlQZchIiIiskVm9umWr/LUDSoiIiKSwBTWRERERBJYTMOamQ03syozW2xm41q45idm9l54a5bIPfd+ZmYfhh8/i2WdIiIiIokqZmPWzCwNuAM4AagG5pvZLOfcexHXDACuAI5wzn1tZjuHz/cCJgC5+I2RF4Tf+3Ws6hURERFJRLFsWcsDFjvnljjn1gOPAqc0ueYi4I7GEOacWxE+Pwx4wTm3MvzaC8DwGNYqIiIikpBiGdaygKURx9Xhc5EGAgPN7L9mNtfMhrfjvSIiIiIpL5ZLd1gz51wznz8AOAbIBl41s5w2vhczuxi4GGCPPfboSK0iIiIiCSmWLWvVQN+I42xgeTPXPO2cq3POfQxU4cNbW96Lc26qcy7XOZfbp0+b1pUTERERSSqxDGvzgQFmtqeZdQPOBGY1uWYmcCyAmfXGd4suAUqBoWbW08x6AkPD50REREQ6lZh1gzrn6s1sDD5kpQH3OucqzWwiUOacm8XGUPYe0AD80Tn3FYCZTcIHPoCJzrmVsao1nhoaoKQEysthyBAoKIC0tKCrEhERkURlzm02FCwp5ebmukTfbqqhAYqGhVg2r5qhoZk8n1FIVn42xaUZCmwiIiKdiJktcM7ltuVa7WAQRyUlsGxeNXNrc7jejWNubQ7V85ZRUhJ0ZSIiIpKoFNbiqLwcTgjNJJ16ANKpZ1iomIqKgAsTERGRhKWwFkf9+8NMV0hdeKhgHV0pzShi8OBg6xIREZHEpbAWR6NGQfd9shmcXsnlTCavRyXZ+VkUFARdmYiIiCQqhbU4+OwzWLgQunaFBe9ncMltA5l/zFguvXOgJheIiIhIq2K5g4EAX3wBxx/vZ4K+/z6kp8PPf+4fIiIiIluilrUYWrkShg6F5cvhwQd9UGv07bfw1lvB1SYiIiLJQWEtRr79FoYPhw8+gKefhsMP3/T1K6+EI4+E+vpg6hMREZHkoLAWI9dd51vOnngCfvzjzV/Py4PVq2HRovjXJiIiIslDYS1GrrkG5syBk09u/vVDD/XPb74Zv5pEREQk+SisRVF9ve/eXLkSuneHY45p+dp99oEdd1RYExERkdYprEXJhg1w/vlw7bXw7LNbvr5LF9+6prAmIiIirdHSHVHgHPz6137G57XXwjnntO19Eyf6tddEREREWqKo0EHOwdix8I9/+Oc//ant7z3ssNjVJSIiIqlB3aAdtGoVzJjhW9auvx7M2v5e5+Dxx+GVV2JXn4iIiCQ3tax1gHPQs6cfd9arV/uCGvjr//AHOOIIOOqo2NQoIiIiyU0ta1tp2jS46CK/jVTv3n7CwNbIy9MkAxEREWmZwtpWeOQRv7fn8uU+rHVEXh4sWQJffhmd2kRERCS1KKy1UUMDzJ4NZ53lZ3sedRQ8+SR069ax++bl+eeyso7XKCIiIqlHYa0NGhqgaFiI8WdUkT19CgOpogehDgc1gEMO8WPXKio6fi8RERFJPZpg0AYlJbBsXjXz1+aQTj3XbRhP/oJKSkoGMmJEx+693XawdCnsvnt0ahUREZHUopa1Nigvh6GhmaRTD0A69QwLFUetNSwrq/0zSUVERKRzUFhrgyFD4PmMQurCDZF1dKU0o4jBg6Nz/4UL/Ti4zz6Lzv1EREQkdSistUFBAWTlZ5OfWckVNpn8zEqy87MoKIjO/detg4cegrlzo3M/ERERSR0as9YGaWlQXJpBSclAKirGMnGwD3BpadG5/0EHwTbb+PXWfvKT6NxTREREUoPCWhulpcGIEXR4QkFzunXzXa1aHFdERESaUjdogsjLgwULoL4+6EpEREQkkSisJYjDDoM994T//S/oSkRERCSRKKwliFGj/KzQrKygKxEREZFEorAmIiIiksAU1hLI+PFw3HFBVyEiIiKJJKZhzcyGm1mVmS02s3HNvD7azGrMrCL8uDDitSlmtjD8+Gks60wUZvDKKxAKBV2JiIiIJIqYhTUzSwPuAAqAA4BRZnZAM5c+5pwbHH78M/zek4CDgcFAPvBHM9s+VrUmirw8v2l8eXnQlYiIiEiiiGXLWh6w2Dm3xDm3HngUOKWN7z0AeNk5V++cCwFvA8NjVGfCOPRQ/6z11kRERKRRLMNaFrA04rg6fK6p08zsHTObYWZ9w+feBgrMrIeZ9QaOBfo2faOZXWxmZWZWVlNTE+36427XXWGPPRTWREREZKNYhjVr5pxrcvwM0N85NwiYA9wP4Jx7Hvg38DowHXgD2Gy5WOfcVOdcrnMut0+fPtGsPTAXXLCxhU1EREQklttNVbNpa1g2sDzyAufcVxGH04ApEa9dB1wHYGaPAB/GrNIEctVVQVcgIiIiiSSWLWvzgQFmtqeZdQPOBGZFXmBmu0UcjgQWhc+nmdlO4b8HAYOA52NYa0JZvRpWrQq6ChEREUkEMQtrzrl6YAxQig9hjzvnKs1sopmNDF92iZlVmtnbwCXA6PD5dOBVM3sPmAqcHb5fyluzBnr2hFtuCboSERERSQTmXNNhZMkpNzfXlZWVBV1GVOTkQL9+8OyzQVciIiIisWBmC5xzuW25VjsYJKC8PD8jNEVytIiIiHSAwloCysuDL7+ETz4JuhIREREJmsJaAsrL889ab01EREQU1hLQQQfBTTdBbpt6skVERCSVxXKdNdlK6enw+98HXYWIiIgkArWsJaivvoKZM6G+UyxYIiIiIi1RWEtQpaVQVASVlUFXIiIiIkFSWEtQmmQgIiIioLCWsPbe2+9koLAmIiLSuSmsJSizjYvjioiISOelsJbA8vJg4UIIhYKuRERERIKisJbALr4YFi2CbbcNuhIREREJitZZS2DZ2UFXICIiIkFTy1qCe/RRuPvuoKsQERGRoCisJbgnn4QpU4KuQkRERIKisJbg8vLg44+hpiboSkRERCQICmsJrnFx3Pnzg61DREREgqGwluAOOQS6dNF6ayIiIp2VwlqCy8yEAw+E6uqgKxEREZEgaOmOJDB/PmyzTdBViIiISBDUspYEFNREREQ6L4W1JLBiBYwcCc88E3QlIiIiEm8Ka0mgZ0944QX4z3+CrkRERETiTWEtCaSnw8EHa0aoiIhIZ6SwliTy8uCtt6CuLuhKREREJJ4U1pJEXh6sWQOVlUFXIiIiIvGksJYk8vPhiCN8YBMREZHOQ+usJYm99oLXXgu6ChEREYk3tawlmfr6oCsQERGReFJYSyL/+AfssAOEQkFXIiIiIvGisJZEsrNh9Wo/K1REREQ6h5iGNTMbbmZVZrbYzMY18/poM6sxs4rw48KI124ws0ozW2Rmt5qZxbLWZHDoof5Z662JiIh0HjGbYGBmacAdwAlANTDfzGY5595rculjzrkxTd57OHAEMCh86jXgaOClWNWbDHbZBfr1U1gTERHpTGLZspYHLHbOLXHOrQceBU5p43sd0B3oBmwDpAP/i0mVSSYvT2FNRESkM4llWMsClkYcV4fPNXWamb1jZjPMrC+Ac+4N4D/A5+FHqXNuUdM3mtnFZlZmZmU1NTXR/wYJ6Oyz4Re/gA0bgq5ERERE4iGWYa25MWauyfEzQH/n3CBgDnA/gJntA+wPZOMD3nFmdtRmN3NuqnMu1zmX26dPn6gWn6hGjoSxY6GLpoaIiIh0CrH8J78a6BtxnA0sj7zAOfeVc25d+HAacEj47yJgrnOu1jlXC5QAh8Ww1qRSUwMffhh0FSIiIhIPsQxr84EBZranmXUDzgRmRV5gZrtFHI4EGrs6PwOONrOuZpaOn1ywWTdoZ/XjH8MllwRdhYiIiMRDzGaDOufqzWwMUAqkAfc65yrNbCJQ5pybBVxiZiOBemAlMDr89hnAccC7+K7T55xzz8Sq1mSTlwczZ4JzoAVNREREUps513QYWXLKzc11ZWVlQZcRF1Onws9/Dh995PcMFRERkeRiZgucc7ltuVbD1JNQXp5/1hIeIiIiqU9hLQkdeCBsu63CmoiISGcQszFrEjvp6fDYY7D//kFXIiIiIrGmsJakTj456ApEREQkHhTWktSXX8KkSdC1Kxx7LBQUQFpa0FWJiIhItGnMWhJqaIBRI0M8d2sV6X+bwoRRVRQNC9HQEHRlIiIiEm0Ka0mopARWvlvNQnKYzDjm1uZQPW8ZJSVBVyYiIiLRprCWhMrLYWhoJunUA5BOPcNCxVRUBFyYiIiIRJ3CWhIaMgSezyikLjzksI6ulGYUMXhwwIWJiIhI1CmsJaGCAsjKzyY/s5KxTOYHXSvJzs+ioCDoykRERCTaNBs0CaWlQXFpBiUlA5k/fyw3HKrZoCIiIqlKYS1JpaXBiBH+AX6f0MxM2GWXYOsSERGR6FI3aApYtQoGDYKrrw66EhEREYk2hbUUsOOOcP75MG0afPBB0NWIiIhINCmspYjx46F7d/8sIiIiqUNhLUXssgtcdhk88QSUlQVdjYiIiESLwloKuewy2H13mD8/6EpEREQkWjQbNIVsvz18+CH06BF0JSIiIhItallLMY1B7c03YcOGYGsRERGRjlNYS0Fz5kB+vh+/JiIiIslNYS0FHXusX3ftz3+G9euDrkZEREQ6QmEtBaWlwfXX+10N/vnPoKsRERGRjlBYS1EFBXDUUTBxItTWBl2NiIiIbC2FtRRlBlOmQF0dvPtu0NWIiIjI1tLSHSnssMNg6VIt5SEiIpLM1LKW4nr0gIYGWLAg6EpERERkayisdQLXXAOHHw6ffhp0JSIiItJeCmudwEUXQZcuMGFC0JWIiIhIeymsdQJ9+8JvfgMPPKDJBiIiIslGYa2TGDcOdtgB/vSnoCsRERGR9lBY6yR69YKxY6GqClatCroaERERaauYhjUzG25mVWa22MzGNfP6aDOrMbOK8OPC8PljI85VmNlaMyuMZa2dwe9+B5WVsOOOQVciIiIibRWzddbMLA24AzgBqAbmm9ks59x7TS59zDk3JvKEc+4/wODwfXoBi4HnY1VrZ7HNNv65thaqq2G//YKtR0RERLYsli1recBi59wS59x64FHglK24z+lAiXNudVSr68ROOglOP92vvyYiIiKJLZZhLQtYGnFcHT7X1Glm9o6ZzTCzvs28fiYwvbkPMLOLzazMzMpqamo6XnEn8Zvf+O7QBx8MuhIRERHZkliGNWvmnGty/AzQ3zk3CJgD3L/JDcx2Aw4CSpv7AOfcVOdcrnMut0+fPlEouXM47TTIy4OrroK1a4OuRkRERFoTy7BWDUS2lGUDyyMvcM595ZxbFz6cBhzS5B4/AYqdc3Uxq7ITMoPJk/2+oXfeGZ17NjTA7NkwaZJ/VheriIhIdMRyI/f5wAAz2xNYhu/OPCvyAjPbzTn3efhwJLCoyT1GAVfEsMZO69hjYdgweOONjt+roQGKhoVYNq+aoaGZTMgoZGp+NsWlGaSldfz+IiIinVnMwppzrt7MxuC7MNOAe51zlWY2EShzzs0CLjGzkUA9sBIY3fh+M+uPb5l7OVY1dnYzZkD37r4lrLwchgyBggLaHbCefRaq51YzL5RDOvVMrB1P/rxKSkoGMmJEbGoXERHpLGLZsoZz7t/Av5ucuyri7ytooeXMOfcJzU9IkCjZdlvfIlb9RjVD1zTfIvbNN7BkCSxfDp9/7h/Ll8PNN/ugd9VVcN11cNmGmaRTD0A69QwLFVNRMVZhTUREpIO0g0EnVlISbhFbncNkN465tTksfmkZ++4Ln3zir5k2DQ4+GEaM8BvCX3UVPPEEfPWVf/2ww/yEhee2KaQunP3r6EppRhGDBwfzvURERFKJwlonVl4Ow1Zv2iI2oqGYLl2gLjylY+RIeOopP7bt009h3Tr48kvICrd5nngiTJ8O/X+UTX5mJeNsMvmZlWTnZ1FQENAXExERSSHmXNPVNJJTbm6uKysrC7qMpDJ7NkwYVcXcWj/WrI6u5GdWMnF6+8eaNTT4lrqKChg8GI47Dnr0iE3dIiIiyc7MFjjncttyrVrWOrGCAsjK9y1iV3SwRSwtzXeVjh/vlwbp18+3xImIiEjHqGWtk2vaIrY1s0GbWroU9t4bLrgA7rorOnWKiIikkva0rCmsSUz84hdw773w0UfQt7lNxERERDqxqHeDmtm2ZrZvx8qSzuSKK8A5uOGGoCsRERFJblsMa2Z2MlABPBc+Hmxms2JdmCS3fv1g9Gi/9EfjMh8iIiLSfm1pWbsayANWATjnKoD+sStJUsWVV8Krr8JOOwVdiYiISPJqyw4G9c65b8ws5sVIatljD/8A3yWq/wuJiIi0X1ta1haa2VlAmpkNMLPbgNdjXJekCOfg4ov9GDYRERFpv7aEtd8ABwLrgEeAb4DfxrIoSR1msHYt3HorrFgRdDUiIiLJpy1h7STn3J+dc4eGH+OBkbEuTFLHn//st6m68cagKxEREUk+bQlrzXVgqVNL2mzffeHMM+GOO6CmJuhqREREkkuLYc3MCsLj07LM7NaIx78gvPO3SBuNHw9r1sDf/hZ0JSIiIsmltdmgy4EyfJfngojz3wG/i2VRknr239+vuXb88UFXIiIiklxaDGvOubeBt83sEedcXRxrkhR1wQVBVyAiIpJ82jJmrb+ZzTCz98xsSeMj5pVJSlq4EIqK4Ouvg65EREQkObQlrN0H3IUfp3Ys8ADwYCyLktTV0AAzZ8IttwRdiYiISHJoS1jb1jn3ImDOuU+dc1cDx8W2LElVP/gBFBbC3/8O33wTdDUiIiKJry1hba2ZdQE+NLMxZlYE7BzjuiSFXXmlD2q33RZ0JSIiIomvLWHtUqAHcAlwCHAO8LNYFiWp7eCD4eST/TIe330XdDUiIiKJbYsbuTvn5of/rAXOAzCzfrEsSlLfhAnw3HPQpS3/uSAiItKJtRrWzOyHQBbwinNuhZkNAsYBRwJ941CfpKhDDvEPERERaV1rOxj8FbgXOA141swmAC8A84AB8SlPUplz8Nhj8KDmFouIiLSotZa1k4Ahzrm1ZtYTv6PBIOfch/EpTVKdGdx7L5SXw6mnQkZG0BWJiIgkntZGDK1xzq0FcM59DVQpqEm0TZjgN3e/++6gKxEREUlM5pxr/gWzVcArEaeOijx2zo2MbWntk5ub68rKyoIuQ7bC8cf7nQ0+/hi23TboakRERGLPzBY453Lbcm1r3aCnNDm+aetLEmnZhAlw1FEwdSr89rdBVyMiIpJYWtvI/eV4FiKd15FHwvnnQ3Z20JWIiIgkni2usyYSD/fcE3QFIiIiiSmmS5Ka2XAzqzKzxWY2rpnXR5tZjZlVhB8XRry2h5k9b2aLzOw9M+sfy1oleKEQ3H47rFsXdCUiIiKJo9WwZmZp4fXW2s3M0oA7gALgAGCUmR3QzKWPOecGhx//jDj/APBX59z+QB6wYmvqkOQxdy785jdw331BVyIiIpI4Wu0Gdc41mNkhZmaupWmjLcsDFjvnlgCY2aP4SQvvbemN4VDX1Tn3QriO2nZ+tiSh446DH/4QrroKvvgCcnOhoADS0oKuTEREJDht6QYtB542s3PM7NTGRxvelwUsjTiuDp9r6jQze8fMZphZ4xZWA4FVZvaUmZWb2V/DLXWbMLOLzazMzMpqamraUJIksg0bwNaE6FlTxdprpjBhVBVFw0I0NARdmYiISHDaEtZ6AV8BxwEnhx8j2vA+a+Zc09a5Z4D+zrlBwBzg/vD5rvj9R/8AHArsBYze7GbOTXXO5Trncvv06dOGkiSRlZTA2sXVLCSHyYxjbm0O1fOWUVISdGUiIiLB2eJsUOfceVt572o23ew9G79lVeS9v4o4nAZMiXhveUQX6kzgMEBzBlNYeTkMDc0knXoA0qlnWKiYioqxjGjLfx6IiIikoC22rJlZtpkVm9kKM/ufmT1pZm1ZEWs+MMDM9jSzbsCZwKwm994t4nAksCjivT3NrLG57DjaMNZNktuQIfB8RiF14f+GqKMrpRlFDB4ccGEiIiIBaks36H34kLU7fszZM+FzrXLO1QNjgFJ8CHvcOVdpZhPNrHGrqkvMrNLM3gYuIdzV6ZxrwHeBvmhm7+K7VKe154tJ8ikogKz8bPIzK7nCJpOXUcnanbI4/vigKxMREQlOi3uDfn+BWYVzbvCWzgVNe4OmhoYGP3atogLWrIG//AUmToQrrwy6MhERkeiJ1t6gjb40s7OB6eHjUfgJByJRl5YGI0bw/Ri1jz6CSZOgsBAOOijY2kRERILQlm7Q84GfAF8AnwOnh8+JxNxtt8GOO8J550F9fdDViIiIxN8WdzAATnPOjXTO9XHO7eycK3TOfRqn+qST69MH7rwTFiyAv/896GpERETir9WwFh7of0qcahFp1umnw803wznnBF2JiIhI/LVlzNp/zex24DEg1HjSOfdWzKoSaeLSS/1z424G2oJKREQ6i7aEtcPDzxMjzjn82mcicfPddzB8OJxyClx+edDViIiIxEerYc3MugB3Oecej1M9Ii3KzIRddvEbvY8cCfvtF3RFIiIisbelMWsb8AvbigTOzE82yMjws0O1wbuIiHQGbVm64wUz+4OZ9TWzXo2PmFcm0oxdd4Vbb4W5czU7VEREOoe27GDwcTOnnXNur9iUtHW0g0Hn4ZxfJPfjj+Gtt6BrW0ZeioiIJJCo7mDgnNuz4yWJRI8Z3HMP9OihoCYiIqmvxW5QM7s84u8zmrz2l1gWJbIlvXv7sLZ6NbzyStDViIiIxE5rY9bOjPj7iiavDY9BLSLt9vvf++U8Fi8OuhIREZHYaC2sWQt/N3csEogrr4Ru3eCCC2DDhqCrERERib7Wwppr4e8li9FbAAAgAElEQVTmjkUCkZXlt6J65RW/rIeIiEiqaXE2qJk14LeXMmBbYHXjS0B351x6XCpsI80G7bycg4ICeO01eOcd2Cuh5ilv1NAAJSVQXg5DhviatW2WiEjnFJXZoM45/TMiScEMpk2Diy7ywS0RNTRA0bAQy+ZVMzQ0kwkZhUzNz6a4NEOBTUREWtWWRXFFEl7fvvDcc7D33kFX0rySElj6RjVza3O43o1jbm0O1fOWUVISdGUiIpLoFNYkpaxYAeeeC598EnQlmyouhhNWzySdegDSqWdYqJiKioALExGRhKewJillzRofjC68MHG6RBcvhgcegGeskLrwyIM6ulKaUcTgwQEXJyIiCU9hTVJKv37w17/Ciy/6cWyJYJ994JZboP+R2eRnVnKFTSY/s5KsvCyOPz7o6kREJNFtcW/QZKHZoNJowwY44QR4802/6Xt1dfxnX27YAFdfDUVF/rNh42zQigrIyfFLjey3n69RREQ6l6juDSqSbLp0gbvvhoP3DXHjxdWMbIjv7Mv16/0ivQ895ANaY1hLS4MRI/wD/NpwN98MP/whjBoV25pERCR5qRtUUtL778Ne3aqpqI/v7MvvvoOTT/ZBbdIkuPbalq+dMgV+9CM/vq6yMrZ1iYhI8lJYk5RUXg4F6zadfXlCbTGvvRa7z/zqKzjmGD9e7p57YPx4vwZcS9LT4bHHYLvt4NRT4dtvY1ebiIgkL4U1SUlDhsDzGZvOviymiFtvhZtu8l2V0bb99rDnnvD003D++W17z+67+8BWV+fH1omIiDSlCQaSkhp3DKiet4xhoWJKM4rolZNFt54ZlJTAgAHw7LP+uaPKymCPPWDnnbf+HuvX+w3pRUSkc2jPBAO1rElKSkuD4tIMJk4fSMbEsUycPpDS1zL497/9jMyBA33AAr8229Z69lk4+mgYM6Zj9Xbr5lvX/vAHePXVjt1LRERSi1rWpFMLhfwyGief7Jfa6NWr7e+95x74+c/hBz+Af/8bdtmlY7V8+y3k5vpJCuXlsOuuHbufiIgkLrWsibRRfb1ff+2OO3yX6B13+HOtcc7P9LzwQjj+eHjppY4HNfBj3p56yoe2n/50y3WIiEjnENOwZmbDzazKzBab2bhmXh9tZjVmVhF+XBjxWkPE+VmxrFM6rx128IvTlpfD4MG+O3PwYL/HaEu++w4efNDvQfrMM342Z7Tk5MDUqX4NtiuuiN59RUQkecWsG9TM0oAPgBOAamA+MMo5917ENaOBXOfcZiN+zKzWOZfZ1s9TN6h0lHN+JufMmXDffX7Zjdpa2HZbP87tzTf9LNORI+Hrr2GnnVpfmqMjxoyBe++FDz6A7OzYfIaIiAQnUXYwyAMWO+eWhIt6FDgFeK/Vd4kExAwKC/0DYNky39K12/YhtvmymqGrZzK+ayH3He13QohVUAP429/gV79SUBMRkdh2g2YBSyOOq8PnmjrNzN4xsxlm1jfifHczKzOzuWZWGMM6RZqVnu4H/Dd8Vs2bq3OYwjgq6uOzE0K3bnDAAf7vJ5/0EyFERKRzimVYa67doWmf6zNAf+fcIGAOcH/Ea3uEmwfPAv5uZntv9gFmF4cDXVlNTU206hYB/LppRx0FRbbpTgjDQsVUVMSnhkWL4Iwz/KzTFJm4LSIi7RTLsFYNRLaUZQPLIy9wzn3lnFsXPpwGHBLx2vLw8xLgJWBI0w9wzk11zuU653L79OkT3epF8GPUXmiyE0JpRhGDB8fn8/ff3888ffhhuOuu+HymiIgklliGtfnAADPb08y6AWcCm8zqNLPdIg5HAovC53ua2Tbhv3sDR6CxbhKAggLIys8mP7OSK2wy+ZmVZOdnUVAQvxquuAJOOgkuvRTmzYvf54qISGKI6aK4ZnYi8HcgDbjXOXedmU0Eypxzs8zsenxIqwdWAr90zr1vZocDdwMb8IHy7865e1r7LM0GlVhpaPCzQSsq/LIeBQV+h4R4+vprOOQQv/ba++9Djx7x/XwREYmu9swG1Q4GIkmivBwWL4ZTT/Xhsbzcd9MGER5FRKRjEmXpDhGJoiFDYNCg8Ab1c6sZtnomEzIKmZrvlxJRYBMRSU3abkokiZSUwGevVzMvlMP1bhxza+OzlIiIiARHYU0kiZSXw/C1wS0lIiIi8aewJpJEml1KpEf8lhIREZH4U1gTSSKRS4mMs8kcSCVrdorvUiIiIhJfmmAgkkTS0qC4NIOSkoFUVIxl33l+0kEX/WeXiEjKUlgTSTJpaTBihH84R0w3lI+nxvXsOrokSbTuIyKSKBTWRJJYY1B7+WW4+WZ4/HG/CXyyaWjwS5Ism1fNCaGZXNWjkNuHZHPPo35JkowM2G472LABVqzY/P2Zmf6xfj2M/HGIFeXVDNXSJiKSItR5IpICamrg6adh3LigK9k6JSWwbF41c2tzmOzGMS+Uw5LXlpGdDbvtBtdd569btcofN33ccot//aGH4OPX/NImk8NLmyydq6VNRCS5qWVNJAWcfjqMGeNb144+Gk45JeiK2ubTT+H226G0FE4KbbokSRHFLDp5LCeeyPezXXv0aH5D+7w8/7xkCRSy6X1OCBXz3HNjGTEiHt9IRCT6tN2USIpYtw6OOAI++siP1+rfP+iKmuccvP46/P3v8NRTviv38MMhVF7F3Noc0qmnjq7kZ1YycfrAdoWs2bNhwqhN7zO4ayV/mTGQU06Bjz/2v0uqjPMTkeTVnu2m1A0qkiK22caPWduwAe6+O+hqWvbPf8KPfgQvvgh//KMPUP/5z8YlSa6wyeRnVpKd3/4lSSKXNmm8z95HZzFiBHz3HRx2mA+0b7wRm+8mIhILalkTSTEffAADBiRO61FNjQ+Pgwf7GaxffglPPAHnnusnDjRqnMVZUeGv7ehs0Kb3aWiA+++H8ePh88/hjDNg8mTYa6/ofVcRkbZqT8uawppIivr0U98letxxwXz+u+/6gf8PPeS7aC+7DG68MZhaItXWwk03wQ03QF0dLFwIAwcGXZWIdDbqBhURfv5zOPVU380YSw0NfqzYpEn+uaEBfvELv1jvI4/AeefBe+8lRlADv8THhAnw4Ye+Za0xqL32ml/6Q0Qk0ahlTSRFffyxXxR2wAAfRLbZJvqf8f36aHOrOT40kzkZhWQdls2Z52dQXQ0XXgi9ekX/c6Ptiy/8xIPsbJgyxYfcROlGFpHUpJY1EWHPPeG++6CsDC6/PDafMWsWfPJqNXNDOUxhHHNDOVTPW8b22/vPTIagBrDrrjBzJnTv7pdB+dGP4L//3bzFUEQkCAprIimsqAh++1u49VZ49tno3dc5ePhhOP98GL5+03XNhoWKqaiI3mfFy/DhflLCtGl+rN/QH4W46qdVrJ4whQmjqigaFlJgE5FAKKyJpLgbbvBjtI4+Orr3vesu6NkTnu9eSF14fe06ulKaUfT9IrbJpmtX33V7222wT/dq5q3O4frwTgjV87QTgogEQ2FNJMV16wZXX+0H1q9e7Wdmbo0334QTT/TLXphBcTFUVcEeR3R8fbRE8/77cOK6Jjsh1CZni6GIJD+FNZFOYvVqyM/3C9G2R1WVH8eVn+/Hv1VV+fN9+kB6OhSXZjBx+kAyJo5l4vSBKbFp+pAh8HzGpi2GxRRRWem7gEVE4klhTaST6NEDTjjBd/HNmLHl6zdsgF/+Eg480O/defXVfizXMcdsel1aml/sdvx4/5zsQQ2a2Qkho5INu2Xx6KPw619rsoGIxJeW7hDpRNavhyOP9N18b70Fe++9+TVr1/pZkeAnEGy3Hfz5z7DzzvGtNWhNd0IYPtwH0ilT/OzQk04KukIRSWbawUBEWvTppz587LmnDx+Vlb7b75hj/KSBKVP8vp0/+IHv8tN6Y5v673/9/qKg30dEtp7WWRORFvXrB/feC8sXh7j23CpCE6bwp9Or2KN3iMsvh0MP3biAroLI5hqD2vz5fiuvmppg6xGR1KewJtIJpadDlqtmXiiHyW4cC9blsHPdMq67znf97bdf0BUmvi+/hLlz/QK6n3wSdDUiksoU1kQ6ofJyGBradGmKQlfMhg0BF5ZECgpgzhxYscK3ti1cGHRFIpKqFNZEOqHmlqZ4PokXsw3KEUfAq6/6vxsnboiIRJvCmkgntNnSFCmymG0QcnL8pINzzoF99gm6GhFJRZoNKtJJNV2aoqAgNdZIC9oXX/jWtjPOCLoSEUlkmg0qIluUiovZJoK//AV+8hO48cagKxGRVBHTsGZmw82syswWm9m4Zl4fbWY1ZlYRflzY5PXtzWyZmd0eyzpFRKLlr3/1Ye2Pf4TLL9f2VCLScV1jdWMzSwPuAE4AqoH5ZjbLOfdek0sfc86NaeE2k4CXY1WjiEi0bbMNPPII9O7tg1tNDfzjH/DCC34W7pAh6nIWkfaJWVgD8oDFzrklAGb2KHAK0DSsNcvMDgF2AZ4D2tSnKyKSCNLS4Pbb/RZd06dD4dAQK96qZmhoJhMyCpman50SG96LSHzEshs0C1gacVwdPtfUaWb2jpnNMLO+AGbWBbgJ+GMM6xMRiRkzmDABrr0WVrxVzdzaHK5345hbm0P1vGWUlARdoYgki1iGteY2qmk6euMZoL9zbhAwB7g/fP5XwL+dc0tphZldbGZlZlZWoz1fRCQBLVq0+QLEJ9QW89JLwdYlIskjlmGtGugbcZwNLI+8wDn3lXNuXfhwGnBI+O8fAmPM7BPgRuBcM5vc9AOcc1Odc7nOudw+ffpEu34RkQ5rbgHiYoq46SY46SRNQBCRLYvlmLX5wAAz2xNYBpwJnBV5gZnt5pz7PHw4ElgE4Jz7v4hrRgO5zrnNZpOKiCS6ggKYmp9N/rxKhoWKKc0oot+gLM4eBmvX+u5SgN//3u+IcNJJ0L17sDWLSGKJWVhzztWb2RigFEgD7nXOVZrZRKDMOTcLuMTMRgL1wEpgdKzqEREJQloaFJdmUFIykIqKsUxsZgHimho/EeHmm2GHHeD00+Hss+Goo6BLDPo/GhdE1uxUkeSgHQxERBJAfT38v/8HDz0ETz0FoRA8/DCcdZYPV2lp0QlZDQ1QNCzEsnl+durzGYVkaXaqSNy1ZwcDhTURkQQTCsGsWb5LdPvtfYvbvfdClzUh0j6vZuiambwQEbK++QZWr4a6uo2P9HQYONDfb8ECWLnSn3/9dXjmpirK1uaQTj11dCU/s5KJ0wcyYkSw31ukM2lPWIvlmDUREdkKGRkwatTG4z328EHLfVTNQnzImlQ7nvx5lZSUDOTmm32rXKSDDoJ33vF//+pX8OabG1/7I5vOTh0WKqaiYqzCmkiCUlgTEUlwp50G770HoQkzSXebh6zf/Q7OPNO3pjU+evXa+P477/Qtb+npMHcu3P/nQupWj/++Za1k2yKuHRzQlxORLVJYExFJAkOGwISMQibVbgxZpRlFTBzMFlvEDjlk49+HHgr/b7afnTo0VMzTVsT/6rPYe+/Y1i8iW09j1kREkkDjxIDqecu+XwIkOz9rqyYGNE5UqKjws0+vuca3ur34IhxwQGzqF5FNaYKBiEgKigxZg5tZAmRrVVbCj38MGzbAnDkwaFDH7ykirVNYExGRdqmqguOOg/328y1sIhJbmg0qIiLtsu++8OqrsN12QVciIk3Fcm9QERFJInvtBX36wPr1fgeF//436IpEBBTWRESkia+/hvnzYdgweOmloKsREYU1ERHZxC67wMsvQ79+cOKJftKBiARHYU1ERDaz666+VW3AAL+OW0lJ0BWJdF4KayIi0qw+ffw2VkccATvvHHQ1Ip2XZoOKiEiLdtrJd4Oa+eNFi2D//YOtSaSzUcuaiIi0qjGoPfSQ3yD+kUeCrUeks1FYExGRNikshCOP9Mt6/OtfQVcj0nmoG1RERNokMxOefdaHtvPOg7VrITsbysv9RvPR2v5KRDalsCYiIm3WowfMmgWnngqX/TLEwB7VDF8zkwkZhUzNz96qjeVFpHXqBhURkXbp3h0uuggGdK/mzdU5XO/GMbc2h+p5y7TEh0gMKKyJiEi7LVwIBetmkk49AOnUc0JtMfff77tHRSR6FNZERKTdhgyB5zMKqQuPpqmjKzOtiBkzICsLfvc7+OabgIvcSg0NMHs2TJrknxsagq5IOjuFNRERabeCAsjKzyY/s5IrbDL5mZUMPDaL0lI4/ngoLvbj2wDefhvWrAm23rZqaICiYSEmjKpi9YQpTBhVRdGwkAKbBMqcc0HXEBW5ubmurKws6DJERDqNhga/DVVFBQwevOls0PXroVs3qK+HPfeE2lo45xw/1u2gg4KtuzWzZ8OEUVXMrc0hnXrq6Ep+ZiUTpw9kxIigq5NUYmYLnHO5bblWLWsiIrJV0tL8vqHjx/vnyFmg3bptvObBB32Qu/tuGDQIfvhDv41Vo0TqdlywAI6v3XQs3rBQMRUVwdUkorAmIiIxYwbHHON3PVi2DP72Nz+Wra7Ov/7pp3D84cF3O375pX8+5BCY3XXTsXilPYoYPDi+9YhEUjeoiIjEVeM/O2Zw2mmw8KkqFhJMt+OHH8K118Kjj8K778Lee0PR0BDVby5jaKiYp1wR2+6TxVvva/04iS51g4qISMIy27jf6L77QiGbLwFSXh7bGj74AM49F/bbD554An79a9hxR99tW/x8BhOnDyRz4ljOmjCQee8qqEmwtIOBiIgE5vDDYUJmIXW1479vWXs2vYjJQ/zrv/oV5OZCURH07Bmdz/z2W7/0iHN+iZE//AF23XXj641j8SJb9lat8rNbG8fiicSTWtZERCQwzS0BstdRWRQU+IBUWgoXXAC77AInnQQPPLB167ctWuQnMABsvz08/DB8/DHceOOmQa05K1bA/vvDDTe0/3NFokFj1kREJFCtLQHinJ+h+fjj/vHpp/Cvf8HPfgbffedf3377Te8TubH8++/7kPb4475lrLIS+vVrf41nnunXjquo8MFNpKPaM2ZNYU1ERJKCc/Dmmz4sbb893HILjB0LJ54Ip58OD08N8cWCaoaGZlLao5CvM7L5ZEUGmZkwZgxcdhn07r11n93YurbffvDqq9BF/VLSQQkzwcDMhptZlZktNrNxzbw+2sxqzKwi/LgwfL6fmS0In6s0s1/Esk4REUl8ZpCfv7El7eij4ec/h7lz4f/+Dxa/XM3cWr+x/LxQDt1qlnHGGfDJJ3D99Vsf1AB23hluvhlefx3uvDMqX0ekzWIW1swsDbgDKAAOAEaZ2QHNXPqYc25w+PHP8LnPgcOdc4OBfGCcme0eq1pFRCT5DB7sW9eWLoXzz998VmkRxQwaBDvtFJ3PO+ccGDrUt6yJxFMsW9bygMXOuSXOufXAo8ApbXmjc269c25d+HAbNBFCRERakJbmZ4vOydx0MdvnM6K7mK0ZPPmkX5NNJJ5iGYKygKURx9Xhc02dZmbvmNkMM+vbeNLM+prZO+F7THHOLY9hrSIiksSam1Wane9nlUZTZqYPbR9/DHPmRPfeIi2JZVizZs41nc3wDNDfOTcImAPc//2Fzi0Nn98H+JmZ7bLZB5hdbGZlZlZWU1MTxdJFRCSZpKVBcalfzDZj4lgmTh9IcWnsFrO96CI/Q1T/9Eg8xDKsVQN9I46zgU1ax5xzX0V0d04DDml6k3CLWiVwZDOvTXXO5Trncvv06RO1wkVEJPm0trF8tN1yi19c97e/jd1niDSKZVibDwwwsz3NrBtwJjAr8gIz2y3icCSwKHw+28y2Df/dEzgCqIphrSIiIm124IHw5z/D9Okwe3bsP6+hwX/OpEn+Od4b3UuwYrbdlHOu3szGAKVAGnCvc67SzCYCZc65WcAlZjYSqAdWAqPDb98fuMnMHL479Ubn3LuxqlVERKS9rrgCZsyAX/4Sjjpq45Ii0dbQAEXDQiyb59eQm5BRyNT87Jh280pi0aK4IiIiW2nePL+jwg03wHbbxeYzZs+Gq86sYl4o5/v9U/MzK5k4feAm+5dKckmYRXFFRERSWX4+3HVX7IIa+O2zTghtuobc0FAxFRWx+0xJLAprIiIiHVRWBqeeCmvXRu+eCxdCba3f57R0203XkHvKFfHdd9H7LElsCmsiIiId9PXXfqP3SZM6fq/aWvjjH/0ODddf79eQ2+PwjWvIHdqjkvpdsjj3XH/98uUouKU4jVkTERGJgvPOg4cegvnz2eqdE55+Gn7zG7+F1oUXwuTJfrushgYoKYGKCn/vgoKNS5Ocdhq8/DKMGwe/+hX06BG97ySx054xawprIiIiUbByJRxwAGRl+YkHXdu53sI118DVV0NODvzjH3DEEW1735tvwlVXQWkp7LabX1Lkwgthm23a/RXarDE8lpf7btrI8ChtowkGIiIicdarF9x+O7z1Ftx//5avB6ir812o4HdE+Otf/fvbGtQA8vLguefglVdgwAAYMwamTGl//W3VuJTIhFFVrJ4whQmjqigaFtLabzGkljUREZEocc6vvVZYCOnprV/76qt+jbZ99/UbxEfr8+fM8a1dvXv7ALd0qQ+CHW35WrkSFi+Gzz+HiWdXMbd241IieRmVTHpUS4m0h1rWREREAmAGZ5zhg9o33/jw1NSXX8L55/uFdGtrYfTo6H7+CSf4oAZwzz1w9tnwgx/AU09BfX3LOyE454PYmjX++NVXfcg79FDo2dOPncvPh//8B4Y2WUrkhFAxo0fDz34G69YhUaaWNRERkSj75BM47DAf3HbeeeO4rtdf961u334Ll10GV14JGRmxq2PDBt/Sd9VVUFUFu2wXYtf6agrWzuS5bQtZ1zubfQ/O4KOP4KOPYPVqePFFOO44P9nh97+Hffbxj7339s9r18KUCzZtWRvSrZLMIQNpaPATLMBPuFiyxP8OjY/ddtu0vs489k0TDERERAJUXw/9+4TIWFVNkc3khYxCsvKzmfZwBhdfDNdd5ycSxLOeyy+Hf/+9infdxpB1IJWsyR7IkCEbA9nIkdC3b8v3ahyzVj1vGcNCxZRmFJGdn7XZ9lfXXQfPPOPH4NXV+XMnngjPPuv/fucd+NOlIT6f77fRej78G23NNlrJGPoU1kRERAI0ezZc+dMq3lwdsUVURiUTAxzXNWkShCZMYbIb9/25cTaZzIljGT++ffdqbSmRptau9dfNnev3Tz3/fP/+zEzYY20VC9n4Gx3SvZK/PDGQ4cPh0Udhhx38Y8cd/XOfPpsvTdJ079SOhL540pg1ERGRAJWXw/A1TbaIWh3sFlFDhsALGZvuhPB8RtFWrQmXlgYjRsD48f65tVDUvbvvAr30Uh/UwHfPFhVBIZv+RgVr/W/09ddwzjm+le/oo/2Yu/794eab/furq2GPPeCgg2DQIFj8UjVza3O43o1jbm0O1fOWUVLS/u+VqBTWREREomzIEHg+SsEoWgoKICt/404I+ZmVZOdnUVAQ/1rS0+Gss2BO5qa/0QuZ/jfq2RM++MCPf3vhBT/u7p574KST/PvT0uDHP/Zdt2vWwMkNm++d+uCDqTPZQd2gIiIiUdbWcV1B1NXW7st41BKN32j2bJgwavMJD5XrB9Kzpw+F550HBx/sZ8smCo1ZExERCVgiBaNEFY3fqLnQl5WXxa//mMEDD/g9W9euhdxcP24uUf43UFgTERGRTqO10LdqFTz2mN/w/ppr/Llx4/w4uhNPhG7dgqlZYU1ERESkGV9/DQce6BcA7t3bLxo8erSfxBDPJUA0G1RERESkGT17wmef+fXejjkG7rzTt8Y98kji7nmqsCYiIiKdSteuvgv0iSd89+htt0GXLrBsXmIuAaKwJiIiIp3WTjvBmDHw4Yeb73k6LBTs2niNFNZERESk02tubbzSgNfGa6SwJiIiIp1eIi0a3FTXoAsQERERCVpaGhSXZlBSMpCKirFMTKC18RTWRERERNi45+mIEUFXsil1g4qIiIgkMIU1ERERkQSmsCYiIiKSwBTWRERERBKYwpqIiIhIAlNYExEREUlgCmsiIiIiCUxhTURERCSBKayJiIiIJDCFNREREZEEZs65oGuICjOrAT5t5ZLewJdxKqcz0+8cP/qt40O/c/zot44f/dbx0drv3M8516ctN0mZsLYlZlbmnMsNuo5Up985fvRbx4d+5/jRbx0/+q3jI1q/s7pBRURERBKYwpqIiIhIAutMYW1q0AV0Evqd40e/dXzod44f/dbxo986PqLyO3eaMWsiIiIiyagztayJiIiIJJ2UD2tmNtzMqsxssZmNC7qeVGZmn5jZu2ZWYWZlQdeTSszsXjNbYWYLI871MrMXzOzD8HPPIGtMBS38zleb2bLw/68rzOzE/9/evYVYVYZhHP8/jEoxBRYdEA90oIsgwqIi6IB0kJLAgpKEwCCoiwKjm8CbDhBEVARdGISBQTVJWnpZF4ZGYKKlHQYsQ2xQRmKQHIKy5ulifwOD7JmYmTWsNWs/Pxhm7W+vWby8vOx5Z3/v2lNnjG0gabmk3ZIGJf0oaWNZT01XbIpcp64rJuk8Sd9IOlRy/VJZv1LSvlLXH0taNO1rt3kbVFIfcAS4FxgC9gPrbf9Ua2AtJekYcJPtfHZPxSTdCYwC79u+rqy9BozYfrX8IXKR7efrjHO+myTPLwKjtl+vM7Y2kbQEWGL7oKQLgQPAg8DjpKYrNUWu15G6rpQkAf22RyUtBL4CNgLPATtsD0h6Bzhke/N0rt32d9ZuAX6x/avtv4EBYG3NMUVMm+09wMg5y2uBreV4K50X4JiFSfIcFbN90vbBcnwGGASWkpqu3BS5joq5Y7Q8XFi+DNwFfFLWZ1TXbW/WlgK/TXg8RIp0Lhn4XNIBSU/WHUwPuNz2Sei8IAOX1RxPmz0j6XDZJs3WXIUkXQHcAOwjNT2nzsk1pK4rJ6lP0nfAKeAL4Chw2vY/5ZQZ9SFtb9bUZa29+771u832jcD9wNNlSylivtsMXA2sBE4Cb9OmIx0AAAJ1SURBVNQbTntIugDYDjxr+4+642mzLrlOXc8B2//aXgkso7O7d22306Z73bY3a0PA8gmPlwEnaoql9WyfKN9PAZ/SKdSYO8NlHmV8LuVUzfG0ku3h8gI8BrxL6roSZaZnO/CB7R1lOTU9B7rlOnU9t2yfBr4EbgUWS1pQnppRH9L2Zm0/cE25E2MR8Ciwq+aYWklSfxleRVI/sBr4YeqfilnaBWwoxxuAnTXG0lrjzUPxEKnrWSuD2FuAQdtvTngqNV2xyXKduq6epEslLS7H5wP30JkR3A08XE6bUV23+m5QgHI78ltAH/Ce7VdqDqmVJF1F5900gAXAh8l1dSR9BKwCLgGGgReAz4BtwArgOPCI7QzHz8IkeV5FZ6vIwDHgqfG5qpgZSbcDe4HvgbGyvInOLFVqukJT5Ho9qetKSbqezg0EfXTeDNtm++Xy+3EAuBj4FnjM9l/Tunbbm7WIiIiI+azt26ARERER81qatYiIiIgGS7MWERER0WBp1iIiIiIaLM1aRERERIOlWYuI6ELS6ITjNZJ+lrSizpgiojct+P9TIiJ6l6S7gbeB1baP1x1PRPSeNGsREZOQdAedf8WzxvbRuuOJiN6UD8WNiOhC0lngDLDK9uG644mI3pWZtYiI7s4CXwNP1B1IRPS2NGsREd2NAeuAmyVtqjuYiOhdmVmLiJiE7T8lPQDslTRse0vdMUVE70mzFhExBdsjku4D9kj63fbOumOKiN6SGwwiIiIiGiwzaxERERENlmYtIiIiosHSrEVEREQ0WJq1iIiIiAZLsxYRERHRYGnWIiIiIhoszVpEREREg6VZi4iIiGiw/wApwaB4pQl6/QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(range(1,50),error_rate,color='blue', linestyle='dashed', marker='o',\n",
    "         markerfacecolor='red', markersize=5)\n",
    "plt.title('Error Rate vs. K Value')\n",
    "plt.xlabel('K')\n",
    "plt.ylabel('Error Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

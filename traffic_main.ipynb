{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('../HW1_data/traffic/Casualties0514.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dataset.groupby(\"Casualty_Severity\").count()\n",
    "fatal_dataset = dataset[dataset[\"Casualty_Severity\"]==1]\n",
    "num_fatal = fatal_dataset.shape[0]\n",
    "serious_dataset = dataset[dataset[\"Casualty_Severity\"]==2].sample(n=num_fatal, random_state=35674, axis=0)\n",
    "slight_dataset = dataset[dataset[\"Casualty_Severity\"]==3].sample(n=num_fatal, random_state=25442, axis=0)\n",
    "dataset = pd.concat([fatal_dataset, serious_dataset, slight_dataset],axis=0)\n",
    "del fatal_dataset, serious_dataset, slight_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Casualty_Class</th>\n",
       "      <th>Sex_of_Casualty</th>\n",
       "      <th>Age_of_Casualty</th>\n",
       "      <th>Age_Band_of_Casualty</th>\n",
       "      <th>Casualty_Severity</th>\n",
       "      <th>Pedestrian_Location</th>\n",
       "      <th>Pedestrian_Movement</th>\n",
       "      <th>Car_Passenger</th>\n",
       "      <th>Bus_or_Coach_Passenger</th>\n",
       "      <th>Pedestrian_Road_Maintenance_Worker</th>\n",
       "      <th>Casualty_Type</th>\n",
       "      <th>Casualty_Home_Area_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1351455</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1740504</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998542</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800167</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1115993</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>59</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Casualty_Class  Sex_of_Casualty  Age_of_Casualty  \\\n",
       "1351455               1                1               26   \n",
       "1740504               2                2               32   \n",
       "1998542               3                1                5   \n",
       "800167                1                1               60   \n",
       "1115993               1                1               59   \n",
       "\n",
       "         Age_Band_of_Casualty  Casualty_Severity  Pedestrian_Location  \\\n",
       "1351455                     6                  3                    0   \n",
       "1740504                     6                  3                    0   \n",
       "1998542                     1                  3                    5   \n",
       "800167                      9                  2                    0   \n",
       "1115993                     9                  1                    0   \n",
       "\n",
       "         Pedestrian_Movement  Car_Passenger  Bus_or_Coach_Passenger  \\\n",
       "1351455                    0              0                       0   \n",
       "1740504                    0              1                       0   \n",
       "1998542                    4              0                       0   \n",
       "800167                     0              0                       0   \n",
       "1115993                    0              0                       0   \n",
       "\n",
       "         Pedestrian_Road_Maintenance_Worker  Casualty_Type  \\\n",
       "1351455                                  -1              1   \n",
       "1740504                                   0              9   \n",
       "1998542                                   0              0   \n",
       "800167                                   -1              1   \n",
       "1115993                                  -1              1   \n",
       "\n",
       "         Casualty_Home_Area_Type  \n",
       "1351455                        1  \n",
       "1740504                        1  \n",
       "1998542                        1  \n",
       "800167                         1  \n",
       "1115993                        1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset.drop([\"Accident_Index\", \"Vehicle_Reference\", \"Casualty_Reference\"], axis=1)\n",
    "dataset = dataset.sample(frac=1, axis=0)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(44297, 11)\n",
      "(11075, 11)\n",
      "(13844, 11)\n"
     ]
    }
   ],
   "source": [
    "# Prepare data for Decision Tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "X = dataset.drop([\"Casualty_Severity\"], axis=1)\n",
    "y = dataset[\"Casualty_Severity\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=6357)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=6357)\n",
    "del X, y\n",
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit end! \n",
      "Validation score:  0.43873589164785554\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import pydotplus as pydot\n",
    "from IPython.display import Image\n",
    "from sklearn.externals.six import StringIO\n",
    "from sklearn import tree\n",
    "\n",
    "# Vanilla Decision Tree\n",
    "dt = DecisionTreeClassifier(criterion=\"entropy\", random_state=4321)\n",
    "dt.fit(X_train, y_train)\n",
    "print(\"Fit end! \")\n",
    "dt_val_score = dt.score(X_val, y_val)\n",
    "print(\"Validation score: \", dt_val_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Post-prune Decision Tree \n",
    "# My own implementation based on https://stackoverflow.com/questions/49428469/pruning-decision-trees/49496027#49496027\n",
    "# Pruning based on validation score (if pruning a subtree gains better performance on validate set, then prune it)\n",
    "from sklearn.tree._tree import TREE_LEAF\n",
    "\n",
    "def prune_from_root(inner_tree, index):\n",
    "    global dt_val_score\n",
    "    memo = (inner_tree.children_left[index], inner_tree.children_right[index])\n",
    "    inner_tree.children_left[index] = TREE_LEAF\n",
    "    inner_tree.children_right[index] = TREE_LEAF\n",
    "    new_score = dt.score(X_val, y_val)\n",
    "    if new_score <= dt_val_score:\n",
    "        inner_tree.children_left[index] = memo[0]\n",
    "        inner_tree.children_right[index] = memo[1]\n",
    "    else:\n",
    "        dt_val_score = new_score\n",
    "\n",
    "    # if there are children, visit them as well\n",
    "    if inner_tree.children_left[index] != TREE_LEAF:\n",
    "        prune_from_root(inner_tree, inner_tree.children_left[index])\n",
    "        prune_from_root(inner_tree, inner_tree.children_right[index])\n",
    "\n",
    "def prune_from_leaf(inner_tree, index):\n",
    "    global dt_val_score\n",
    "    # if there are children, firstly visit them\n",
    "    if inner_tree.children_left[index] != TREE_LEAF:\n",
    "        prune_from_leaf(inner_tree, inner_tree.children_left[index])\n",
    "        prune_from_leaf(inner_tree, inner_tree.children_right[index])\n",
    "        memo = (inner_tree.children_left[index], inner_tree.children_right[index])\n",
    "        inner_tree.children_left[index] = TREE_LEAF\n",
    "        inner_tree.children_right[index] = TREE_LEAF\n",
    "        new_score = dt.score(X_val, y_val)\n",
    "        if new_score <= dt_val_score:\n",
    "            inner_tree.children_left[index] = memo[0]\n",
    "            inner_tree.children_right[index] = memo[1]\n",
    "        else:\n",
    "            dt_val_score = new_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no-prune validation score:  0.43873589164785554\n",
      "no-prune test score:  0.4460416064721179\n",
      "post-prune from root validation score:  0.4588713318284424\n",
      "post-prune from root test score:  0.46865067899451024\n"
     ]
    }
   ],
   "source": [
    "# prune from root\n",
    "dt = DecisionTreeClassifier(criterion=\"entropy\", random_state=4321)\n",
    "dt.fit(X_train, y_train)\n",
    "dt_val_score = dt.score(X_val, y_val)\n",
    "print(\"no-prune validation score: \", dt_val_score)\n",
    "print(\"no-prune test score: \", dt.score(X_test, y_test))\n",
    "prune_from_root(dt.tree_, 0)\n",
    "print(\"post-prune from root validation score: \", dt.score(X_val, y_val))\n",
    "print(\"post-prune from root test score: \", dt.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no-prune validation score:  0.43873589164785554\n",
      "no-prune test score:  0.4460416064721179\n",
      "post-prune from leaf validation score:  0.5398645598194131\n",
      "post-prune from leaf test score:  0.46850621207743426\n"
     ]
    }
   ],
   "source": [
    "# prune from leaf\n",
    "# create an identical decision tree to the previous one using the same random_state\n",
    "dt = DecisionTreeClassifier(criterion=\"entropy\", random_state=4321)\n",
    "dt.fit(X_train, y_train)\n",
    "dt_val_score = dt.score(X_val, y_val)\n",
    "print(\"no-prune validation score: \", dt_val_score)\n",
    "print(\"no-prune test score: \", dt.score(X_test, y_test))\n",
    "prune_from_leaf(dt.tree_, 0)\n",
    "print(\"post-prune from leaf validation score: \", dt.score(X_val, y_val))\n",
    "print(\"post-prune from leaf test score: \", dt.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================\n",
      "depth=1, post-prune=from root\n",
      "no-prune validation score:  0.4302483069977427\n",
      "no-prune test score:  0.43433978618896274\n",
      "post-prune from root validation score:  0.4302483069977427\n",
      "post-prune from root test score:  0.43433978618896274\n",
      "===================\n",
      "depth=1, post-prune=from leaf\n",
      "no-prune validation score:  0.4302483069977427\n",
      "no-prune test score:  0.43433978618896274\n",
      "post-prune from leaf validation score:  0.4302483069977427\n",
      "post-prune from leaf test score:  0.43433978618896274\n",
      "===================\n",
      "depth=2, post-prune=from root\n",
      "no-prune validation score:  0.43548532731376977\n",
      "no-prune test score:  0.4328951170182028\n",
      "post-prune from root validation score:  0.43548532731376977\n",
      "post-prune from root test score:  0.4328951170182028\n",
      "===================\n",
      "depth=2, post-prune=from leaf\n",
      "no-prune validation score:  0.43548532731376977\n",
      "no-prune test score:  0.4328951170182028\n",
      "post-prune from leaf validation score:  0.43548532731376977\n",
      "post-prune from leaf test score:  0.4328951170182028\n",
      "===================\n",
      "depth=3, post-prune=from root\n",
      "no-prune validation score:  0.46428893905191876\n",
      "no-prune test score:  0.4749349898873158\n",
      "post-prune from root validation score:  0.46428893905191876\n",
      "post-prune from root test score:  0.4749349898873158\n",
      "===================\n",
      "depth=3, post-prune=from leaf\n",
      "no-prune validation score:  0.46428893905191876\n",
      "no-prune test score:  0.4749349898873158\n",
      "post-prune from leaf validation score:  0.46428893905191876\n",
      "post-prune from leaf test score:  0.4749349898873158\n",
      "===================\n",
      "depth=4, post-prune=from root\n",
      "no-prune validation score:  0.47665914221218963\n",
      "no-prune test score:  0.48295290378503325\n",
      "post-prune from root validation score:  0.4767494356659142\n",
      "post-prune from root test score:  0.4817971684484253\n",
      "===================\n",
      "depth=4, post-prune=from leaf\n",
      "no-prune validation score:  0.47665914221218963\n",
      "no-prune test score:  0.48295290378503325\n",
      "post-prune from leaf validation score:  0.4767494356659142\n",
      "post-prune from leaf test score:  0.4817971684484253\n",
      "===================\n",
      "depth=5, post-prune=from root\n",
      "no-prune validation score:  0.4855079006772009\n",
      "no-prune test score:  0.4946547240681884\n",
      "post-prune from root validation score:  0.4860496613995485\n",
      "post-prune from root test score:  0.4932822883559665\n",
      "===================\n",
      "depth=5, post-prune=from leaf\n",
      "no-prune validation score:  0.4855079006772009\n",
      "no-prune test score:  0.4946547240681884\n",
      "post-prune from leaf validation score:  0.4860496613995485\n",
      "post-prune from leaf test score:  0.4932822883559665\n",
      "===================\n",
      "depth=6, post-prune=from root\n",
      "no-prune validation score:  0.4922799097065463\n",
      "no-prune test score:  0.5015891360878358\n",
      "post-prune from root validation score:  0.4930022573363431\n",
      "post-prune from root test score:  0.5\n",
      "===================\n",
      "depth=6, post-prune=from leaf\n",
      "no-prune validation score:  0.4922799097065463\n",
      "no-prune test score:  0.5015891360878358\n",
      "post-prune from leaf validation score:  0.49318284424379233\n",
      "post-prune from leaf test score:  0.499855533082924\n",
      "===================\n",
      "depth=7, post-prune=from root\n",
      "no-prune validation score:  0.490293453724605\n",
      "no-prune test score:  0.49891649812193006\n",
      "post-prune from root validation score:  0.49354401805869075\n",
      "post-prune from root test score:  0.5006501011268419\n",
      "===================\n",
      "depth=7, post-prune=from leaf\n",
      "no-prune validation score:  0.490293453724605\n",
      "no-prune test score:  0.49891649812193006\n",
      "post-prune from leaf validation score:  0.49381489841986453\n",
      "post-prune from leaf test score:  0.500072233458538\n",
      "===================\n",
      "depth=8, post-prune=from root\n",
      "no-prune validation score:  0.48993227990970656\n",
      "no-prune test score:  0.499422132331696\n",
      "post-prune from root validation score:  0.49399548532731374\n",
      "post-prune from root test score:  0.49956659924877206\n",
      "===================\n",
      "depth=8, post-prune=from leaf\n",
      "no-prune validation score:  0.48993227990970656\n",
      "no-prune test score:  0.499422132331696\n",
      "post-prune from leaf validation score:  0.49525959367945827\n",
      "post-prune from leaf test score:  0.49956659924877206\n",
      "===================\n",
      "depth=9, post-prune=from root\n",
      "no-prune validation score:  0.4883069977426637\n",
      "no-prune test score:  0.49631609361456225\n",
      "post-prune from root validation score:  0.49670428893905194\n",
      "post-prune from root test score:  0.5028171048829818\n",
      "===================\n",
      "depth=9, post-prune=from leaf\n",
      "no-prune validation score:  0.4883069977426637\n",
      "no-prune test score:  0.49631609361456225\n",
      "post-prune from leaf validation score:  0.4992325056433409\n",
      "post-prune from leaf test score:  0.500505634209766\n",
      "===================\n",
      "depth=10, post-prune=from root\n",
      "no-prune validation score:  0.4872234762979684\n",
      "no-prune test score:  0.49530482519503033\n",
      "post-prune from root validation score:  0.49516930022573363\n",
      "post-prune from root test score:  0.5032505056342098\n",
      "===================\n",
      "depth=10, post-prune=from leaf\n",
      "no-prune validation score:  0.4872234762979684\n",
      "no-prune test score:  0.49530482519503033\n",
      "post-prune from leaf validation score:  0.5009480812641084\n",
      "post-prune from leaf test score:  0.4985553308292401\n",
      "===================\n",
      "depth=11, post-prune=from root\n",
      "no-prune validation score:  0.48361173814898417\n",
      "no-prune test score:  0.49364345564865647\n",
      "post-prune from root validation score:  0.4944469525959368\n",
      "post-prune from root test score:  0.5\n",
      "===================\n",
      "depth=11, post-prune=from leaf\n",
      "no-prune validation score:  0.48361173814898417\n",
      "no-prune test score:  0.49364345564865647\n",
      "post-prune from leaf validation score:  0.503747178329571\n",
      "post-prune from leaf test score:  0.4971828951170182\n",
      "===================\n",
      "depth=12, post-prune=from root\n",
      "no-prune validation score:  0.47927765237020314\n",
      "no-prune test score:  0.4906818838485987\n",
      "post-prune from root validation score:  0.49589164785553047\n",
      "post-prune from root test score:  0.5005778676683039\n",
      "===================\n",
      "depth=12, post-prune=from leaf\n",
      "no-prune validation score:  0.47927765237020314\n",
      "no-prune test score:  0.4906818838485987\n",
      "post-prune from leaf validation score:  0.5079909706546275\n",
      "post-prune from leaf test score:  0.4960993932389483\n",
      "===================\n",
      "depth=13, post-prune=from root\n",
      "no-prune validation score:  0.4781038374717833\n",
      "no-prune test score:  0.4874313782143889\n",
      "post-prune from root validation score:  0.49688487584650115\n",
      "post-prune from root test score:  0.49949436579023404\n",
      "===================\n",
      "depth=13, post-prune=from leaf\n",
      "no-prune validation score:  0.4781038374717833\n",
      "no-prune test score:  0.4874313782143889\n",
      "post-prune from leaf validation score:  0.5121444695259594\n",
      "post-prune from leaf test score:  0.49479919098526437\n",
      "===================\n",
      "depth=14, post-prune=from root\n",
      "no-prune validation score:  0.4737697516930023\n",
      "no-prune test score:  0.48259173649234327\n",
      "post-prune from root validation score:  0.4914672686230248\n",
      "post-prune from root test score:  0.49241548685351055\n",
      "===================\n",
      "depth=14, post-prune=from leaf\n",
      "no-prune validation score:  0.4737697516930023\n",
      "no-prune test score:  0.48259173649234327\n",
      "post-prune from leaf validation score:  0.516117381489842\n",
      "post-prune from leaf test score:  0.4916209188095926\n",
      "===================\n",
      "depth=15, post-prune=from root\n",
      "no-prune validation score:  0.4672686230248307\n",
      "no-prune test score:  0.4755128575556198\n",
      "post-prune from root validation score:  0.48613995485327316\n",
      "post-prune from root test score:  0.4875758451314649\n",
      "===================\n",
      "depth=15, post-prune=from leaf\n",
      "no-prune validation score:  0.4672686230248307\n",
      "no-prune test score:  0.4755128575556198\n",
      "post-prune from leaf validation score:  0.52\n",
      "post-prune from leaf test score:  0.485914475585091\n",
      "===================\n",
      "depth=16, post-prune=from root\n",
      "no-prune validation score:  0.4654627539503386\n",
      "no-prune test score:  0.4709621496677261\n",
      "post-prune from root validation score:  0.48939051918735893\n",
      "post-prune from root test score:  0.49458249060965037\n",
      "===================\n",
      "depth=16, post-prune=from leaf\n",
      "no-prune validation score:  0.4654627539503386\n",
      "no-prune test score:  0.4709621496677261\n",
      "post-prune from leaf validation score:  0.5244243792325056\n",
      "post-prune from leaf test score:  0.4846865067899451\n",
      "===================\n",
      "depth=17, post-prune=from root\n",
      "no-prune validation score:  0.45914221218961626\n",
      "no-prune test score:  0.46568910719445245\n",
      "post-prune from root validation score:  0.48478555304740406\n",
      "post-prune from root test score:  0.48808147934123086\n",
      "===================\n",
      "depth=17, post-prune=from leaf\n",
      "no-prune validation score:  0.45914221218961626\n",
      "no-prune test score:  0.46568910719445245\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "post-prune from leaf validation score:  0.5272234762979684\n",
      "post-prune from leaf test score:  0.48129153423865934\n",
      "===================\n",
      "depth=18, post-prune=from root\n",
      "no-prune validation score:  0.45580135440180586\n",
      "no-prune test score:  0.46056053163825483\n",
      "post-prune from root validation score:  0.4817155756207675\n",
      "post-prune from root test score:  0.485842242126553\n",
      "===================\n",
      "depth=18, post-prune=from leaf\n",
      "no-prune validation score:  0.45580135440180586\n",
      "no-prune test score:  0.46056053163825483\n",
      "post-prune from leaf validation score:  0.531647855530474\n",
      "post-prune from leaf test score:  0.4775353943946836\n",
      "===================\n",
      "depth=19, post-prune=from root\n",
      "no-prune validation score:  0.4524604966139955\n",
      "no-prune test score:  0.458176827506501\n",
      "post-prune from root validation score:  0.4817155756207675\n",
      "post-prune from root test score:  0.485842242126553\n",
      "===================\n",
      "depth=19, post-prune=from leaf\n",
      "no-prune validation score:  0.4524604966139955\n",
      "no-prune test score:  0.458176827506501\n",
      "post-prune from leaf validation score:  0.5337246049661399\n",
      "post-prune from leaf test score:  0.4745015891360878\n",
      "===================\n",
      "depth=20, post-prune=from root\n",
      "no-prune validation score:  0.4461399548532731\n",
      "no-prune test score:  0.4543484542039873\n",
      "post-prune from root validation score:  0.4679909706546275\n",
      "post-prune from root test score:  0.47601849176538574\n",
      "===================\n",
      "depth=20, post-prune=from leaf\n",
      "no-prune validation score:  0.4461399548532731\n",
      "no-prune test score:  0.4543484542039873\n",
      "post-prune from leaf validation score:  0.535530474040632\n",
      "post-prune from leaf test score:  0.4731291534238659\n",
      "===================\n",
      "depth=21, post-prune=from root\n",
      "no-prune validation score:  0.44604966139954855\n",
      "no-prune test score:  0.4527593181161514\n",
      "post-prune from root validation score:  0.4679909706546275\n",
      "post-prune from root test score:  0.47601849176538574\n",
      "===================\n",
      "depth=21, post-prune=from leaf\n",
      "no-prune validation score:  0.44604966139954855\n",
      "no-prune test score:  0.4527593181161514\n",
      "post-prune from leaf validation score:  0.5360722347629797\n",
      "post-prune from leaf test score:  0.47226235192141\n",
      "===================\n",
      "depth=22, post-prune=from root\n",
      "no-prune validation score:  0.44650112866817154\n",
      "no-prune test score:  0.44994221323316963\n",
      "post-prune from root validation score:  0.4679909706546275\n",
      "post-prune from root test score:  0.47601849176538574\n",
      "===================\n",
      "depth=22, post-prune=from leaf\n",
      "no-prune validation score:  0.44650112866817154\n",
      "no-prune test score:  0.44994221323316963\n",
      "post-prune from leaf validation score:  0.5376975169300225\n",
      "post-prune from leaf test score:  0.4701675816238082\n",
      "===================\n",
      "depth=23, post-prune=from root\n",
      "no-prune validation score:  0.44623024830699776\n",
      "no-prune test score:  0.45037561398439757\n",
      "post-prune from root validation score:  0.4679909706546275\n",
      "post-prune from root test score:  0.47601849176538574\n",
      "===================\n",
      "depth=23, post-prune=from leaf\n",
      "no-prune validation score:  0.44623024830699776\n",
      "no-prune test score:  0.45037561398439757\n",
      "post-prune from leaf validation score:  0.5390519187358916\n",
      "post-prune from leaf test score:  0.4707454492921121\n",
      "===================\n",
      "depth=24, post-prune=from root\n",
      "no-prune validation score:  0.4427990970654628\n",
      "no-prune test score:  0.44820861022825775\n",
      "post-prune from root validation score:  0.4679909706546275\n",
      "post-prune from root test score:  0.47601849176538574\n",
      "===================\n",
      "depth=24, post-prune=from leaf\n",
      "no-prune validation score:  0.4427990970654628\n",
      "no-prune test score:  0.44820861022825775\n",
      "post-prune from leaf validation score:  0.5391422121896162\n",
      "post-prune from leaf test score:  0.4692285466628142\n",
      "===================\n",
      "depth=25, post-prune=from root\n",
      "no-prune validation score:  0.4418058690744921\n",
      "no-prune test score:  0.44770297601849174\n",
      "post-prune from root validation score:  0.4679909706546275\n",
      "post-prune from root test score:  0.47601849176538574\n",
      "===================\n",
      "depth=25, post-prune=from leaf\n",
      "no-prune validation score:  0.4418058690744921\n",
      "no-prune test score:  0.44770297601849174\n",
      "post-prune from leaf validation score:  0.5393227990970655\n",
      "post-prune from leaf test score:  0.4695897139555042\n",
      "===================\n",
      "depth=26, post-prune=from root\n",
      "no-prune validation score:  0.4396388261851016\n",
      "no-prune test score:  0.44661947414042186\n",
      "post-prune from root validation score:  0.4679909706546275\n",
      "post-prune from root test score:  0.47601849176538574\n",
      "===================\n",
      "depth=26, post-prune=from leaf\n",
      "no-prune validation score:  0.4396388261851016\n",
      "no-prune test score:  0.44661947414042186\n",
      "post-prune from leaf validation score:  0.5391422121896162\n",
      "post-prune from leaf test score:  0.47002311470673214\n",
      "===================\n",
      "depth=27, post-prune=from root\n",
      "no-prune validation score:  0.4388261851015801\n",
      "no-prune test score:  0.4468361745160358\n",
      "post-prune from root validation score:  0.4679909706546275\n",
      "post-prune from root test score:  0.47601849176538574\n",
      "===================\n",
      "depth=27, post-prune=from leaf\n",
      "no-prune validation score:  0.4388261851015801\n",
      "no-prune test score:  0.4468361745160358\n",
      "post-prune from leaf validation score:  0.5395033860045146\n",
      "post-prune from leaf test score:  0.46930078012135223\n",
      "===================\n",
      "depth=28, post-prune=from root\n",
      "no-prune validation score:  0.43954853273137695\n",
      "no-prune test score:  0.4459693730135799\n",
      "post-prune from root validation score:  0.4679909706546275\n",
      "post-prune from root test score:  0.47601849176538574\n",
      "===================\n",
      "depth=28, post-prune=from leaf\n",
      "no-prune validation score:  0.43954853273137695\n",
      "no-prune test score:  0.4459693730135799\n",
      "post-prune from leaf validation score:  0.5393227990970655\n",
      "post-prune from leaf test score:  0.46865067899451024\n",
      "===================\n",
      "depth=29, post-prune=from root\n",
      "no-prune validation score:  0.43927765237020316\n",
      "no-prune test score:  0.4459693730135799\n",
      "post-prune from root validation score:  0.4679909706546275\n",
      "post-prune from root test score:  0.47601849176538574\n",
      "===================\n",
      "depth=29, post-prune=from leaf\n",
      "no-prune validation score:  0.43927765237020316\n",
      "no-prune test score:  0.4459693730135799\n",
      "post-prune from leaf validation score:  0.5394130925507901\n",
      "post-prune from leaf test score:  0.46930078012135223\n",
      "*********************\n",
      "best_val=0.539503, best_val_depth=27, best_post_prune=from leaf\n"
     ]
    }
   ],
   "source": [
    "# pre prune + post prune\n",
    "best_val = 0\n",
    "best_val_depth = 0\n",
    "best_post_prune = \"\"\n",
    "for depth in range(1, 30):\n",
    "    dt = DecisionTreeClassifier(criterion=\"entropy\", max_depth=depth, random_state=4321)\n",
    "    dt.fit(X_train, y_train)\n",
    "    dt_val_score = dt.score(X_val, y_val)\n",
    "    print(\"===================\", \"depth=%d, post-prune=from root\" % depth, sep='\\n')\n",
    "    print(\"no-prune validation score: \", dt_val_score)\n",
    "    print(\"no-prune test score: \", dt.score(X_test, y_test))\n",
    "    prune_from_root(dt.tree_, 0)\n",
    "    val_score = dt.score(X_val, y_val)\n",
    "    print(\"post-prune from root validation score: \", val_score)\n",
    "    if val_score > best_val:\n",
    "        best_val = val_score\n",
    "        best_val_depth = depth\n",
    "        best_post_prune = \"from root\"\n",
    "    print(\"post-prune from root test score: \", dt.score(X_test, y_test))\n",
    "    \n",
    "    dt = DecisionTreeClassifier(criterion=\"entropy\", max_depth=depth, random_state=4321)\n",
    "    dt.fit(X_train, y_train)\n",
    "    dt_val_score = dt.score(X_val, y_val)\n",
    "    print(\"===================\", \"depth=%d, post-prune=from leaf\" % depth, sep='\\n')\n",
    "    print(\"no-prune validation score: \", dt_val_score)\n",
    "    print(\"no-prune test score: \", dt.score(X_test, y_test))\n",
    "    prune_from_leaf(dt.tree_, 0)\n",
    "    val_score = dt.score(X_val, y_val)\n",
    "    print(\"post-prune from leaf validation score: \", val_score)\n",
    "    if val_score >= best_val:\n",
    "        best_val = val_score\n",
    "        best_val_depth = depth\n",
    "        best_post_prune = \"from leaf\"\n",
    "    print(\"post-prune from leaf test score: \", dt.score(X_test, y_test))\n",
    "print(\"*********************\")\n",
    "print(\"best_val=%f, best_val_depth=%d, best_post_prune=%s\" % (best_val, best_val_depth, best_post_prune))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth=1, n_estimator=100, val_score=0.495711\n",
      "max_depth=1, n_estimator=200, val_score=0.498420\n",
      "max_depth=1, n_estimator=400, val_score=0.498420\n",
      "max_depth=1, n_estimator=1000, val_score=0.498691\n",
      "max_depth=2, n_estimator=100, val_score=0.496253\n",
      "max_depth=2, n_estimator=200, val_score=0.496524\n",
      "max_depth=2, n_estimator=400, val_score=0.496614\n",
      "max_depth=2, n_estimator=1000, val_score=0.494718\n",
      "max_depth=3, n_estimator=100, val_score=0.492641\n",
      "max_depth=3, n_estimator=200, val_score=0.490745\n",
      "max_depth=3, n_estimator=400, val_score=0.487404\n",
      "max_depth=3, n_estimator=1000, val_score=0.476840\n",
      "max_depth=4, n_estimator=100, val_score=0.482799\n",
      "max_depth=4, n_estimator=200, val_score=0.478555\n",
      "max_depth=4, n_estimator=400, val_score=0.467178\n",
      "max_depth=4, n_estimator=1000, val_score=0.456975\n",
      "max_depth=5, n_estimator=100, val_score=0.478104\n",
      "max_depth=5, n_estimator=200, val_score=0.466546\n",
      "max_depth=5, n_estimator=400, val_score=0.454086\n",
      "max_depth=5, n_estimator=1000, val_score=0.441264\n",
      "max_depth=6, n_estimator=100, val_score=0.459865\n",
      "max_depth=6, n_estimator=200, val_score=0.448668\n",
      "max_depth=6, n_estimator=400, val_score=0.439187\n",
      "max_depth=6, n_estimator=1000, val_score=0.440271\n",
      "max_depth=7, n_estimator=100, val_score=0.444695\n",
      "max_depth=7, n_estimator=200, val_score=0.444063\n",
      "max_depth=7, n_estimator=400, val_score=0.441084\n",
      "max_depth=7, n_estimator=1000, val_score=0.436298\n",
      "max_depth=8, n_estimator=100, val_score=0.440722\n",
      "max_depth=8, n_estimator=200, val_score=0.445418\n",
      "max_depth=8, n_estimator=400, val_score=0.439729\n",
      "max_depth=8, n_estimator=1000, val_score=0.438646\n",
      "max_depth=9, n_estimator=100, val_score=0.436659\n",
      "max_depth=9, n_estimator=200, val_score=0.440451\n",
      "max_depth=9, n_estimator=400, val_score=0.441806\n",
      "max_depth=9, n_estimator=1000, val_score=0.441716\n",
      "Best validation score:  0.49869074492099325\n",
      "Best depth:  1\n",
      "Best estimators:  1000\n",
      "Test score:  0.5017336030049119\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "best_val = 0\n",
    "best_depth = 0\n",
    "best_n_estimators = 0\n",
    "for depth in range(1, 10):\n",
    "    for n_estimators in [100, 200, 400, 1000]:\n",
    "        ada_dt = DecisionTreeClassifier(criterion=\"entropy\", max_depth=depth)\n",
    "        adaboost = AdaBoostClassifier(base_estimator=ada_dt, n_estimators=n_estimators)\n",
    "        adaboost.fit(X_train,y_train)\n",
    "        val_score = adaboost.score(X_val,y_val)\n",
    "        print(\"max_depth=%d, n_estimator=%d, val_score=%f\" % (depth, n_estimators, val_score))\n",
    "        if val_score > best_val:\n",
    "            best_val = val_score\n",
    "            best_depth = depth\n",
    "            best_n_estimators = n_estimators\n",
    "            \n",
    "print(\"Best validation score: \", best_val)\n",
    "print(\"Best depth: \", best_depth)\n",
    "print(\"Best estimators: \", best_n_estimators)\n",
    "ada_dt = DecisionTreeClassifier(criterion=\"entropy\", max_depth=best_depth)\n",
    "adaboost = AdaBoostClassifier(base_estimator=ada_dt, n_estimators=best_n_estimators)\n",
    "adaboost.fit(X_train,y_train)\n",
    "test_score = adaboost.score(X_test, y_test)\n",
    "print(\"Test score: \", test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score:  0.5020947702976019\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ada_dt = DecisionTreeClassifier(criterion=\"entropy\", max_depth=1)\n",
    "adaboost = AdaBoostClassifier(base_estimator=ada_dt, n_estimators=2000)\n",
    "adaboost.fit(X_train,y_train)\n",
    "test_score = adaboost.score(X_test, y_test)\n",
    "print(\"Test score: \", test_score)\n",
    "\n",
    "train_mid_error = []\n",
    "for mid_predict in adaboost.staged_predict(X_train):\n",
    "    train_mid_error.append(1 - accuracy_score(mid_predict, y_train))\n",
    "val_mid_error = []\n",
    "for mid_predict in adaboost.staged_predict(X_val):\n",
    "    val_mid_error.append(1 - accuracy_score(mid_predict, y_val))\n",
    "\n",
    "number_of_predict = len(val_mid_error)\n",
    "train_mid_error = train_mid_error[:number_of_predict]\n",
    "\n",
    "plt.plot(range(1, number_of_predict + 1),\n",
    "         val_mid_error, label='Validation')\n",
    "plt.plot(range(1, number_of_predict + 1),\n",
    "         train_mid_error, label='Train')\n",
    "plt.legend()\n",
    "plt.ylabel('Error')\n",
    "plt.xlabel('Number of Trees')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Casualty_Class</th>\n",
       "      <th>Sex_of_Casualty</th>\n",
       "      <th>Age_of_Casualty</th>\n",
       "      <th>Age_Band_of_Casualty</th>\n",
       "      <th>Casualty_Severity</th>\n",
       "      <th>Pedestrian_Location</th>\n",
       "      <th>Pedestrian_Movement</th>\n",
       "      <th>Car_Passenger</th>\n",
       "      <th>Bus_or_Coach_Passenger</th>\n",
       "      <th>Pedestrian_Road_Maintenance_Worker</th>\n",
       "      <th>Casualty_Type</th>\n",
       "      <th>Casualty_Home_Area_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2187726</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498445</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43972</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>9</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1062340</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489502</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Casualty_Class  Sex_of_Casualty  Age_of_Casualty  \\\n",
       "2187726               1                1               38   \n",
       "498445                1                1               27   \n",
       "43972                 1                1               24   \n",
       "1062340               1                1               12   \n",
       "489502                1                1               16   \n",
       "\n",
       "         Age_Band_of_Casualty  Casualty_Severity  Pedestrian_Location  \\\n",
       "2187726                     7                  1                    0   \n",
       "498445                      6                  3                    0   \n",
       "43972                       5                  2                    0   \n",
       "1062340                     3                  3                    0   \n",
       "489502                      4                  1                    0   \n",
       "\n",
       "         Pedestrian_Movement  Car_Passenger  Bus_or_Coach_Passenger  \\\n",
       "2187726                    0              0                       0   \n",
       "498445                     0              0                       0   \n",
       "43972                      0              0                       0   \n",
       "1062340                    0              0                       0   \n",
       "489502                     0              0                       0   \n",
       "\n",
       "         Pedestrian_Road_Maintenance_Worker  Casualty_Type  \\\n",
       "2187726                                   0              5   \n",
       "498445                                   -1              5   \n",
       "43972                                    -1              9   \n",
       "1062340                                  -1              1   \n",
       "489502                                   -1              2   \n",
       "\n",
       "         Casualty_Home_Area_Type  \n",
       "2187726                        2  \n",
       "498445                         1  \n",
       "43972                         -1  \n",
       "1062340                        1  \n",
       "489502                         2  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('../HW1_data/traffic/Casualties0514.csv')\n",
    "dataset.head()\n",
    "# dataset.groupby(\"Casualty_Severity\").count()\n",
    "fatal_dataset = dataset[dataset[\"Casualty_Severity\"]==1]\n",
    "num_fatal = fatal_dataset.shape[0]\n",
    "serious_dataset = dataset[dataset[\"Casualty_Severity\"]==2].sample(n=num_fatal, random_state=35674, axis=0)\n",
    "slight_dataset = dataset[dataset[\"Casualty_Severity\"]==3].sample(n=num_fatal, random_state=25442, axis=0)\n",
    "dataset = pd.concat([fatal_dataset, serious_dataset, slight_dataset],axis=0)\n",
    "del fatal_dataset, serious_dataset, slight_dataset\n",
    "dataset = dataset.drop([\"Accident_Index\", \"Vehicle_Reference\", \"Casualty_Reference\"], axis=1)\n",
    "dataset = dataset.sample(frac=1, axis=0)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age_of_Casualty</th>\n",
       "      <th>Casualty_Severity</th>\n",
       "      <th>Casualty_Class_1</th>\n",
       "      <th>Casualty_Class_2</th>\n",
       "      <th>Casualty_Class_3</th>\n",
       "      <th>Sex_of_Casualty_1</th>\n",
       "      <th>Sex_of_Casualty_2</th>\n",
       "      <th>Age_Band_of_Casualty_1</th>\n",
       "      <th>Age_Band_of_Casualty_2</th>\n",
       "      <th>Age_Band_of_Casualty_3</th>\n",
       "      <th>...</th>\n",
       "      <th>Casualty_Type_18</th>\n",
       "      <th>Casualty_Type_19</th>\n",
       "      <th>Casualty_Type_20</th>\n",
       "      <th>Casualty_Type_21</th>\n",
       "      <th>Casualty_Type_22</th>\n",
       "      <th>Casualty_Type_90</th>\n",
       "      <th>Casualty_Type_97</th>\n",
       "      <th>Casualty_Home_Area_Type_1</th>\n",
       "      <th>Casualty_Home_Area_Type_2</th>\n",
       "      <th>Casualty_Home_Area_Type_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2187726</th>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498445</th>\n",
       "      <td>27</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43972</th>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1062340</th>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489502</th>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  72 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Age_of_Casualty  Casualty_Severity  Casualty_Class_1  \\\n",
       "2187726               38                  1                 1   \n",
       "498445                27                  3                 1   \n",
       "43972                 24                  2                 1   \n",
       "1062340               12                  3                 1   \n",
       "489502                16                  1                 1   \n",
       "\n",
       "         Casualty_Class_2  Casualty_Class_3  Sex_of_Casualty_1  \\\n",
       "2187726                 0                 0                  1   \n",
       "498445                  0                 0                  1   \n",
       "43972                   0                 0                  1   \n",
       "1062340                 0                 0                  1   \n",
       "489502                  0                 0                  1   \n",
       "\n",
       "         Sex_of_Casualty_2  Age_Band_of_Casualty_1  Age_Band_of_Casualty_2  \\\n",
       "2187726                  0                       0                       0   \n",
       "498445                   0                       0                       0   \n",
       "43972                    0                       0                       0   \n",
       "1062340                  0                       0                       0   \n",
       "489502                   0                       0                       0   \n",
       "\n",
       "         Age_Band_of_Casualty_3            ...              Casualty_Type_18  \\\n",
       "2187726                       0            ...                             0   \n",
       "498445                        0            ...                             0   \n",
       "43972                         0            ...                             0   \n",
       "1062340                       1            ...                             0   \n",
       "489502                        0            ...                             0   \n",
       "\n",
       "         Casualty_Type_19  Casualty_Type_20  Casualty_Type_21  \\\n",
       "2187726                 0                 0                 0   \n",
       "498445                  0                 0                 0   \n",
       "43972                   0                 0                 0   \n",
       "1062340                 0                 0                 0   \n",
       "489502                  0                 0                 0   \n",
       "\n",
       "         Casualty_Type_22  Casualty_Type_90  Casualty_Type_97  \\\n",
       "2187726                 0                 0                 0   \n",
       "498445                  0                 0                 0   \n",
       "43972                   0                 0                 0   \n",
       "1062340                 0                 0                 0   \n",
       "489502                  0                 0                 0   \n",
       "\n",
       "         Casualty_Home_Area_Type_1  Casualty_Home_Area_Type_2  \\\n",
       "2187726                          0                          1   \n",
       "498445                           1                          0   \n",
       "43972                            0                          0   \n",
       "1062340                          1                          0   \n",
       "489502                           0                          1   \n",
       "\n",
       "         Casualty_Home_Area_Type_3  \n",
       "2187726                          0  \n",
       "498445                           0  \n",
       "43972                            0  \n",
       "1062340                          0  \n",
       "489502                           0  \n",
       "\n",
       "[5 rows x 72 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for col in [\"Casualty_Class\", \"Sex_of_Casualty\", \"Age_Band_of_Casualty\", \"Pedestrian_Location\", \"Pedestrian_Movement\", \"Car_Passenger\", \"Bus_or_Coach_Passenger\", \"Pedestrian_Road_Maintenance_Worker\", \"Casualty_Type\", \"Casualty_Home_Area_Type\"]: \n",
    "    need_remove_non = False\n",
    "    if dataset[col].min() < 0:\n",
    "        need_remove_non = True\n",
    "    dataset = pd.concat([dataset,pd.get_dummies(dataset[col], prefix=col)],axis=1).drop([col],axis=1)\n",
    "    if need_remove_non:\n",
    "        dataset = dataset.drop([col+\"_-1\"], axis=1)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Age_of_Casualty', 'Casualty_Severity', 'Casualty_Class_1',\n",
       "       'Casualty_Class_2', 'Casualty_Class_3', 'Sex_of_Casualty_1',\n",
       "       'Sex_of_Casualty_2', 'Age_Band_of_Casualty_1', 'Age_Band_of_Casualty_2',\n",
       "       'Age_Band_of_Casualty_3', 'Age_Band_of_Casualty_4',\n",
       "       'Age_Band_of_Casualty_5', 'Age_Band_of_Casualty_6',\n",
       "       'Age_Band_of_Casualty_7', 'Age_Band_of_Casualty_8',\n",
       "       'Age_Band_of_Casualty_9', 'Age_Band_of_Casualty_10',\n",
       "       'Age_Band_of_Casualty_11', 'Pedestrian_Location_0',\n",
       "       'Pedestrian_Location_1', 'Pedestrian_Location_2',\n",
       "       'Pedestrian_Location_3', 'Pedestrian_Location_4',\n",
       "       'Pedestrian_Location_5', 'Pedestrian_Location_6',\n",
       "       'Pedestrian_Location_7', 'Pedestrian_Location_8',\n",
       "       'Pedestrian_Location_9', 'Pedestrian_Location_10',\n",
       "       'Pedestrian_Movement_0', 'Pedestrian_Movement_1',\n",
       "       'Pedestrian_Movement_2', 'Pedestrian_Movement_3',\n",
       "       'Pedestrian_Movement_4', 'Pedestrian_Movement_5',\n",
       "       'Pedestrian_Movement_6', 'Pedestrian_Movement_7',\n",
       "       'Pedestrian_Movement_8', 'Pedestrian_Movement_9', 'Car_Passenger_0',\n",
       "       'Car_Passenger_1', 'Car_Passenger_2', 'Bus_or_Coach_Passenger_0',\n",
       "       'Bus_or_Coach_Passenger_1', 'Bus_or_Coach_Passenger_2',\n",
       "       'Bus_or_Coach_Passenger_3', 'Bus_or_Coach_Passenger_4',\n",
       "       'Pedestrian_Road_Maintenance_Worker_0',\n",
       "       'Pedestrian_Road_Maintenance_Worker_1',\n",
       "       'Pedestrian_Road_Maintenance_Worker_2', 'Casualty_Type_0',\n",
       "       'Casualty_Type_1', 'Casualty_Type_2', 'Casualty_Type_3',\n",
       "       'Casualty_Type_4', 'Casualty_Type_5', 'Casualty_Type_8',\n",
       "       'Casualty_Type_9', 'Casualty_Type_10', 'Casualty_Type_11',\n",
       "       'Casualty_Type_16', 'Casualty_Type_17', 'Casualty_Type_18',\n",
       "       'Casualty_Type_19', 'Casualty_Type_20', 'Casualty_Type_21',\n",
       "       'Casualty_Type_22', 'Casualty_Type_90', 'Casualty_Type_97',\n",
       "       'Casualty_Home_Area_Type_1', 'Casualty_Home_Area_Type_2',\n",
       "       'Casualty_Home_Area_Type_3'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = dataset.drop([\"Casualty_Severity\"], axis=1)\n",
    "y = dataset[\"Casualty_Severity\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(69216, 71)\n",
      "(69216,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(44297, 71)\n",
      "(11075, 71)\n",
      "(13844, 71)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=6357)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=6357)\n",
    "del X, y\n",
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age_of_Casualty</th>\n",
       "      <th>Casualty_Class_1</th>\n",
       "      <th>Casualty_Class_2</th>\n",
       "      <th>Casualty_Class_3</th>\n",
       "      <th>Sex_of_Casualty_1</th>\n",
       "      <th>Sex_of_Casualty_2</th>\n",
       "      <th>Age_Band_of_Casualty_1</th>\n",
       "      <th>Age_Band_of_Casualty_2</th>\n",
       "      <th>Age_Band_of_Casualty_3</th>\n",
       "      <th>Age_Band_of_Casualty_4</th>\n",
       "      <th>...</th>\n",
       "      <th>Casualty_Type_18</th>\n",
       "      <th>Casualty_Type_19</th>\n",
       "      <th>Casualty_Type_20</th>\n",
       "      <th>Casualty_Type_21</th>\n",
       "      <th>Casualty_Type_22</th>\n",
       "      <th>Casualty_Type_90</th>\n",
       "      <th>Casualty_Type_97</th>\n",
       "      <th>Casualty_Home_Area_Type_1</th>\n",
       "      <th>Casualty_Home_Area_Type_2</th>\n",
       "      <th>Casualty_Home_Area_Type_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>44297.000000</td>\n",
       "      <td>44297.000000</td>\n",
       "      <td>44297.000000</td>\n",
       "      <td>44297.000000</td>\n",
       "      <td>44297.000000</td>\n",
       "      <td>44297.000000</td>\n",
       "      <td>44297.000000</td>\n",
       "      <td>44297.000000</td>\n",
       "      <td>44297.000000</td>\n",
       "      <td>44297.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>44297.000000</td>\n",
       "      <td>44297.000000</td>\n",
       "      <td>44297.000000</td>\n",
       "      <td>44297.000000</td>\n",
       "      <td>44297.000000</td>\n",
       "      <td>44297.00000</td>\n",
       "      <td>44297.000000</td>\n",
       "      <td>44297.000000</td>\n",
       "      <td>44297.000000</td>\n",
       "      <td>44297.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>37.622503</td>\n",
       "      <td>0.613879</td>\n",
       "      <td>0.198614</td>\n",
       "      <td>0.187507</td>\n",
       "      <td>0.667133</td>\n",
       "      <td>0.332709</td>\n",
       "      <td>0.014493</td>\n",
       "      <td>0.021356</td>\n",
       "      <td>0.043276</td>\n",
       "      <td>0.145021</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.019098</td>\n",
       "      <td>0.002732</td>\n",
       "      <td>0.007066</td>\n",
       "      <td>0.000384</td>\n",
       "      <td>0.00596</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>0.622299</td>\n",
       "      <td>0.090029</td>\n",
       "      <td>0.122627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>20.874821</td>\n",
       "      <td>0.486864</td>\n",
       "      <td>0.398961</td>\n",
       "      <td>0.390322</td>\n",
       "      <td>0.471245</td>\n",
       "      <td>0.471189</td>\n",
       "      <td>0.119513</td>\n",
       "      <td>0.144569</td>\n",
       "      <td>0.203480</td>\n",
       "      <td>0.352126</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006719</td>\n",
       "      <td>0.136872</td>\n",
       "      <td>0.052194</td>\n",
       "      <td>0.083763</td>\n",
       "      <td>0.019587</td>\n",
       "      <td>0.07697</td>\n",
       "      <td>0.010624</td>\n",
       "      <td>0.484818</td>\n",
       "      <td>0.286226</td>\n",
       "      <td>0.328012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>34.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>51.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>99.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows  71 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Age_of_Casualty  Casualty_Class_1  Casualty_Class_2  Casualty_Class_3  \\\n",
       "count     44297.000000      44297.000000      44297.000000      44297.000000   \n",
       "mean         37.622503          0.613879          0.198614          0.187507   \n",
       "std          20.874821          0.486864          0.398961          0.390322   \n",
       "min          -1.000000          0.000000          0.000000          0.000000   \n",
       "25%          21.000000          0.000000          0.000000          0.000000   \n",
       "50%          34.000000          1.000000          0.000000          0.000000   \n",
       "75%          51.000000          1.000000          0.000000          0.000000   \n",
       "max          99.000000          1.000000          1.000000          1.000000   \n",
       "\n",
       "       Sex_of_Casualty_1  Sex_of_Casualty_2  Age_Band_of_Casualty_1  \\\n",
       "count       44297.000000       44297.000000            44297.000000   \n",
       "mean            0.667133           0.332709                0.014493   \n",
       "std             0.471245           0.471189                0.119513   \n",
       "min             0.000000           0.000000                0.000000   \n",
       "25%             0.000000           0.000000                0.000000   \n",
       "50%             1.000000           0.000000                0.000000   \n",
       "75%             1.000000           1.000000                0.000000   \n",
       "max             1.000000           1.000000                1.000000   \n",
       "\n",
       "       Age_Band_of_Casualty_2  Age_Band_of_Casualty_3  Age_Band_of_Casualty_4  \\\n",
       "count            44297.000000            44297.000000            44297.000000   \n",
       "mean                 0.021356                0.043276                0.145021   \n",
       "std                  0.144569                0.203480                0.352126   \n",
       "min                  0.000000                0.000000                0.000000   \n",
       "25%                  0.000000                0.000000                0.000000   \n",
       "50%                  0.000000                0.000000                0.000000   \n",
       "75%                  0.000000                0.000000                0.000000   \n",
       "max                  1.000000                1.000000                1.000000   \n",
       "\n",
       "                 ...              Casualty_Type_18  Casualty_Type_19  \\\n",
       "count            ...                  44297.000000      44297.000000   \n",
       "mean             ...                      0.000045          0.019098   \n",
       "std              ...                      0.006719          0.136872   \n",
       "min              ...                      0.000000          0.000000   \n",
       "25%              ...                      0.000000          0.000000   \n",
       "50%              ...                      0.000000          0.000000   \n",
       "75%              ...                      0.000000          0.000000   \n",
       "max              ...                      1.000000          1.000000   \n",
       "\n",
       "       Casualty_Type_20  Casualty_Type_21  Casualty_Type_22  Casualty_Type_90  \\\n",
       "count      44297.000000      44297.000000      44297.000000       44297.00000   \n",
       "mean           0.002732          0.007066          0.000384           0.00596   \n",
       "std            0.052194          0.083763          0.019587           0.07697   \n",
       "min            0.000000          0.000000          0.000000           0.00000   \n",
       "25%            0.000000          0.000000          0.000000           0.00000   \n",
       "50%            0.000000          0.000000          0.000000           0.00000   \n",
       "75%            0.000000          0.000000          0.000000           0.00000   \n",
       "max            1.000000          1.000000          1.000000           1.00000   \n",
       "\n",
       "       Casualty_Type_97  Casualty_Home_Area_Type_1  Casualty_Home_Area_Type_2  \\\n",
       "count      44297.000000               44297.000000               44297.000000   \n",
       "mean           0.000113                   0.622299                   0.090029   \n",
       "std            0.010624                   0.484818                   0.286226   \n",
       "min            0.000000                   0.000000                   0.000000   \n",
       "25%            0.000000                   0.000000                   0.000000   \n",
       "50%            0.000000                   1.000000                   0.000000   \n",
       "75%            0.000000                   1.000000                   0.000000   \n",
       "max            1.000000                   1.000000                   1.000000   \n",
       "\n",
       "       Casualty_Home_Area_Type_3  \n",
       "count               44297.000000  \n",
       "mean                    0.122627  \n",
       "std                     0.328012  \n",
       "min                     0.000000  \n",
       "25%                     0.000000  \n",
       "50%                     0.000000  \n",
       "75%                     0.000000  \n",
       "max                     1.000000  \n",
       "\n",
       "[8 rows x 71 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first_layer=100, activation=identity, val_score=0.479910\n",
      "first_layer=100, activation=logistic, val_score=0.499594\n",
      "first_layer=100, activation=tanh, val_score=0.499774\n",
      "first_layer=100, activation=relu, val_score=0.500677\n",
      "first_layer=100, second_layer=100, activation=identity, val_score=0.496795\n",
      "first_layer=100, second_layer=100, activation=logistic, val_score=0.501129\n",
      "first_layer=100, second_layer=100, activation=tanh, val_score=0.487946\n",
      "first_layer=100, second_layer=100, activation=relu, val_score=0.483883\n",
      "first_layer=100, second_layer=200, activation=identity, val_score=0.489120\n",
      "first_layer=100, second_layer=200, activation=logistic, val_score=0.501851\n",
      "first_layer=100, second_layer=200, activation=tanh, val_score=0.499594\n",
      "first_layer=100, second_layer=200, activation=relu, val_score=0.487133\n",
      "first_layer=100, second_layer=300, activation=identity, val_score=0.472957\n",
      "first_layer=100, second_layer=300, activation=logistic, val_score=0.489120\n",
      "first_layer=100, second_layer=300, activation=tanh, val_score=0.501129\n",
      "first_layer=100, second_layer=300, activation=relu, val_score=0.496433\n",
      "first_layer=200, activation=identity, val_score=0.449120\n",
      "first_layer=200, activation=logistic, val_score=0.495892\n",
      "first_layer=200, activation=tanh, val_score=0.500587\n",
      "first_layer=200, activation=relu, val_score=0.486501\n",
      "first_layer=200, second_layer=100, activation=identity, val_score=0.485779\n",
      "first_layer=200, second_layer=100, activation=logistic, val_score=0.500767\n",
      "first_layer=200, second_layer=100, activation=tanh, val_score=0.500135\n",
      "first_layer=200, second_layer=100, activation=relu, val_score=0.486772\n",
      "first_layer=200, second_layer=200, activation=identity, val_score=0.492731\n",
      "first_layer=200, second_layer=200, activation=logistic, val_score=0.501670\n",
      "first_layer=200, second_layer=200, activation=tanh, val_score=0.500497\n",
      "first_layer=200, second_layer=200, activation=relu, val_score=0.496343\n",
      "first_layer=200, second_layer=300, activation=identity, val_score=0.494266\n",
      "first_layer=200, second_layer=300, activation=logistic, val_score=0.499865\n",
      "first_layer=200, second_layer=300, activation=tanh, val_score=0.502483\n",
      "first_layer=200, second_layer=300, activation=relu, val_score=0.501670\n",
      "first_layer=300, activation=identity, val_score=0.484876\n",
      "first_layer=300, activation=logistic, val_score=0.498871\n",
      "first_layer=300, activation=tanh, val_score=0.500135\n",
      "first_layer=300, activation=relu, val_score=0.492641\n",
      "first_layer=300, second_layer=100, activation=identity, val_score=0.497246\n",
      "first_layer=300, second_layer=100, activation=logistic, val_score=0.500677\n",
      "first_layer=300, second_layer=100, activation=tanh, val_score=0.501219\n",
      "first_layer=300, second_layer=100, activation=relu, val_score=0.481264\n",
      "first_layer=300, second_layer=200, activation=identity, val_score=0.497156\n",
      "first_layer=300, second_layer=200, activation=logistic, val_score=0.499413\n",
      "first_layer=300, second_layer=200, activation=tanh, val_score=0.500677\n",
      "first_layer=300, second_layer=200, activation=relu, val_score=0.476117\n",
      "first_layer=300, second_layer=300, activation=identity, val_score=0.497427\n",
      "first_layer=300, second_layer=300, activation=logistic, val_score=0.500316\n",
      "first_layer=300, second_layer=300, activation=tanh, val_score=0.490113\n",
      "first_layer=300, second_layer=300, activation=relu, val_score=0.472777\n",
      "0.5024830699774266\n",
      "(200, 300)\n",
      "tanh\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5018058364634499"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "best_val = 0\n",
    "best_layer = (0)\n",
    "best_activation = \"\"\n",
    "for first_layer in range(100, 301, 100):\n",
    "    for activation in ['identity', 'logistic', 'tanh', 'relu']:\n",
    "        mlp = MLPClassifier(hidden_layer_sizes=(first_layer), activation=activation, max_iter=1000)\n",
    "        mlp.fit(X_train, y_train)\n",
    "        val_score = mlp.score(X_val, y_val)\n",
    "        print(\"first_layer=%d, activation=%s, val_score=%f\" % (first_layer, activation, val_score))\n",
    "        if val_score > best_val:\n",
    "            best_val = val_score\n",
    "            best_layer = (first_layer)\n",
    "            best_activation = activation\n",
    "    for second_layer in range(100, 301, 100):\n",
    "        for activation in ['identity', 'logistic', 'tanh', 'relu']:\n",
    "            mlp = MLPClassifier(hidden_layer_sizes=(first_layer, second_layer), activation=activation, max_iter=1000)\n",
    "            mlp.fit(X_train, y_train)\n",
    "            val_score = mlp.score(X_val, y_val)\n",
    "            print(\"first_layer=%d, second_layer=%d, activation=%s, val_score=%f\" % (first_layer, second_layer, activation, val_score))\n",
    "            if val_score > best_val:\n",
    "                best_val = val_score\n",
    "                best_layer = (first_layer, second_layer)\n",
    "                best_activation = activation\n",
    "\n",
    "print(best_val)\n",
    "print(best_layer)\n",
    "print(best_activation)\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(best_layer), activation=best_activation, max_iter=1000)\n",
    "mlp.fit(X_train, y_train)\n",
    "mlp.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C=0.017016, val_score=0.503025\n",
      "C=0.009832, val_score=0.503567\n",
      "C=0.030914, val_score=0.502573\n",
      "C=0.022152, val_score=0.502935\n",
      "C=123.472334, val_score=0.341580\n",
      "C=30.268342, val_score=0.341038\n",
      "C=30.769953, val_score=0.361625\n",
      "C=35.780220, val_score=0.331648\n",
      "C=0.679693, val_score=0.496975\n",
      "C=22.344992, val_score=0.401986\n",
      "C=0.552051, val_score=0.386637\n",
      "C=2.928661, val_score=0.428533\n",
      "C=6.792751, val_score=0.373815\n",
      "C=1.680424, val_score=0.358736\n",
      "C=107.719136, val_score=0.326953\n",
      "C=0.531973, val_score=0.393318\n",
      "C=0.893940, val_score=0.458420\n",
      "C=0.010707, val_score=0.503386\n",
      "C=0.016990, val_score=0.502844\n",
      "C=1.646754, val_score=0.482619\n",
      "C=3.243688, val_score=0.467720\n",
      "C=0.010618, val_score=0.503567\n",
      "C=4.975460, val_score=0.353499\n",
      "C=0.062937, val_score=0.502664\n",
      "C=5.851849, val_score=0.377517\n",
      "C=30.596189, val_score=0.417788\n",
      "C=0.022831, val_score=0.502754\n",
      "C=0.111749, val_score=0.503205\n",
      "C=27.370081, val_score=0.458962\n",
      "C=39.521140, val_score=0.469977\n",
      "C=0.856100, val_score=0.430880\n",
      "C=78.430274, val_score=0.369391\n",
      "C=0.105863, val_score=0.476388\n",
      "C=2.701365, val_score=0.492641\n",
      "C=110.409716, val_score=0.347720\n",
      "C=0.029726, val_score=0.503928\n",
      "C=7.768340, val_score=0.422844\n",
      "C=32.065507, val_score=0.429797\n",
      "C=0.303804, val_score=0.474582\n",
      "C=8.295939, val_score=0.393499\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f82f0c4f550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best validation score:  0.5039277652370203\n",
      "Best C:  0.029725770708089135\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from random import random\n",
    "\n",
    "best_val = 0\n",
    "best_C = 0\n",
    "all_C_val_score = []\n",
    "all_C = []\n",
    "for i in range(40):\n",
    "    log_C = random() * 10 - 5\n",
    "    C = np.exp(log_C)\n",
    "    clf = svm.LinearSVC(C=C, multi_class=\"ovr\")\n",
    "    clf.fit(X_train,y_train)\n",
    "    val_score = clf.score(X_val,y_val)\n",
    "    print(\"C=%f, val_score=%f\" % (C, val_score))\n",
    "    if val_score > best_val:\n",
    "        best_val = val_score\n",
    "        best_C = C\n",
    "    all_C.append(C)\n",
    "    all_C_val_score.append(val_score)\n",
    "\n",
    "plt.scatter(all_C, all_C_val_score)\n",
    "plt.show()\n",
    "print(\"Best validation score: \", best_val)\n",
    "print(\"Best C: \", best_C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score:  0.49776076278532216\n"
     ]
    }
   ],
   "source": [
    "clf = svm.LinearSVC(C=best_C, multi_class=\"ovr\")\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"Test score: \", clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=-1, n_neighbors=9, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=9, n_jobs=-1)\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.44604966139954855"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n=1, weights=uniform, metric=euclidean, val_score=0.406050\n",
      "n=1, weights=uniform, metric=manhattan, val_score=0.406501\n",
      "n=1, weights=uniform, metric=chebyshev, val_score=0.397111\n",
      "n=1, weights=uniform, metric=minkowski, val_score=0.406050\n",
      "n=1, weights=distance, metric=euclidean, val_score=0.406050\n",
      "n=1, weights=distance, metric=manhattan, val_score=0.406501\n",
      "n=1, weights=distance, metric=chebyshev, val_score=0.397111\n",
      "n=1, weights=distance, metric=minkowski, val_score=0.406050\n",
      "n=2, weights=uniform, metric=euclidean, val_score=0.401716\n",
      "n=2, weights=uniform, metric=manhattan, val_score=0.401716\n",
      "n=2, weights=uniform, metric=chebyshev, val_score=0.391874\n",
      "n=2, weights=uniform, metric=minkowski, val_score=0.401716\n",
      "n=2, weights=distance, metric=euclidean, val_score=0.397833\n",
      "n=2, weights=distance, metric=manhattan, val_score=0.398104\n",
      "n=2, weights=distance, metric=chebyshev, val_score=0.392415\n",
      "n=2, weights=distance, metric=minkowski, val_score=0.397833\n",
      "n=3, weights=uniform, metric=euclidean, val_score=0.422483\n",
      "n=3, weights=uniform, metric=manhattan, val_score=0.423296\n",
      "n=3, weights=uniform, metric=chebyshev, val_score=0.404334\n",
      "n=3, weights=uniform, metric=minkowski, val_score=0.422483\n",
      "n=3, weights=distance, metric=euclidean, val_score=0.415530\n",
      "n=3, weights=distance, metric=manhattan, val_score=0.415621\n",
      "n=3, weights=distance, metric=chebyshev, val_score=0.407223\n",
      "n=3, weights=distance, metric=minkowski, val_score=0.415530\n",
      "n=4, weights=uniform, metric=euclidean, val_score=0.431964\n",
      "n=4, weights=uniform, metric=manhattan, val_score=0.431783\n",
      "n=4, weights=uniform, metric=chebyshev, val_score=0.407223\n",
      "n=4, weights=uniform, metric=minkowski, val_score=0.431964\n",
      "n=4, weights=distance, metric=euclidean, val_score=0.424831\n",
      "n=4, weights=distance, metric=manhattan, val_score=0.423928\n",
      "n=4, weights=distance, metric=chebyshev, val_score=0.411377\n",
      "n=4, weights=distance, metric=minkowski, val_score=0.424831\n",
      "n=5, weights=uniform, metric=euclidean, val_score=0.431061\n",
      "n=5, weights=uniform, metric=manhattan, val_score=0.431332\n",
      "n=5, weights=uniform, metric=chebyshev, val_score=0.404063\n",
      "n=5, weights=uniform, metric=minkowski, val_score=0.431061\n",
      "n=5, weights=distance, metric=euclidean, val_score=0.421129\n",
      "n=5, weights=distance, metric=manhattan, val_score=0.422032\n",
      "n=5, weights=distance, metric=chebyshev, val_score=0.409391\n",
      "n=5, weights=distance, metric=minkowski, val_score=0.421129\n",
      "n=6, weights=uniform, metric=euclidean, val_score=0.440451\n",
      "n=6, weights=uniform, metric=manhattan, val_score=0.440542\n",
      "n=6, weights=uniform, metric=chebyshev, val_score=0.415079\n",
      "n=6, weights=uniform, metric=minkowski, val_score=0.440451\n",
      "n=6, weights=distance, metric=euclidean, val_score=0.431422\n",
      "n=6, weights=distance, metric=manhattan, val_score=0.431874\n",
      "n=6, weights=distance, metric=chebyshev, val_score=0.417246\n",
      "n=6, weights=distance, metric=minkowski, val_score=0.431422\n",
      "n=7, weights=uniform, metric=euclidean, val_score=0.447133\n",
      "n=7, weights=uniform, metric=manhattan, val_score=0.447404\n",
      "n=7, weights=uniform, metric=chebyshev, val_score=0.419052\n",
      "n=7, weights=uniform, metric=minkowski, val_score=0.447133\n",
      "n=7, weights=distance, metric=euclidean, val_score=0.436027\n",
      "n=7, weights=distance, metric=manhattan, val_score=0.436388\n",
      "n=7, weights=distance, metric=chebyshev, val_score=0.422393\n",
      "n=7, weights=distance, metric=minkowski, val_score=0.436027\n",
      "n=8, weights=uniform, metric=euclidean, val_score=0.449752\n",
      "n=8, weights=uniform, metric=manhattan, val_score=0.450023\n",
      "n=8, weights=uniform, metric=chebyshev, val_score=0.423386\n",
      "n=8, weights=uniform, metric=minkowski, val_score=0.449752\n",
      "n=8, weights=distance, metric=euclidean, val_score=0.437743\n",
      "n=8, weights=distance, metric=manhattan, val_score=0.436298\n",
      "n=8, weights=distance, metric=chebyshev, val_score=0.423928\n",
      "n=8, weights=distance, metric=minkowski, val_score=0.437743\n",
      "n=9, weights=uniform, metric=euclidean, val_score=0.446050\n",
      "n=9, weights=uniform, metric=manhattan, val_score=0.445959\n",
      "n=9, weights=uniform, metric=chebyshev, val_score=0.420497\n",
      "n=9, weights=uniform, metric=minkowski, val_score=0.446050\n",
      "n=9, weights=distance, metric=euclidean, val_score=0.433499\n",
      "n=9, weights=distance, metric=manhattan, val_score=0.435395\n",
      "n=9, weights=distance, metric=chebyshev, val_score=0.422032\n",
      "n=9, weights=distance, metric=minkowski, val_score=0.433499\n",
      "n=10, weights=uniform, metric=euclidean, val_score=0.451919\n",
      "n=10, weights=uniform, metric=manhattan, val_score=0.451828\n",
      "n=10, weights=uniform, metric=chebyshev, val_score=0.422844\n",
      "n=10, weights=uniform, metric=minkowski, val_score=0.451919\n",
      "n=10, weights=distance, metric=euclidean, val_score=0.437381\n",
      "n=10, weights=distance, metric=manhattan, val_score=0.437833\n",
      "n=10, weights=distance, metric=chebyshev, val_score=0.424831\n",
      "n=10, weights=distance, metric=minkowski, val_score=0.437381\n",
      "n=11, weights=uniform, metric=euclidean, val_score=0.457427\n",
      "n=11, weights=uniform, metric=manhattan, val_score=0.457878\n",
      "n=11, weights=uniform, metric=chebyshev, val_score=0.427178\n",
      "n=11, weights=uniform, metric=minkowski, val_score=0.457427\n",
      "n=11, weights=distance, metric=euclidean, val_score=0.441625\n",
      "n=11, weights=distance, metric=manhattan, val_score=0.441445\n",
      "n=11, weights=distance, metric=chebyshev, val_score=0.428984\n",
      "n=11, weights=distance, metric=minkowski, val_score=0.441625\n",
      "n=12, weights=uniform, metric=euclidean, val_score=0.455350\n",
      "n=12, weights=uniform, metric=manhattan, val_score=0.455440\n",
      "n=12, weights=uniform, metric=chebyshev, val_score=0.421490\n",
      "n=12, weights=uniform, metric=minkowski, val_score=0.455350\n",
      "n=12, weights=distance, metric=euclidean, val_score=0.439458\n",
      "n=12, weights=distance, metric=manhattan, val_score=0.439819\n",
      "n=12, weights=distance, metric=chebyshev, val_score=0.425282\n",
      "n=12, weights=distance, metric=minkowski, val_score=0.439458\n",
      "n=13, weights=uniform, metric=euclidean, val_score=0.453815\n",
      "n=13, weights=uniform, metric=manhattan, val_score=0.453454\n",
      "n=13, weights=uniform, metric=chebyshev, val_score=0.418691\n",
      "n=13, weights=uniform, metric=minkowski, val_score=0.453815\n",
      "n=13, weights=distance, metric=euclidean, val_score=0.439097\n",
      "n=13, weights=distance, metric=manhattan, val_score=0.440181\n",
      "n=13, weights=distance, metric=chebyshev, val_score=0.423115\n",
      "n=13, weights=distance, metric=minkowski, val_score=0.439097\n",
      "n=14, weights=uniform, metric=euclidean, val_score=0.454718\n",
      "n=14, weights=uniform, metric=manhattan, val_score=0.453454\n",
      "n=14, weights=uniform, metric=chebyshev, val_score=0.421761\n",
      "n=14, weights=uniform, metric=minkowski, val_score=0.454718\n",
      "n=14, weights=distance, metric=euclidean, val_score=0.439729\n",
      "n=14, weights=distance, metric=manhattan, val_score=0.439639\n",
      "n=14, weights=distance, metric=chebyshev, val_score=0.425372\n",
      "n=14, weights=distance, metric=minkowski, val_score=0.439729\n",
      "n=15, weights=uniform, metric=euclidean, val_score=0.456704\n",
      "n=15, weights=uniform, metric=manhattan, val_score=0.455982\n",
      "n=15, weights=uniform, metric=chebyshev, val_score=0.421941\n",
      "n=15, weights=uniform, metric=minkowski, val_score=0.456704\n",
      "n=15, weights=distance, metric=euclidean, val_score=0.442619\n",
      "n=15, weights=distance, metric=manhattan, val_score=0.443883\n",
      "n=15, weights=distance, metric=chebyshev, val_score=0.427810\n",
      "n=15, weights=distance, metric=minkowski, val_score=0.442619\n",
      "n=16, weights=uniform, metric=euclidean, val_score=0.460316\n",
      "n=16, weights=uniform, metric=manhattan, val_score=0.460135\n",
      "n=16, weights=uniform, metric=chebyshev, val_score=0.423386\n",
      "n=16, weights=uniform, metric=minkowski, val_score=0.460316\n",
      "n=16, weights=distance, metric=euclidean, val_score=0.443883\n",
      "n=16, weights=distance, metric=manhattan, val_score=0.444334\n",
      "n=16, weights=distance, metric=chebyshev, val_score=0.429255\n",
      "n=16, weights=distance, metric=minkowski, val_score=0.443883\n",
      "n=17, weights=uniform, metric=euclidean, val_score=0.462754\n",
      "n=17, weights=uniform, metric=manhattan, val_score=0.461761\n",
      "n=17, weights=uniform, metric=chebyshev, val_score=0.430339\n",
      "n=17, weights=uniform, metric=minkowski, val_score=0.462754\n",
      "n=17, weights=distance, metric=euclidean, val_score=0.445959\n",
      "n=17, weights=distance, metric=manhattan, val_score=0.445508\n",
      "n=17, weights=distance, metric=chebyshev, val_score=0.431242\n",
      "n=17, weights=distance, metric=minkowski, val_score=0.445959\n",
      "n=18, weights=uniform, metric=euclidean, val_score=0.461038\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n=18, weights=uniform, metric=manhattan, val_score=0.461670\n",
      "n=18, weights=uniform, metric=chebyshev, val_score=0.429436\n",
      "n=18, weights=uniform, metric=minkowski, val_score=0.461038\n",
      "n=18, weights=distance, metric=euclidean, val_score=0.445056\n",
      "n=18, weights=distance, metric=manhattan, val_score=0.445959\n",
      "n=18, weights=distance, metric=chebyshev, val_score=0.430880\n",
      "n=18, weights=distance, metric=minkowski, val_score=0.445056\n",
      "n=19, weights=uniform, metric=euclidean, val_score=0.464831\n",
      "n=19, weights=uniform, metric=manhattan, val_score=0.466095\n",
      "n=19, weights=uniform, metric=chebyshev, val_score=0.425914\n",
      "n=19, weights=uniform, metric=minkowski, val_score=0.464831\n",
      "n=19, weights=distance, metric=euclidean, val_score=0.448668\n",
      "n=19, weights=distance, metric=manhattan, val_score=0.449029\n",
      "n=19, weights=distance, metric=chebyshev, val_score=0.432867\n",
      "n=19, weights=distance, metric=minkowski, val_score=0.448668\n",
      "Best validation score:  0.46609480812641085\n",
      "Best n:  19\n",
      "Best weights method:  uniform\n",
      "Best distance metric:  manhattan\n"
     ]
    }
   ],
   "source": [
    "best_val = 0\n",
    "best_n = 0\n",
    "best_weights = \"\"\n",
    "best_metric = \"\"\n",
    "for n in range(1,20):\n",
    "    for weights in [\"uniform\", \"distance\"]:\n",
    "        for metric in [\"euclidean\", \"manhattan\", \"chebyshev\", \"minkowski\"]:\n",
    "            knn = KNeighborsClassifier(n_neighbors=n, weights=weights, metric=metric, n_jobs=-1)\n",
    "            knn.fit(X_train,y_train)\n",
    "            val_score = knn.score(X_val, y_val)\n",
    "            print(\"n=%d, weights=%s, metric=%s, val_score=%f\" % (n, weights, metric, val_score))\n",
    "            if val_score > best_val:\n",
    "                best_val = val_score\n",
    "                best_n = n\n",
    "                best_weights = weights\n",
    "                best_metric = metric\n",
    "print(\"Best validation score: \", best_val)\n",
    "print(\"Best n: \", best_n)\n",
    "print(\"Best weights method: \", best_weights)\n",
    "print(\"Best distance metric: \", best_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score:  0.46850621207743426\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=best_n, weights=best_weights, metric=best_metric, n_jobs=-1)\n",
    "knn.fit(X_train,y_train)\n",
    "print(\"Test score: \", knn.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "error_rate = []\n",
    "for n in range(1,80):\n",
    "    knn = KNeighborsClassifier(n_neighbors=n, weights=\"uniform\", metric=\"manhattan\", n_jobs=-1)\n",
    "    knn.fit(X_train,y_train)\n",
    "    pred_i = knn.predict(X_val)\n",
    "    error_rate.append(np.mean(pred_i != y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmsAAAGDCAYAAAB0s1eWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAExMrAEATOwHEFcV2fd83KIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f82ed9bb2e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(range(1,len(error_rate)+1),error_rate,color='blue', linestyle='dashed', marker='o',\n",
    "         markerfacecolor='red', markersize=5)\n",
    "plt.title('Error Rate vs. K Value')\n",
    "plt.xlabel('K')\n",
    "plt.ylabel('Error Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

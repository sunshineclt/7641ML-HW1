{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Reading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('../HW1_data/traffic/Casualties0514.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deal with skewed data: resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dataset.groupby(\"Casualty_Severity\").count()\n",
    "fatal_dataset = dataset[dataset[\"Casualty_Severity\"]==1]\n",
    "num_fatal = fatal_dataset.shape[0]\n",
    "serious_dataset = dataset[dataset[\"Casualty_Severity\"]==2].sample(n=num_fatal, random_state=35674, axis=0)\n",
    "slight_dataset = dataset[dataset[\"Casualty_Severity\"]==3].sample(n=num_fatal, random_state=25442, axis=0)\n",
    "dataset = pd.concat([fatal_dataset, serious_dataset, slight_dataset],axis=0)\n",
    "del fatal_dataset, serious_dataset, slight_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Casualty_Class</th>\n",
       "      <th>Sex_of_Casualty</th>\n",
       "      <th>Age_of_Casualty</th>\n",
       "      <th>Age_Band_of_Casualty</th>\n",
       "      <th>Casualty_Severity</th>\n",
       "      <th>Pedestrian_Location</th>\n",
       "      <th>Pedestrian_Movement</th>\n",
       "      <th>Car_Passenger</th>\n",
       "      <th>Bus_or_Coach_Passenger</th>\n",
       "      <th>Pedestrian_Road_Maintenance_Worker</th>\n",
       "      <th>Casualty_Type</th>\n",
       "      <th>Casualty_Home_Area_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1884347</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>59</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1527962</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1899098</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>45</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1262549</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1485824</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>82</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Casualty_Class  Sex_of_Casualty  Age_of_Casualty  \\\n",
       "1884347               3                1               59   \n",
       "1527962               1                1               30   \n",
       "1899098               3                2               45   \n",
       "1262549               1                1               20   \n",
       "1485824               3                2               82   \n",
       "\n",
       "         Age_Band_of_Casualty  Casualty_Severity  Pedestrian_Location  \\\n",
       "1884347                     9                  1                    5   \n",
       "1527962                     6                  1                    0   \n",
       "1899098                     7                  1                    6   \n",
       "1262549                     4                  2                    0   \n",
       "1485824                    11                  2                    1   \n",
       "\n",
       "         Pedestrian_Movement  Car_Passenger  Bus_or_Coach_Passenger  \\\n",
       "1884347                    3              0                       0   \n",
       "1527962                    0              0                       0   \n",
       "1899098                    9              0                       0   \n",
       "1262549                    0              0                       0   \n",
       "1485824                    1              0                       0   \n",
       "\n",
       "         Pedestrian_Road_Maintenance_Worker  Casualty_Type  \\\n",
       "1884347                                   0              0   \n",
       "1527962                                   0              9   \n",
       "1899098                                   0              0   \n",
       "1262549                                  -1              9   \n",
       "1485824                                   0              0   \n",
       "\n",
       "         Casualty_Home_Area_Type  \n",
       "1884347                        3  \n",
       "1527962                        1  \n",
       "1899098                        1  \n",
       "1262549                        1  \n",
       "1485824                       -1  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset.drop([\"Accident_Index\", \"Vehicle_Reference\", \"Casualty_Reference\"], axis=1)\n",
    "dataset = dataset.sample(frac=1, axis=0)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(44297, 11)\n",
      "(11075, 11)\n",
      "(13844, 11)\n"
     ]
    }
   ],
   "source": [
    "# Prepare data for Decision Tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "X = dataset.drop([\"Casualty_Severity\"], axis=1)\n",
    "y = dataset[\"Casualty_Severity\"]\n",
    "X_all_train, X_test, y_all_train, y_test = train_test_split(X, y, test_size=0.2, random_state=6357)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_all_train, y_all_train, test_size=0.2, random_state=6357)\n",
    "del X, y\n",
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit end! \n",
      "Validation score:  0.43909706546275395\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import pydotplus as pydot\n",
    "from IPython.display import Image\n",
    "from sklearn.externals.six import StringIO\n",
    "from sklearn import tree\n",
    "\n",
    "# Vanilla Decision Tree\n",
    "dt = DecisionTreeClassifier(criterion=\"entropy\", random_state=4321)\n",
    "dt.fit(X_train, y_train)\n",
    "print(\"Fit end! \")\n",
    "dt_val_score = dt.score(X_val, y_val)\n",
    "print(\"Validation score: \", dt_val_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement post-prune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Post-prune Decision Tree \n",
    "# My own implementation based on https://stackoverflow.com/questions/49428469/pruning-decision-trees/49496027#49496027\n",
    "# Pruning based on validation score (if pruning a subtree gains better performance on validate set, then prune it)\n",
    "from sklearn.tree._tree import TREE_LEAF\n",
    "\n",
    "def prune_from_root(inner_tree, index):\n",
    "    global dt_val_score\n",
    "    memo = (inner_tree.children_left[index], inner_tree.children_right[index])\n",
    "    inner_tree.children_left[index] = TREE_LEAF\n",
    "    inner_tree.children_right[index] = TREE_LEAF\n",
    "    new_score = dt.score(X_val, y_val)\n",
    "    if new_score <= dt_val_score:\n",
    "        inner_tree.children_left[index] = memo[0]\n",
    "        inner_tree.children_right[index] = memo[1]\n",
    "    else:\n",
    "        dt_val_score = new_score\n",
    "\n",
    "    # if there are children, visit them as well\n",
    "    if inner_tree.children_left[index] != TREE_LEAF:\n",
    "        prune_from_root(inner_tree, inner_tree.children_left[index])\n",
    "        prune_from_root(inner_tree, inner_tree.children_right[index])\n",
    "\n",
    "def prune_from_leaf(inner_tree, index):\n",
    "    global dt_val_score\n",
    "    # if there are children, firstly visit them\n",
    "    if inner_tree.children_left[index] != TREE_LEAF:\n",
    "        prune_from_leaf(inner_tree, inner_tree.children_left[index])\n",
    "        prune_from_leaf(inner_tree, inner_tree.children_right[index])\n",
    "        memo = (inner_tree.children_left[index], inner_tree.children_right[index])\n",
    "        inner_tree.children_left[index] = TREE_LEAF\n",
    "        inner_tree.children_right[index] = TREE_LEAF\n",
    "        new_score = dt.score(X_val, y_val)\n",
    "        if new_score <= dt_val_score:\n",
    "            inner_tree.children_left[index] = memo[0]\n",
    "            inner_tree.children_right[index] = memo[1]\n",
    "        else:\n",
    "            dt_val_score = new_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prune from root experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no-prune validation score:  0.43873589164785554\n",
      "no-prune test score:  0.4460416064721179\n",
      "post-prune from root validation score:  0.4588713318284424\n",
      "post-prune from root test score:  0.46865067899451024\n"
     ]
    }
   ],
   "source": [
    "# prune from root\n",
    "dt = DecisionTreeClassifier(criterion=\"entropy\", random_state=4321)\n",
    "dt.fit(X_train, y_train)\n",
    "dt_val_score = dt.score(X_val, y_val)\n",
    "print(\"no-prune validation score: \", dt_val_score)\n",
    "print(\"no-prune test score: \", dt.score(X_test, y_test))\n",
    "prune_from_root(dt.tree_, 0)\n",
    "print(\"post-prune from root validation score: \", dt.score(X_val, y_val))\n",
    "print(\"post-prune from root test score: \", dt.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prune from leaf experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no-prune validation score:  0.43873589164785554\n",
      "no-prune test score:  0.4460416064721179\n",
      "post-prune from leaf validation score:  0.5398645598194131\n",
      "post-prune from leaf test score:  0.46850621207743426\n"
     ]
    }
   ],
   "source": [
    "# prune from leaf\n",
    "# create an identical decision tree to the previous one using the same random_state\n",
    "dt = DecisionTreeClassifier(criterion=\"entropy\", random_state=4321)\n",
    "dt.fit(X_train, y_train)\n",
    "dt_val_score = dt.score(X_val, y_val)\n",
    "print(\"no-prune validation score: \", dt_val_score)\n",
    "print(\"no-prune test score: \", dt.score(X_test, y_test))\n",
    "prune_from_leaf(dt.tree_, 0)\n",
    "print(\"post-prune from leaf validation score: \", dt.score(X_val, y_val))\n",
    "print(\"post-prune from leaf test score: \", dt.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning using CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================\n",
      "depth=1, post-prune=from root\n",
      "no-prune validation score:  0.4302483069977427\n",
      "no-prune test score:  0.43433978618896274\n",
      "post-prune from root validation score:  0.4302483069977427\n",
      "post-prune from root test score:  0.43433978618896274\n",
      "===================\n",
      "depth=1, post-prune=from leaf\n",
      "no-prune validation score:  0.4302483069977427\n",
      "no-prune test score:  0.43433978618896274\n",
      "post-prune from leaf validation score:  0.4302483069977427\n",
      "post-prune from leaf test score:  0.43433978618896274\n",
      "===================\n",
      "depth=2, post-prune=from root\n",
      "no-prune validation score:  0.43548532731376977\n",
      "no-prune test score:  0.4328951170182028\n",
      "post-prune from root validation score:  0.43548532731376977\n",
      "post-prune from root test score:  0.4328951170182028\n",
      "===================\n",
      "depth=2, post-prune=from leaf\n",
      "no-prune validation score:  0.43548532731376977\n",
      "no-prune test score:  0.4328951170182028\n",
      "post-prune from leaf validation score:  0.43548532731376977\n",
      "post-prune from leaf test score:  0.4328951170182028\n",
      "===================\n",
      "depth=3, post-prune=from root\n",
      "no-prune validation score:  0.46428893905191876\n",
      "no-prune test score:  0.4749349898873158\n",
      "post-prune from root validation score:  0.46428893905191876\n",
      "post-prune from root test score:  0.4749349898873158\n",
      "===================\n",
      "depth=3, post-prune=from leaf\n",
      "no-prune validation score:  0.46428893905191876\n",
      "no-prune test score:  0.4749349898873158\n",
      "post-prune from leaf validation score:  0.46428893905191876\n",
      "post-prune from leaf test score:  0.4749349898873158\n",
      "===================\n",
      "depth=4, post-prune=from root\n",
      "no-prune validation score:  0.47665914221218963\n",
      "no-prune test score:  0.48295290378503325\n",
      "post-prune from root validation score:  0.4767494356659142\n",
      "post-prune from root test score:  0.4817971684484253\n",
      "===================\n",
      "depth=4, post-prune=from leaf\n",
      "no-prune validation score:  0.47665914221218963\n",
      "no-prune test score:  0.48295290378503325\n",
      "post-prune from leaf validation score:  0.4767494356659142\n",
      "post-prune from leaf test score:  0.4817971684484253\n",
      "===================\n",
      "depth=5, post-prune=from root\n",
      "no-prune validation score:  0.4855079006772009\n",
      "no-prune test score:  0.4946547240681884\n",
      "post-prune from root validation score:  0.4860496613995485\n",
      "post-prune from root test score:  0.4932822883559665\n",
      "===================\n",
      "depth=5, post-prune=from leaf\n",
      "no-prune validation score:  0.4855079006772009\n",
      "no-prune test score:  0.4946547240681884\n",
      "post-prune from leaf validation score:  0.4860496613995485\n",
      "post-prune from leaf test score:  0.4932822883559665\n",
      "===================\n",
      "depth=6, post-prune=from root\n",
      "no-prune validation score:  0.4922799097065463\n",
      "no-prune test score:  0.5015891360878358\n",
      "post-prune from root validation score:  0.4930022573363431\n",
      "post-prune from root test score:  0.5\n",
      "===================\n",
      "depth=6, post-prune=from leaf\n",
      "no-prune validation score:  0.4922799097065463\n",
      "no-prune test score:  0.5015891360878358\n",
      "post-prune from leaf validation score:  0.49318284424379233\n",
      "post-prune from leaf test score:  0.499855533082924\n",
      "===================\n",
      "depth=7, post-prune=from root\n",
      "no-prune validation score:  0.490293453724605\n",
      "no-prune test score:  0.49891649812193006\n",
      "post-prune from root validation score:  0.49354401805869075\n",
      "post-prune from root test score:  0.5006501011268419\n",
      "===================\n",
      "depth=7, post-prune=from leaf\n",
      "no-prune validation score:  0.490293453724605\n",
      "no-prune test score:  0.49891649812193006\n",
      "post-prune from leaf validation score:  0.49381489841986453\n",
      "post-prune from leaf test score:  0.500072233458538\n",
      "===================\n",
      "depth=8, post-prune=from root\n",
      "no-prune validation score:  0.48993227990970656\n",
      "no-prune test score:  0.499422132331696\n",
      "post-prune from root validation score:  0.49399548532731374\n",
      "post-prune from root test score:  0.49956659924877206\n",
      "===================\n",
      "depth=8, post-prune=from leaf\n",
      "no-prune validation score:  0.48993227990970656\n",
      "no-prune test score:  0.499422132331696\n",
      "post-prune from leaf validation score:  0.49525959367945827\n",
      "post-prune from leaf test score:  0.49956659924877206\n",
      "===================\n",
      "depth=9, post-prune=from root\n",
      "no-prune validation score:  0.4883069977426637\n",
      "no-prune test score:  0.49631609361456225\n",
      "post-prune from root validation score:  0.49670428893905194\n",
      "post-prune from root test score:  0.5028171048829818\n",
      "===================\n",
      "depth=9, post-prune=from leaf\n",
      "no-prune validation score:  0.4883069977426637\n",
      "no-prune test score:  0.49631609361456225\n",
      "post-prune from leaf validation score:  0.4992325056433409\n",
      "post-prune from leaf test score:  0.500505634209766\n",
      "===================\n",
      "depth=10, post-prune=from root\n",
      "no-prune validation score:  0.4872234762979684\n",
      "no-prune test score:  0.49530482519503033\n",
      "post-prune from root validation score:  0.49516930022573363\n",
      "post-prune from root test score:  0.5032505056342098\n",
      "===================\n",
      "depth=10, post-prune=from leaf\n",
      "no-prune validation score:  0.4872234762979684\n",
      "no-prune test score:  0.49530482519503033\n",
      "post-prune from leaf validation score:  0.5009480812641084\n",
      "post-prune from leaf test score:  0.4985553308292401\n",
      "===================\n",
      "depth=11, post-prune=from root\n",
      "no-prune validation score:  0.48361173814898417\n",
      "no-prune test score:  0.49364345564865647\n",
      "post-prune from root validation score:  0.4944469525959368\n",
      "post-prune from root test score:  0.5\n",
      "===================\n",
      "depth=11, post-prune=from leaf\n",
      "no-prune validation score:  0.48361173814898417\n",
      "no-prune test score:  0.49364345564865647\n",
      "post-prune from leaf validation score:  0.503747178329571\n",
      "post-prune from leaf test score:  0.4971828951170182\n",
      "===================\n",
      "depth=12, post-prune=from root\n",
      "no-prune validation score:  0.47927765237020314\n",
      "no-prune test score:  0.4906818838485987\n",
      "post-prune from root validation score:  0.49589164785553047\n",
      "post-prune from root test score:  0.5005778676683039\n",
      "===================\n",
      "depth=12, post-prune=from leaf\n",
      "no-prune validation score:  0.47927765237020314\n",
      "no-prune test score:  0.4906818838485987\n",
      "post-prune from leaf validation score:  0.5079909706546275\n",
      "post-prune from leaf test score:  0.4960993932389483\n",
      "===================\n",
      "depth=13, post-prune=from root\n",
      "no-prune validation score:  0.4781038374717833\n",
      "no-prune test score:  0.4874313782143889\n",
      "post-prune from root validation score:  0.49688487584650115\n",
      "post-prune from root test score:  0.49949436579023404\n",
      "===================\n",
      "depth=13, post-prune=from leaf\n",
      "no-prune validation score:  0.4781038374717833\n",
      "no-prune test score:  0.4874313782143889\n",
      "post-prune from leaf validation score:  0.5121444695259594\n",
      "post-prune from leaf test score:  0.49479919098526437\n",
      "===================\n",
      "depth=14, post-prune=from root\n",
      "no-prune validation score:  0.4737697516930023\n",
      "no-prune test score:  0.48259173649234327\n",
      "post-prune from root validation score:  0.4914672686230248\n",
      "post-prune from root test score:  0.49241548685351055\n",
      "===================\n",
      "depth=14, post-prune=from leaf\n",
      "no-prune validation score:  0.4737697516930023\n",
      "no-prune test score:  0.48259173649234327\n",
      "post-prune from leaf validation score:  0.516117381489842\n",
      "post-prune from leaf test score:  0.4916209188095926\n",
      "===================\n",
      "depth=15, post-prune=from root\n",
      "no-prune validation score:  0.4672686230248307\n",
      "no-prune test score:  0.4755128575556198\n",
      "post-prune from root validation score:  0.48613995485327316\n",
      "post-prune from root test score:  0.4875758451314649\n",
      "===================\n",
      "depth=15, post-prune=from leaf\n",
      "no-prune validation score:  0.4672686230248307\n",
      "no-prune test score:  0.4755128575556198\n",
      "post-prune from leaf validation score:  0.52\n",
      "post-prune from leaf test score:  0.485914475585091\n",
      "===================\n",
      "depth=16, post-prune=from root\n",
      "no-prune validation score:  0.4654627539503386\n",
      "no-prune test score:  0.4709621496677261\n",
      "post-prune from root validation score:  0.48939051918735893\n",
      "post-prune from root test score:  0.49458249060965037\n",
      "===================\n",
      "depth=16, post-prune=from leaf\n",
      "no-prune validation score:  0.4654627539503386\n",
      "no-prune test score:  0.4709621496677261\n",
      "post-prune from leaf validation score:  0.5244243792325056\n",
      "post-prune from leaf test score:  0.4846865067899451\n",
      "===================\n",
      "depth=17, post-prune=from root\n",
      "no-prune validation score:  0.45914221218961626\n",
      "no-prune test score:  0.46568910719445245\n",
      "post-prune from root validation score:  0.48478555304740406\n",
      "post-prune from root test score:  0.48808147934123086\n",
      "===================\n",
      "depth=17, post-prune=from leaf\n",
      "no-prune validation score:  0.45914221218961626\n",
      "no-prune test score:  0.46568910719445245\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "post-prune from leaf validation score:  0.5272234762979684\n",
      "post-prune from leaf test score:  0.48129153423865934\n",
      "===================\n",
      "depth=18, post-prune=from root\n",
      "no-prune validation score:  0.45580135440180586\n",
      "no-prune test score:  0.46056053163825483\n",
      "post-prune from root validation score:  0.4817155756207675\n",
      "post-prune from root test score:  0.485842242126553\n",
      "===================\n",
      "depth=18, post-prune=from leaf\n",
      "no-prune validation score:  0.45580135440180586\n",
      "no-prune test score:  0.46056053163825483\n",
      "post-prune from leaf validation score:  0.531647855530474\n",
      "post-prune from leaf test score:  0.4775353943946836\n",
      "===================\n",
      "depth=19, post-prune=from root\n",
      "no-prune validation score:  0.4524604966139955\n",
      "no-prune test score:  0.458176827506501\n",
      "post-prune from root validation score:  0.4817155756207675\n",
      "post-prune from root test score:  0.485842242126553\n",
      "===================\n",
      "depth=19, post-prune=from leaf\n",
      "no-prune validation score:  0.4524604966139955\n",
      "no-prune test score:  0.458176827506501\n",
      "post-prune from leaf validation score:  0.5337246049661399\n",
      "post-prune from leaf test score:  0.4745015891360878\n",
      "===================\n",
      "depth=20, post-prune=from root\n",
      "no-prune validation score:  0.4461399548532731\n",
      "no-prune test score:  0.4543484542039873\n",
      "post-prune from root validation score:  0.4679909706546275\n",
      "post-prune from root test score:  0.47601849176538574\n",
      "===================\n",
      "depth=20, post-prune=from leaf\n",
      "no-prune validation score:  0.4461399548532731\n",
      "no-prune test score:  0.4543484542039873\n",
      "post-prune from leaf validation score:  0.535530474040632\n",
      "post-prune from leaf test score:  0.4731291534238659\n",
      "===================\n",
      "depth=21, post-prune=from root\n",
      "no-prune validation score:  0.44604966139954855\n",
      "no-prune test score:  0.4527593181161514\n",
      "post-prune from root validation score:  0.4679909706546275\n",
      "post-prune from root test score:  0.47601849176538574\n",
      "===================\n",
      "depth=21, post-prune=from leaf\n",
      "no-prune validation score:  0.44604966139954855\n",
      "no-prune test score:  0.4527593181161514\n",
      "post-prune from leaf validation score:  0.5360722347629797\n",
      "post-prune from leaf test score:  0.47226235192141\n",
      "===================\n",
      "depth=22, post-prune=from root\n",
      "no-prune validation score:  0.44650112866817154\n",
      "no-prune test score:  0.44994221323316963\n",
      "post-prune from root validation score:  0.4679909706546275\n",
      "post-prune from root test score:  0.47601849176538574\n",
      "===================\n",
      "depth=22, post-prune=from leaf\n",
      "no-prune validation score:  0.44650112866817154\n",
      "no-prune test score:  0.44994221323316963\n",
      "post-prune from leaf validation score:  0.5376975169300225\n",
      "post-prune from leaf test score:  0.4701675816238082\n",
      "===================\n",
      "depth=23, post-prune=from root\n",
      "no-prune validation score:  0.44623024830699776\n",
      "no-prune test score:  0.45037561398439757\n",
      "post-prune from root validation score:  0.4679909706546275\n",
      "post-prune from root test score:  0.47601849176538574\n",
      "===================\n",
      "depth=23, post-prune=from leaf\n",
      "no-prune validation score:  0.44623024830699776\n",
      "no-prune test score:  0.45037561398439757\n",
      "post-prune from leaf validation score:  0.5390519187358916\n",
      "post-prune from leaf test score:  0.4707454492921121\n",
      "===================\n",
      "depth=24, post-prune=from root\n",
      "no-prune validation score:  0.4427990970654628\n",
      "no-prune test score:  0.44820861022825775\n",
      "post-prune from root validation score:  0.4679909706546275\n",
      "post-prune from root test score:  0.47601849176538574\n",
      "===================\n",
      "depth=24, post-prune=from leaf\n",
      "no-prune validation score:  0.4427990970654628\n",
      "no-prune test score:  0.44820861022825775\n",
      "post-prune from leaf validation score:  0.5391422121896162\n",
      "post-prune from leaf test score:  0.4692285466628142\n",
      "===================\n",
      "depth=25, post-prune=from root\n",
      "no-prune validation score:  0.4418058690744921\n",
      "no-prune test score:  0.44770297601849174\n",
      "post-prune from root validation score:  0.4679909706546275\n",
      "post-prune from root test score:  0.47601849176538574\n",
      "===================\n",
      "depth=25, post-prune=from leaf\n",
      "no-prune validation score:  0.4418058690744921\n",
      "no-prune test score:  0.44770297601849174\n",
      "post-prune from leaf validation score:  0.5393227990970655\n",
      "post-prune from leaf test score:  0.4695897139555042\n",
      "===================\n",
      "depth=26, post-prune=from root\n",
      "no-prune validation score:  0.4396388261851016\n",
      "no-prune test score:  0.44661947414042186\n",
      "post-prune from root validation score:  0.4679909706546275\n",
      "post-prune from root test score:  0.47601849176538574\n",
      "===================\n",
      "depth=26, post-prune=from leaf\n",
      "no-prune validation score:  0.4396388261851016\n",
      "no-prune test score:  0.44661947414042186\n",
      "post-prune from leaf validation score:  0.5391422121896162\n",
      "post-prune from leaf test score:  0.47002311470673214\n",
      "===================\n",
      "depth=27, post-prune=from root\n",
      "no-prune validation score:  0.4388261851015801\n",
      "no-prune test score:  0.4468361745160358\n",
      "post-prune from root validation score:  0.4679909706546275\n",
      "post-prune from root test score:  0.47601849176538574\n",
      "===================\n",
      "depth=27, post-prune=from leaf\n",
      "no-prune validation score:  0.4388261851015801\n",
      "no-prune test score:  0.4468361745160358\n",
      "post-prune from leaf validation score:  0.5395033860045146\n",
      "post-prune from leaf test score:  0.46930078012135223\n",
      "===================\n",
      "depth=28, post-prune=from root\n",
      "no-prune validation score:  0.43954853273137695\n",
      "no-prune test score:  0.4459693730135799\n",
      "post-prune from root validation score:  0.4679909706546275\n",
      "post-prune from root test score:  0.47601849176538574\n",
      "===================\n",
      "depth=28, post-prune=from leaf\n",
      "no-prune validation score:  0.43954853273137695\n",
      "no-prune test score:  0.4459693730135799\n",
      "post-prune from leaf validation score:  0.5393227990970655\n",
      "post-prune from leaf test score:  0.46865067899451024\n",
      "===================\n",
      "depth=29, post-prune=from root\n",
      "no-prune validation score:  0.43927765237020316\n",
      "no-prune test score:  0.4459693730135799\n",
      "post-prune from root validation score:  0.4679909706546275\n",
      "post-prune from root test score:  0.47601849176538574\n",
      "===================\n",
      "depth=29, post-prune=from leaf\n",
      "no-prune validation score:  0.43927765237020316\n",
      "no-prune test score:  0.4459693730135799\n",
      "post-prune from leaf validation score:  0.5394130925507901\n",
      "post-prune from leaf test score:  0.46930078012135223\n",
      "*********************\n",
      "best_val=0.539503, best_val_depth=27, best_post_prune=from leaf\n"
     ]
    }
   ],
   "source": [
    "# pre prune + post prune\n",
    "best_val = 0\n",
    "best_val_depth = 0\n",
    "best_post_prune = \"\"\n",
    "for depth in range(1, 30):\n",
    "    dt = DecisionTreeClassifier(criterion=\"entropy\", max_depth=depth, random_state=4321)\n",
    "    dt.fit(X_train, y_train)\n",
    "    dt_val_score = dt.score(X_val, y_val)\n",
    "    print(\"===================\", \"depth=%d, post-prune=from root\" % depth, sep='\\n')\n",
    "    print(\"no-prune validation score: \", dt_val_score)\n",
    "    print(\"no-prune test score: \", dt.score(X_test, y_test))\n",
    "    prune_from_root(dt.tree_, 0)\n",
    "    val_score = dt.score(X_val, y_val)\n",
    "    print(\"post-prune from root validation score: \", val_score)\n",
    "    if val_score > best_val:\n",
    "        best_val = val_score\n",
    "        best_val_depth = depth\n",
    "        best_post_prune = \"from root\"\n",
    "    print(\"post-prune from root test score: \", dt.score(X_test, y_test))\n",
    "    \n",
    "    dt = DecisionTreeClassifier(criterion=\"entropy\", max_depth=depth, random_state=4321)\n",
    "    dt.fit(X_train, y_train)\n",
    "    dt_val_score = dt.score(X_val, y_val)\n",
    "    print(\"===================\", \"depth=%d, post-prune=from leaf\" % depth, sep='\\n')\n",
    "    print(\"no-prune validation score: \", dt_val_score)\n",
    "    print(\"no-prune test score: \", dt.score(X_test, y_test))\n",
    "    prune_from_leaf(dt.tree_, 0)\n",
    "    val_score = dt.score(X_val, y_val)\n",
    "    print(\"post-prune from leaf validation score: \", val_score)\n",
    "    if val_score >= best_val:\n",
    "        best_val = val_score\n",
    "        best_val_depth = depth\n",
    "        best_post_prune = \"from leaf\"\n",
    "    print(\"post-prune from leaf test score: \", dt.score(X_test, y_test))\n",
    "print(\"*********************\")\n",
    "print(\"best_val=%f, best_val_depth=%d, best_post_prune=%s\" % (best_val, best_val_depth, best_post_prune))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no-prune training score:  0.648102580310179\n",
      "no-prune validation score:  0.4396388261851016\n",
      "no-prune test score:  0.43932389482808437\n",
      "post-prune from leaf training score:  0.5920942727498476\n",
      "post-prune from leaf validation score:  0.5441083521444695\n",
      "post-prune from leaf test score:  0.46749494365790234\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier(criterion=\"entropy\", max_depth=27, random_state=4321)\n",
    "dt.fit(X_train, y_train)\n",
    "dt_val_score = dt.score(X_val, y_val)\n",
    "print(\"no-prune training score: \", dt.score(X_train, y_train))\n",
    "print(\"no-prune validation score: \", dt_val_score)\n",
    "print(\"no-prune test score: \", dt.score(X_test, y_test))\n",
    "prune_from_leaf(dt.tree_, 0)\n",
    "val_score = dt.score(X_val, y_val)\n",
    "print(\"post-prune from leaf training score: \", dt.score(X_train, y_train))\n",
    "print(\"post-prune from leaf validation score: \", val_score)\n",
    "print(\"post-prune from leaf test score: \", dt.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning using CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/envs/7641ML/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'DecisionTreeClassifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-d185f893623f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdepth\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mn_estimators\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m400\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mada_dt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"entropy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdepth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0madaboost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAdaBoostClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mada_dt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0madaboost\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'DecisionTreeClassifier' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "best_val = 0\n",
    "best_depth = 0\n",
    "best_n_estimators = 0\n",
    "for depth in range(1, 10):\n",
    "    for n_estimators in [100, 200, 400, 1000]:\n",
    "        ada_dt = DecisionTreeClassifier(criterion=\"entropy\", max_depth=depth)\n",
    "        adaboost = AdaBoostClassifier(base_estimator=ada_dt, n_estimators=n_estimators)\n",
    "        adaboost.fit(X_train,y_train)\n",
    "        val_score = adaboost.score(X_val,y_val)\n",
    "        print(\"max_depth=%d, n_estimator=%d, val_score=%f\" % (depth, n_estimators, val_score))\n",
    "        if val_score > best_val:\n",
    "            best_val = val_score\n",
    "            best_depth = depth\n",
    "            best_n_estimators = n_estimators\n",
    "            \n",
    "print(\"Best validation score: \", best_val)\n",
    "print(\"Best depth: \", best_depth)\n",
    "print(\"Best estimators: \", best_n_estimators)\n",
    "ada_dt = DecisionTreeClassifier(criterion=\"entropy\", max_depth=best_depth)\n",
    "adaboost = AdaBoostClassifier(base_estimator=ada_dt, n_estimators=best_n_estimators)\n",
    "adaboost.fit(X_train,y_train)\n",
    "test_score = adaboost.score(X_test, y_test)\n",
    "print(\"Test score: \", test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Draw Iterative Training Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val score:  0.5034762979683973\n",
      "Test score:  0.50072233458538\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "ada_dt = DecisionTreeClassifier(criterion=\"entropy\", max_depth=1)\n",
    "adaboost = AdaBoostClassifier(base_estimator=ada_dt, n_estimators=1000)\n",
    "adaboost.fit(X_train,y_train)\n",
    "val_score = adaboost.score(X_val, y_val)\n",
    "print(\"Val score: \", val_score)\n",
    "test_score = adaboost.score(X_test, y_test)\n",
    "print(\"Test score: \", test_score)\n",
    "\n",
    "train_mid_error = []\n",
    "for mid_predict in adaboost.staged_predict(X_train):\n",
    "    train_mid_error.append(1 - accuracy_score(mid_predict, y_train))\n",
    "val_mid_error = []\n",
    "for mid_predict in adaboost.staged_predict(X_val):\n",
    "    val_mid_error.append(1 - accuracy_score(mid_predict, y_val))\n",
    "\n",
    "number_of_predict = len(val_mid_error)\n",
    "train_mid_error = train_mid_error[:number_of_predict]\n",
    "\n",
    "plt.plot(range(1, number_of_predict + 1),\n",
    "         val_mid_error, label='Validation')\n",
    "plt.plot(range(1, number_of_predict + 1),\n",
    "         train_mid_error, label='Train')\n",
    "plt.legend()\n",
    "plt.ylabel('Error')\n",
    "plt.xlabel('Number of Trees')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score:  0.5011400320563469\n",
      "Test score:  0.5010835018780699\n"
     ]
    }
   ],
   "source": [
    "ada_dt = DecisionTreeClassifier(criterion=\"entropy\", max_depth=1)\n",
    "adaboost = AdaBoostClassifier(base_estimator=ada_dt, n_estimators=1000)\n",
    "adaboost.fit(X_all_train,y_all_train)\n",
    "print(\"Training score: \", adaboost.score(X_train, y_train))\n",
    "test_score = adaboost.score(X_test, y_test)\n",
    "print(\"Test score: \", test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess data to onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Casualty_Class</th>\n",
       "      <th>Sex_of_Casualty</th>\n",
       "      <th>Age_of_Casualty</th>\n",
       "      <th>Age_Band_of_Casualty</th>\n",
       "      <th>Casualty_Severity</th>\n",
       "      <th>Pedestrian_Location</th>\n",
       "      <th>Pedestrian_Movement</th>\n",
       "      <th>Car_Passenger</th>\n",
       "      <th>Bus_or_Coach_Passenger</th>\n",
       "      <th>Pedestrian_Road_Maintenance_Worker</th>\n",
       "      <th>Casualty_Type</th>\n",
       "      <th>Casualty_Home_Area_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>436699</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007290</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2064356</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2115758</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1543466</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Casualty_Class  Sex_of_Casualty  Age_of_Casualty  \\\n",
       "436699                1                1               22   \n",
       "2007290               1                1               17   \n",
       "2064356               1                1               29   \n",
       "2115758               2                2               25   \n",
       "1543466               3                2               13   \n",
       "\n",
       "         Age_Band_of_Casualty  Casualty_Severity  Pedestrian_Location  \\\n",
       "436699                      5                  2                    0   \n",
       "2007290                     4                  1                    0   \n",
       "2064356                     6                  3                    0   \n",
       "2115758                     5                  3                    0   \n",
       "1543466                     3                  2                    1   \n",
       "\n",
       "         Pedestrian_Movement  Car_Passenger  Bus_or_Coach_Passenger  \\\n",
       "436699                     0              0                       0   \n",
       "2007290                    0              0                       0   \n",
       "2064356                    0              0                       0   \n",
       "2115758                    0              2                       0   \n",
       "1543466                    1              0                       0   \n",
       "\n",
       "         Pedestrian_Road_Maintenance_Worker  Casualty_Type  \\\n",
       "436699                                   -1              5   \n",
       "2007290                                   0              1   \n",
       "2064356                                   0              1   \n",
       "2115758                                   0              9   \n",
       "1543466                                   0              0   \n",
       "\n",
       "         Casualty_Home_Area_Type  \n",
       "436699                         1  \n",
       "2007290                        1  \n",
       "2064356                        1  \n",
       "2115758                        1  \n",
       "1543466                        1  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('../HW1_data/traffic/Casualties0514.csv')\n",
    "dataset.head()\n",
    "# dataset.groupby(\"Casualty_Severity\").count()\n",
    "fatal_dataset = dataset[dataset[\"Casualty_Severity\"]==1]\n",
    "num_fatal = fatal_dataset.shape[0]\n",
    "serious_dataset = dataset[dataset[\"Casualty_Severity\"]==2].sample(n=num_fatal, random_state=35674, axis=0)\n",
    "slight_dataset = dataset[dataset[\"Casualty_Severity\"]==3].sample(n=num_fatal, random_state=25442, axis=0)\n",
    "dataset = pd.concat([fatal_dataset, serious_dataset, slight_dataset],axis=0)\n",
    "del fatal_dataset, serious_dataset, slight_dataset\n",
    "dataset = dataset.drop([\"Accident_Index\", \"Vehicle_Reference\", \"Casualty_Reference\"], axis=1)\n",
    "dataset = dataset.sample(frac=1, axis=0)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age_of_Casualty</th>\n",
       "      <th>Casualty_Severity</th>\n",
       "      <th>Casualty_Class_1</th>\n",
       "      <th>Casualty_Class_2</th>\n",
       "      <th>Casualty_Class_3</th>\n",
       "      <th>Sex_of_Casualty_1</th>\n",
       "      <th>Sex_of_Casualty_2</th>\n",
       "      <th>Age_Band_of_Casualty_1</th>\n",
       "      <th>Age_Band_of_Casualty_2</th>\n",
       "      <th>Age_Band_of_Casualty_3</th>\n",
       "      <th>...</th>\n",
       "      <th>Casualty_Type_18</th>\n",
       "      <th>Casualty_Type_19</th>\n",
       "      <th>Casualty_Type_20</th>\n",
       "      <th>Casualty_Type_21</th>\n",
       "      <th>Casualty_Type_22</th>\n",
       "      <th>Casualty_Type_90</th>\n",
       "      <th>Casualty_Type_97</th>\n",
       "      <th>Casualty_Home_Area_Type_1</th>\n",
       "      <th>Casualty_Home_Area_Type_2</th>\n",
       "      <th>Casualty_Home_Area_Type_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>436699</th>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007290</th>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2064356</th>\n",
       "      <td>29</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2115758</th>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1543466</th>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  72 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Age_of_Casualty  Casualty_Severity  Casualty_Class_1  \\\n",
       "436699                22                  2                 1   \n",
       "2007290               17                  1                 1   \n",
       "2064356               29                  3                 1   \n",
       "2115758               25                  3                 0   \n",
       "1543466               13                  2                 0   \n",
       "\n",
       "         Casualty_Class_2  Casualty_Class_3  Sex_of_Casualty_1  \\\n",
       "436699                  0                 0                  1   \n",
       "2007290                 0                 0                  1   \n",
       "2064356                 0                 0                  1   \n",
       "2115758                 1                 0                  0   \n",
       "1543466                 0                 1                  0   \n",
       "\n",
       "         Sex_of_Casualty_2  Age_Band_of_Casualty_1  Age_Band_of_Casualty_2  \\\n",
       "436699                   0                       0                       0   \n",
       "2007290                  0                       0                       0   \n",
       "2064356                  0                       0                       0   \n",
       "2115758                  1                       0                       0   \n",
       "1543466                  1                       0                       0   \n",
       "\n",
       "         Age_Band_of_Casualty_3            ...              Casualty_Type_18  \\\n",
       "436699                        0            ...                             0   \n",
       "2007290                       0            ...                             0   \n",
       "2064356                       0            ...                             0   \n",
       "2115758                       0            ...                             0   \n",
       "1543466                       1            ...                             0   \n",
       "\n",
       "         Casualty_Type_19  Casualty_Type_20  Casualty_Type_21  \\\n",
       "436699                  0                 0                 0   \n",
       "2007290                 0                 0                 0   \n",
       "2064356                 0                 0                 0   \n",
       "2115758                 0                 0                 0   \n",
       "1543466                 0                 0                 0   \n",
       "\n",
       "         Casualty_Type_22  Casualty_Type_90  Casualty_Type_97  \\\n",
       "436699                  0                 0                 0   \n",
       "2007290                 0                 0                 0   \n",
       "2064356                 0                 0                 0   \n",
       "2115758                 0                 0                 0   \n",
       "1543466                 0                 0                 0   \n",
       "\n",
       "         Casualty_Home_Area_Type_1  Casualty_Home_Area_Type_2  \\\n",
       "436699                           1                          0   \n",
       "2007290                          1                          0   \n",
       "2064356                          1                          0   \n",
       "2115758                          1                          0   \n",
       "1543466                          1                          0   \n",
       "\n",
       "         Casualty_Home_Area_Type_3  \n",
       "436699                           0  \n",
       "2007290                          0  \n",
       "2064356                          0  \n",
       "2115758                          0  \n",
       "1543466                          0  \n",
       "\n",
       "[5 rows x 72 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for col in [\"Casualty_Class\", \"Sex_of_Casualty\", \"Age_Band_of_Casualty\", \"Pedestrian_Location\", \"Pedestrian_Movement\", \"Car_Passenger\", \"Bus_or_Coach_Passenger\", \"Pedestrian_Road_Maintenance_Worker\", \"Casualty_Type\", \"Casualty_Home_Area_Type\"]: \n",
    "    need_remove_non = False\n",
    "    if dataset[col].min() < 0:\n",
    "        need_remove_non = True\n",
    "    dataset = pd.concat([dataset,pd.get_dummies(dataset[col], prefix=col)],axis=1).drop([col],axis=1)\n",
    "    if need_remove_non:\n",
    "        dataset = dataset.drop([col+\"_-1\"], axis=1)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Age_of_Casualty', 'Casualty_Severity', 'Casualty_Class_1',\n",
       "       'Casualty_Class_2', 'Casualty_Class_3', 'Sex_of_Casualty_1',\n",
       "       'Sex_of_Casualty_2', 'Age_Band_of_Casualty_1', 'Age_Band_of_Casualty_2',\n",
       "       'Age_Band_of_Casualty_3', 'Age_Band_of_Casualty_4',\n",
       "       'Age_Band_of_Casualty_5', 'Age_Band_of_Casualty_6',\n",
       "       'Age_Band_of_Casualty_7', 'Age_Band_of_Casualty_8',\n",
       "       'Age_Band_of_Casualty_9', 'Age_Band_of_Casualty_10',\n",
       "       'Age_Band_of_Casualty_11', 'Pedestrian_Location_0',\n",
       "       'Pedestrian_Location_1', 'Pedestrian_Location_2',\n",
       "       'Pedestrian_Location_3', 'Pedestrian_Location_4',\n",
       "       'Pedestrian_Location_5', 'Pedestrian_Location_6',\n",
       "       'Pedestrian_Location_7', 'Pedestrian_Location_8',\n",
       "       'Pedestrian_Location_9', 'Pedestrian_Location_10',\n",
       "       'Pedestrian_Movement_0', 'Pedestrian_Movement_1',\n",
       "       'Pedestrian_Movement_2', 'Pedestrian_Movement_3',\n",
       "       'Pedestrian_Movement_4', 'Pedestrian_Movement_5',\n",
       "       'Pedestrian_Movement_6', 'Pedestrian_Movement_7',\n",
       "       'Pedestrian_Movement_8', 'Pedestrian_Movement_9', 'Car_Passenger_0',\n",
       "       'Car_Passenger_1', 'Car_Passenger_2', 'Bus_or_Coach_Passenger_0',\n",
       "       'Bus_or_Coach_Passenger_1', 'Bus_or_Coach_Passenger_2',\n",
       "       'Bus_or_Coach_Passenger_3', 'Bus_or_Coach_Passenger_4',\n",
       "       'Pedestrian_Road_Maintenance_Worker_0',\n",
       "       'Pedestrian_Road_Maintenance_Worker_1',\n",
       "       'Pedestrian_Road_Maintenance_Worker_2', 'Casualty_Type_0',\n",
       "       'Casualty_Type_1', 'Casualty_Type_2', 'Casualty_Type_3',\n",
       "       'Casualty_Type_4', 'Casualty_Type_5', 'Casualty_Type_8',\n",
       "       'Casualty_Type_9', 'Casualty_Type_10', 'Casualty_Type_11',\n",
       "       'Casualty_Type_16', 'Casualty_Type_17', 'Casualty_Type_18',\n",
       "       'Casualty_Type_19', 'Casualty_Type_20', 'Casualty_Type_21',\n",
       "       'Casualty_Type_22', 'Casualty_Type_90', 'Casualty_Type_97',\n",
       "       'Casualty_Home_Area_Type_1', 'Casualty_Home_Area_Type_2',\n",
       "       'Casualty_Home_Area_Type_3'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = dataset.drop([\"Casualty_Severity\"], axis=1)\n",
    "y = dataset[\"Casualty_Severity\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(69216, 71)\n",
      "(69216,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(44297, 71)\n",
      "(11075, 71)\n",
      "(13844, 71)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_all_train, X_test, y_all_train, y_test = train_test_split(X, y, test_size=0.2, random_state=6357)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_all_train, y_all_train, test_size=0.2, random_state=6357)\n",
    "del X, y\n",
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age_of_Casualty</th>\n",
       "      <th>Casualty_Class_1</th>\n",
       "      <th>Casualty_Class_2</th>\n",
       "      <th>Casualty_Class_3</th>\n",
       "      <th>Sex_of_Casualty_1</th>\n",
       "      <th>Sex_of_Casualty_2</th>\n",
       "      <th>Age_Band_of_Casualty_1</th>\n",
       "      <th>Age_Band_of_Casualty_2</th>\n",
       "      <th>Age_Band_of_Casualty_3</th>\n",
       "      <th>Age_Band_of_Casualty_4</th>\n",
       "      <th>...</th>\n",
       "      <th>Casualty_Type_18</th>\n",
       "      <th>Casualty_Type_19</th>\n",
       "      <th>Casualty_Type_20</th>\n",
       "      <th>Casualty_Type_21</th>\n",
       "      <th>Casualty_Type_22</th>\n",
       "      <th>Casualty_Type_90</th>\n",
       "      <th>Casualty_Type_97</th>\n",
       "      <th>Casualty_Home_Area_Type_1</th>\n",
       "      <th>Casualty_Home_Area_Type_2</th>\n",
       "      <th>Casualty_Home_Area_Type_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>44297.000000</td>\n",
       "      <td>44297.000000</td>\n",
       "      <td>44297.000000</td>\n",
       "      <td>44297.000000</td>\n",
       "      <td>44297.000000</td>\n",
       "      <td>44297.000000</td>\n",
       "      <td>44297.000000</td>\n",
       "      <td>44297.000000</td>\n",
       "      <td>44297.000000</td>\n",
       "      <td>44297.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>44297.000000</td>\n",
       "      <td>44297.000000</td>\n",
       "      <td>44297.000000</td>\n",
       "      <td>44297.000000</td>\n",
       "      <td>44297.000000</td>\n",
       "      <td>44297.000000</td>\n",
       "      <td>44297.000000</td>\n",
       "      <td>44297.000000</td>\n",
       "      <td>44297.000000</td>\n",
       "      <td>44297.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>37.568549</td>\n",
       "      <td>0.614624</td>\n",
       "      <td>0.197327</td>\n",
       "      <td>0.188049</td>\n",
       "      <td>0.667901</td>\n",
       "      <td>0.331873</td>\n",
       "      <td>0.014719</td>\n",
       "      <td>0.022507</td>\n",
       "      <td>0.044021</td>\n",
       "      <td>0.146308</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.019302</td>\n",
       "      <td>0.002890</td>\n",
       "      <td>0.007201</td>\n",
       "      <td>0.000406</td>\n",
       "      <td>0.006321</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>0.621464</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.124297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>20.894259</td>\n",
       "      <td>0.486690</td>\n",
       "      <td>0.397986</td>\n",
       "      <td>0.390756</td>\n",
       "      <td>0.470972</td>\n",
       "      <td>0.470891</td>\n",
       "      <td>0.120426</td>\n",
       "      <td>0.148328</td>\n",
       "      <td>0.205144</td>\n",
       "      <td>0.353419</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006719</td>\n",
       "      <td>0.137584</td>\n",
       "      <td>0.053678</td>\n",
       "      <td>0.084556</td>\n",
       "      <td>0.020154</td>\n",
       "      <td>0.079254</td>\n",
       "      <td>0.009502</td>\n",
       "      <td>0.485028</td>\n",
       "      <td>0.287483</td>\n",
       "      <td>0.329924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>34.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>51.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>99.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows  71 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Age_of_Casualty  Casualty_Class_1  Casualty_Class_2  Casualty_Class_3  \\\n",
       "count     44297.000000      44297.000000      44297.000000      44297.000000   \n",
       "mean         37.568549          0.614624          0.197327          0.188049   \n",
       "std          20.894259          0.486690          0.397986          0.390756   \n",
       "min          -1.000000          0.000000          0.000000          0.000000   \n",
       "25%          21.000000          0.000000          0.000000          0.000000   \n",
       "50%          34.000000          1.000000          0.000000          0.000000   \n",
       "75%          51.000000          1.000000          0.000000          0.000000   \n",
       "max          99.000000          1.000000          1.000000          1.000000   \n",
       "\n",
       "       Sex_of_Casualty_1  Sex_of_Casualty_2  Age_Band_of_Casualty_1  \\\n",
       "count       44297.000000       44297.000000            44297.000000   \n",
       "mean            0.667901           0.331873                0.014719   \n",
       "std             0.470972           0.470891                0.120426   \n",
       "min             0.000000           0.000000                0.000000   \n",
       "25%             0.000000           0.000000                0.000000   \n",
       "50%             1.000000           0.000000                0.000000   \n",
       "75%             1.000000           1.000000                0.000000   \n",
       "max             1.000000           1.000000                1.000000   \n",
       "\n",
       "       Age_Band_of_Casualty_2  Age_Band_of_Casualty_3  Age_Band_of_Casualty_4  \\\n",
       "count            44297.000000            44297.000000            44297.000000   \n",
       "mean                 0.022507                0.044021                0.146308   \n",
       "std                  0.148328                0.205144                0.353419   \n",
       "min                  0.000000                0.000000                0.000000   \n",
       "25%                  0.000000                0.000000                0.000000   \n",
       "50%                  0.000000                0.000000                0.000000   \n",
       "75%                  0.000000                0.000000                0.000000   \n",
       "max                  1.000000                1.000000                1.000000   \n",
       "\n",
       "                 ...              Casualty_Type_18  Casualty_Type_19  \\\n",
       "count            ...                  44297.000000      44297.000000   \n",
       "mean             ...                      0.000045          0.019302   \n",
       "std              ...                      0.006719          0.137584   \n",
       "min              ...                      0.000000          0.000000   \n",
       "25%              ...                      0.000000          0.000000   \n",
       "50%              ...                      0.000000          0.000000   \n",
       "75%              ...                      0.000000          0.000000   \n",
       "max              ...                      1.000000          1.000000   \n",
       "\n",
       "       Casualty_Type_20  Casualty_Type_21  Casualty_Type_22  Casualty_Type_90  \\\n",
       "count      44297.000000      44297.000000      44297.000000      44297.000000   \n",
       "mean           0.002890          0.007201          0.000406          0.006321   \n",
       "std            0.053678          0.084556          0.020154          0.079254   \n",
       "min            0.000000          0.000000          0.000000          0.000000   \n",
       "25%            0.000000          0.000000          0.000000          0.000000   \n",
       "50%            0.000000          0.000000          0.000000          0.000000   \n",
       "75%            0.000000          0.000000          0.000000          0.000000   \n",
       "max            1.000000          1.000000          1.000000          1.000000   \n",
       "\n",
       "       Casualty_Type_97  Casualty_Home_Area_Type_1  Casualty_Home_Area_Type_2  \\\n",
       "count      44297.000000               44297.000000               44297.000000   \n",
       "mean           0.000090                   0.621464                   0.090909   \n",
       "std            0.009502                   0.485028                   0.287483   \n",
       "min            0.000000                   0.000000                   0.000000   \n",
       "25%            0.000000                   0.000000                   0.000000   \n",
       "50%            0.000000                   1.000000                   0.000000   \n",
       "75%            0.000000                   1.000000                   0.000000   \n",
       "max            1.000000                   1.000000                   1.000000   \n",
       "\n",
       "       Casualty_Home_Area_Type_3  \n",
       "count               44297.000000  \n",
       "mean                    0.124297  \n",
       "std                     0.329924  \n",
       "min                     0.000000  \n",
       "25%                     0.000000  \n",
       "50%                     0.000000  \n",
       "75%                     0.000000  \n",
       "max                     1.000000  \n",
       "\n",
       "[8 rows x 71 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning using CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first_layer=100, activation=identity, val_score=0.479910\n",
      "first_layer=100, activation=logistic, val_score=0.499594\n",
      "first_layer=100, activation=tanh, val_score=0.499774\n",
      "first_layer=100, activation=relu, val_score=0.500677\n",
      "first_layer=100, second_layer=100, activation=identity, val_score=0.496795\n",
      "first_layer=100, second_layer=100, activation=logistic, val_score=0.501129\n",
      "first_layer=100, second_layer=100, activation=tanh, val_score=0.487946\n",
      "first_layer=100, second_layer=100, activation=relu, val_score=0.483883\n",
      "first_layer=100, second_layer=200, activation=identity, val_score=0.489120\n",
      "first_layer=100, second_layer=200, activation=logistic, val_score=0.501851\n",
      "first_layer=100, second_layer=200, activation=tanh, val_score=0.499594\n",
      "first_layer=100, second_layer=200, activation=relu, val_score=0.487133\n",
      "first_layer=100, second_layer=300, activation=identity, val_score=0.472957\n",
      "first_layer=100, second_layer=300, activation=logistic, val_score=0.489120\n",
      "first_layer=100, second_layer=300, activation=tanh, val_score=0.501129\n",
      "first_layer=100, second_layer=300, activation=relu, val_score=0.496433\n",
      "first_layer=200, activation=identity, val_score=0.449120\n",
      "first_layer=200, activation=logistic, val_score=0.495892\n",
      "first_layer=200, activation=tanh, val_score=0.500587\n",
      "first_layer=200, activation=relu, val_score=0.486501\n",
      "first_layer=200, second_layer=100, activation=identity, val_score=0.485779\n",
      "first_layer=200, second_layer=100, activation=logistic, val_score=0.500767\n",
      "first_layer=200, second_layer=100, activation=tanh, val_score=0.500135\n",
      "first_layer=200, second_layer=100, activation=relu, val_score=0.486772\n",
      "first_layer=200, second_layer=200, activation=identity, val_score=0.492731\n",
      "first_layer=200, second_layer=200, activation=logistic, val_score=0.501670\n",
      "first_layer=200, second_layer=200, activation=tanh, val_score=0.500497\n",
      "first_layer=200, second_layer=200, activation=relu, val_score=0.496343\n",
      "first_layer=200, second_layer=300, activation=identity, val_score=0.494266\n",
      "first_layer=200, second_layer=300, activation=logistic, val_score=0.499865\n",
      "first_layer=200, second_layer=300, activation=tanh, val_score=0.502483\n",
      "first_layer=200, second_layer=300, activation=relu, val_score=0.501670\n",
      "first_layer=300, activation=identity, val_score=0.484876\n",
      "first_layer=300, activation=logistic, val_score=0.498871\n",
      "first_layer=300, activation=tanh, val_score=0.500135\n",
      "first_layer=300, activation=relu, val_score=0.492641\n",
      "first_layer=300, second_layer=100, activation=identity, val_score=0.497246\n",
      "first_layer=300, second_layer=100, activation=logistic, val_score=0.500677\n",
      "first_layer=300, second_layer=100, activation=tanh, val_score=0.501219\n",
      "first_layer=300, second_layer=100, activation=relu, val_score=0.481264\n",
      "first_layer=300, second_layer=200, activation=identity, val_score=0.497156\n",
      "first_layer=300, second_layer=200, activation=logistic, val_score=0.499413\n",
      "first_layer=300, second_layer=200, activation=tanh, val_score=0.500677\n",
      "first_layer=300, second_layer=200, activation=relu, val_score=0.476117\n",
      "first_layer=300, second_layer=300, activation=identity, val_score=0.497427\n",
      "first_layer=300, second_layer=300, activation=logistic, val_score=0.500316\n",
      "first_layer=300, second_layer=300, activation=tanh, val_score=0.490113\n",
      "first_layer=300, second_layer=300, activation=relu, val_score=0.472777\n",
      "0.5024830699774266\n",
      "(200, 300)\n",
      "tanh\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5018058364634499"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "best_val = 0\n",
    "best_layer = (0)\n",
    "best_activation = \"\"\n",
    "for first_layer in range(100, 301, 100):\n",
    "    for activation in ['identity', 'logistic', 'tanh', 'relu']:\n",
    "        mlp = MLPClassifier(hidden_layer_sizes=(first_layer), activation=activation, max_iter=1000)\n",
    "        mlp.fit(X_train, y_train)\n",
    "        val_score = mlp.score(X_val, y_val)\n",
    "        print(\"first_layer=%d, activation=%s, val_score=%f\" % (first_layer, activation, val_score))\n",
    "        if val_score > best_val:\n",
    "            best_val = val_score\n",
    "            best_layer = (first_layer)\n",
    "            best_activation = activation\n",
    "    for second_layer in range(100, 301, 100):\n",
    "        for activation in ['identity', 'logistic', 'tanh', 'relu']:\n",
    "            mlp = MLPClassifier(hidden_layer_sizes=(first_layer, second_layer), activation=activation, max_iter=1000)\n",
    "            mlp.fit(X_train, y_train)\n",
    "            val_score = mlp.score(X_val, y_val)\n",
    "            print(\"first_layer=%d, second_layer=%d, activation=%s, val_score=%f\" % (first_layer, second_layer, activation, val_score))\n",
    "            if val_score > best_val:\n",
    "                best_val = val_score\n",
    "                best_layer = (first_layer, second_layer)\n",
    "                best_activation = activation\n",
    "\n",
    "print(best_val)\n",
    "print(best_layer)\n",
    "print(best_activation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training score:  0.5058874521418768\n",
      "test score:  0.5028171048829818\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "best_layer = (200, 300)\n",
    "best_activation = \"tanh\"\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(best_layer), activation=best_activation, max_iter=1000)\n",
    "mlp.fit(X_all_train, y_all_train)\n",
    "print(\"training score: \", mlp.score(X_all_train, y_all_train))\n",
    "print(\"test score: \", mlp.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning using CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C=0.017016, val_score=0.503025\n",
      "C=0.009832, val_score=0.503567\n",
      "C=0.030914, val_score=0.502573\n",
      "C=0.022152, val_score=0.502935\n",
      "C=123.472334, val_score=0.341580\n",
      "C=30.268342, val_score=0.341038\n",
      "C=30.769953, val_score=0.361625\n",
      "C=35.780220, val_score=0.331648\n",
      "C=0.679693, val_score=0.496975\n",
      "C=22.344992, val_score=0.401986\n",
      "C=0.552051, val_score=0.386637\n",
      "C=2.928661, val_score=0.428533\n",
      "C=6.792751, val_score=0.373815\n",
      "C=1.680424, val_score=0.358736\n",
      "C=107.719136, val_score=0.326953\n",
      "C=0.531973, val_score=0.393318\n",
      "C=0.893940, val_score=0.458420\n",
      "C=0.010707, val_score=0.503386\n",
      "C=0.016990, val_score=0.502844\n",
      "C=1.646754, val_score=0.482619\n",
      "C=3.243688, val_score=0.467720\n",
      "C=0.010618, val_score=0.503567\n",
      "C=4.975460, val_score=0.353499\n",
      "C=0.062937, val_score=0.502664\n",
      "C=5.851849, val_score=0.377517\n",
      "C=30.596189, val_score=0.417788\n",
      "C=0.022831, val_score=0.502754\n",
      "C=0.111749, val_score=0.503205\n",
      "C=27.370081, val_score=0.458962\n",
      "C=39.521140, val_score=0.469977\n",
      "C=0.856100, val_score=0.430880\n",
      "C=78.430274, val_score=0.369391\n",
      "C=0.105863, val_score=0.476388\n",
      "C=2.701365, val_score=0.492641\n",
      "C=110.409716, val_score=0.347720\n",
      "C=0.029726, val_score=0.503928\n",
      "C=7.768340, val_score=0.422844\n",
      "C=32.065507, val_score=0.429797\n",
      "C=0.303804, val_score=0.474582\n",
      "C=8.295939, val_score=0.393499\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f82f0c4f550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best validation score:  0.5039277652370203\n",
      "Best C:  0.029725770708089135\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from random import random\n",
    "\n",
    "best_val = 0\n",
    "best_C = 0\n",
    "all_C_val_score = []\n",
    "all_C = []\n",
    "for i in range(40):\n",
    "    log_C = random() * 10 - 5\n",
    "    C = np.exp(log_C)\n",
    "    clf = svm.LinearSVC(C=C, multi_class=\"ovr\")\n",
    "    clf.fit(X_train,y_train)\n",
    "    val_score = clf.score(X_val,y_val)\n",
    "    print(\"C=%f, val_score=%f\" % (C, val_score))\n",
    "    if val_score > best_val:\n",
    "        best_val = val_score\n",
    "        best_C = C\n",
    "    all_C.append(C)\n",
    "    all_C_val_score.append(val_score)\n",
    "\n",
    "plt.scatter(all_C, all_C_val_score)\n",
    "plt.show()\n",
    "print(\"Best validation score: \", best_val)\n",
    "print(\"Best C: \", best_C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score:  0.5039618935819582\n",
      "Test score:  0.4984830973707021\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "best_C = 0.029725770708089135\n",
    "clf = svm.LinearSVC(C=best_C, multi_class=\"ovr\")\n",
    "clf.fit(X_all_train, y_all_train)\n",
    "print(\"Train score: \", clf.score(X_train, y_train))\n",
    "print(\"Test score: \", clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# kNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning using CV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(44297, 70)\n",
      "(11075, 70)\n",
      "(13844, 70)\n"
     ]
    }
   ],
   "source": [
    "X = dataset.drop([\"Casualty_Severity\", \"Age_of_Casualty\"], axis=1)\n",
    "y = dataset[\"Casualty_Severity\"]\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_all_train, X_test, y_all_train, y_test = train_test_split(X, y, test_size=0.2, random_state=6357)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_all_train, y_all_train, test_size=0.2, random_state=6357)\n",
    "del X, y\n",
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=-1, n_neighbors=9, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=9, n_jobs=-1)\n",
    "knn.fit(X_all_train, y_all_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46330540306269863"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n=1, weights=uniform, metric=euclidean, val_score=0.411196\n",
      "n=1, weights=uniform, metric=manhattan, val_score=0.411196\n",
      "n=1, weights=uniform, metric=chebyshev, val_score=0.399549\n",
      "n=1, weights=uniform, metric=minkowski, val_score=0.411196\n",
      "n=1, weights=distance, metric=euclidean, val_score=0.411196\n",
      "n=1, weights=distance, metric=manhattan, val_score=0.411196\n",
      "n=1, weights=distance, metric=chebyshev, val_score=0.399549\n",
      "n=1, weights=distance, metric=minkowski, val_score=0.411196\n",
      "n=2, weights=uniform, metric=euclidean, val_score=0.407404\n",
      "n=2, weights=uniform, metric=manhattan, val_score=0.407585\n",
      "n=2, weights=uniform, metric=chebyshev, val_score=0.400000\n",
      "n=2, weights=uniform, metric=minkowski, val_score=0.407404\n",
      "n=2, weights=distance, metric=euclidean, val_score=0.405779\n",
      "n=2, weights=distance, metric=manhattan, val_score=0.406321\n",
      "n=2, weights=distance, metric=chebyshev, val_score=0.401535\n",
      "n=2, weights=distance, metric=minkowski, val_score=0.405779\n",
      "n=3, weights=uniform, metric=euclidean, val_score=0.429707\n",
      "n=3, weights=uniform, metric=manhattan, val_score=0.429616\n",
      "n=3, weights=uniform, metric=chebyshev, val_score=0.415801\n",
      "n=3, weights=uniform, metric=minkowski, val_score=0.429707\n",
      "n=3, weights=distance, metric=euclidean, val_score=0.427991\n",
      "n=3, weights=distance, metric=manhattan, val_score=0.427720\n",
      "n=3, weights=distance, metric=chebyshev, val_score=0.417517\n",
      "n=3, weights=distance, metric=minkowski, val_score=0.427991\n",
      "n=4, weights=uniform, metric=euclidean, val_score=0.434853\n",
      "n=4, weights=uniform, metric=manhattan, val_score=0.434492\n",
      "n=4, weights=uniform, metric=chebyshev, val_score=0.415440\n",
      "n=4, weights=uniform, metric=minkowski, val_score=0.434853\n",
      "n=4, weights=distance, metric=euclidean, val_score=0.433589\n",
      "n=4, weights=distance, metric=manhattan, val_score=0.433138\n",
      "n=4, weights=distance, metric=chebyshev, val_score=0.421670\n",
      "n=4, weights=distance, metric=minkowski, val_score=0.433589\n",
      "n=5, weights=uniform, metric=euclidean, val_score=0.437743\n",
      "n=5, weights=uniform, metric=manhattan, val_score=0.437381\n",
      "n=5, weights=uniform, metric=chebyshev, val_score=0.424018\n",
      "n=5, weights=uniform, metric=minkowski, val_score=0.437743\n",
      "n=5, weights=distance, metric=euclidean, val_score=0.434402\n",
      "n=5, weights=distance, metric=manhattan, val_score=0.434944\n",
      "n=5, weights=distance, metric=chebyshev, val_score=0.424470\n",
      "n=5, weights=distance, metric=minkowski, val_score=0.434402\n",
      "n=6, weights=uniform, metric=euclidean, val_score=0.447765\n",
      "n=6, weights=uniform, metric=manhattan, val_score=0.447946\n",
      "n=6, weights=uniform, metric=chebyshev, val_score=0.432325\n",
      "n=6, weights=uniform, metric=minkowski, val_score=0.447765\n",
      "n=6, weights=distance, metric=euclidean, val_score=0.443341\n",
      "n=6, weights=distance, metric=manhattan, val_score=0.444244\n",
      "n=6, weights=distance, metric=chebyshev, val_score=0.434312\n",
      "n=6, weights=distance, metric=minkowski, val_score=0.443341\n",
      "n=7, weights=uniform, metric=euclidean, val_score=0.446140\n",
      "n=7, weights=uniform, metric=manhattan, val_score=0.445688\n",
      "n=7, weights=uniform, metric=chebyshev, val_score=0.429977\n",
      "n=7, weights=uniform, metric=minkowski, val_score=0.446140\n",
      "n=7, weights=distance, metric=euclidean, val_score=0.440271\n",
      "n=7, weights=distance, metric=manhattan, val_score=0.440361\n",
      "n=7, weights=distance, metric=chebyshev, val_score=0.430880\n",
      "n=7, weights=distance, metric=minkowski, val_score=0.440271\n",
      "n=8, weights=uniform, metric=euclidean, val_score=0.453634\n",
      "n=8, weights=uniform, metric=manhattan, val_score=0.453183\n",
      "n=8, weights=uniform, metric=chebyshev, val_score=0.432144\n",
      "n=8, weights=uniform, metric=minkowski, val_score=0.453634\n",
      "n=8, weights=distance, metric=euclidean, val_score=0.446050\n",
      "n=8, weights=distance, metric=manhattan, val_score=0.446591\n",
      "n=8, weights=distance, metric=chebyshev, val_score=0.435214\n",
      "n=8, weights=distance, metric=minkowski, val_score=0.446050\n",
      "n=9, weights=uniform, metric=euclidean, val_score=0.449842\n",
      "n=9, weights=uniform, metric=manhattan, val_score=0.450835\n",
      "n=9, weights=uniform, metric=chebyshev, val_score=0.431874\n",
      "n=9, weights=uniform, metric=minkowski, val_score=0.449842\n",
      "n=9, weights=distance, metric=euclidean, val_score=0.443070\n",
      "n=9, weights=distance, metric=manhattan, val_score=0.442799\n",
      "n=9, weights=distance, metric=chebyshev, val_score=0.432777\n",
      "n=9, weights=distance, metric=minkowski, val_score=0.443070\n",
      "n=10, weights=uniform, metric=euclidean, val_score=0.453273\n",
      "n=10, weights=uniform, metric=manhattan, val_score=0.453363\n",
      "n=10, weights=uniform, metric=chebyshev, val_score=0.425282\n",
      "n=10, weights=uniform, metric=minkowski, val_score=0.453273\n",
      "n=10, weights=distance, metric=euclidean, val_score=0.443251\n",
      "n=10, weights=distance, metric=manhattan, val_score=0.443160\n",
      "n=10, weights=distance, metric=chebyshev, val_score=0.430519\n",
      "n=10, weights=distance, metric=minkowski, val_score=0.443251\n",
      "n=11, weights=uniform, metric=euclidean, val_score=0.459503\n",
      "n=11, weights=uniform, metric=manhattan, val_score=0.458691\n",
      "n=11, weights=uniform, metric=chebyshev, val_score=0.434492\n",
      "n=11, weights=uniform, metric=minkowski, val_score=0.459503\n",
      "n=11, weights=distance, metric=euclidean, val_score=0.447585\n",
      "n=11, weights=distance, metric=manhattan, val_score=0.447946\n",
      "n=11, weights=distance, metric=chebyshev, val_score=0.435305\n",
      "n=11, weights=distance, metric=minkowski, val_score=0.447585\n",
      "n=12, weights=uniform, metric=euclidean, val_score=0.460677\n",
      "n=12, weights=uniform, metric=manhattan, val_score=0.460406\n",
      "n=12, weights=uniform, metric=chebyshev, val_score=0.436117\n",
      "n=12, weights=uniform, metric=minkowski, val_score=0.460677\n",
      "n=12, weights=distance, metric=euclidean, val_score=0.447223\n",
      "n=12, weights=distance, metric=manhattan, val_score=0.447133\n",
      "n=12, weights=distance, metric=chebyshev, val_score=0.436840\n",
      "n=12, weights=distance, metric=minkowski, val_score=0.447223\n",
      "n=13, weights=uniform, metric=euclidean, val_score=0.466637\n",
      "n=13, weights=uniform, metric=manhattan, val_score=0.466095\n",
      "n=13, weights=uniform, metric=chebyshev, val_score=0.440181\n",
      "n=13, weights=uniform, metric=minkowski, val_score=0.466637\n",
      "n=13, weights=distance, metric=euclidean, val_score=0.453183\n",
      "n=13, weights=distance, metric=manhattan, val_score=0.450564\n",
      "n=13, weights=distance, metric=chebyshev, val_score=0.440632\n",
      "n=13, weights=distance, metric=minkowski, val_score=0.453183\n",
      "n=14, weights=uniform, metric=euclidean, val_score=0.470519\n",
      "n=14, weights=uniform, metric=manhattan, val_score=0.469887\n",
      "n=14, weights=uniform, metric=chebyshev, val_score=0.439007\n",
      "n=14, weights=uniform, metric=minkowski, val_score=0.470519\n",
      "n=14, weights=distance, metric=euclidean, val_score=0.455350\n",
      "n=14, weights=distance, metric=manhattan, val_score=0.454537\n",
      "n=14, weights=distance, metric=chebyshev, val_score=0.441716\n",
      "n=14, weights=distance, metric=minkowski, val_score=0.455350\n",
      "n=15, weights=uniform, metric=euclidean, val_score=0.469526\n",
      "n=15, weights=uniform, metric=manhattan, val_score=0.469436\n",
      "n=15, weights=uniform, metric=chebyshev, val_score=0.442619\n",
      "n=15, weights=uniform, metric=minkowski, val_score=0.469526\n",
      "n=15, weights=distance, metric=euclidean, val_score=0.456614\n",
      "n=15, weights=distance, metric=manhattan, val_score=0.454357\n",
      "n=15, weights=distance, metric=chebyshev, val_score=0.442167\n",
      "n=15, weights=distance, metric=minkowski, val_score=0.456614\n",
      "n=16, weights=uniform, metric=euclidean, val_score=0.472325\n",
      "n=16, weights=uniform, metric=manhattan, val_score=0.470971\n",
      "n=16, weights=uniform, metric=chebyshev, val_score=0.440000\n",
      "n=16, weights=uniform, metric=minkowski, val_score=0.472325\n",
      "n=16, weights=distance, metric=euclidean, val_score=0.457336\n",
      "n=16, weights=distance, metric=manhattan, val_score=0.456614\n"
     ]
    }
   ],
   "source": [
    "best_val = 0\n",
    "best_n = 0\n",
    "best_weights = \"\"\n",
    "best_metric = \"\"\n",
    "for n in range(1,20):\n",
    "    for weights in [\"uniform\", \"distance\"]:\n",
    "        for metric in [\"euclidean\", \"manhattan\", \"chebyshev\", \"minkowski\"]:\n",
    "            knn = KNeighborsClassifier(n_neighbors=n, weights=weights, metric=metric, n_jobs=-1)\n",
    "            knn.fit(X_train,y_train)\n",
    "            val_score = knn.score(X_val, y_val)\n",
    "            print(\"n=%d, weights=%s, metric=%s, val_score=%f\" % (n, weights, metric, val_score))\n",
    "            if val_score > best_val:\n",
    "                best_val = val_score\n",
    "                best_n = n\n",
    "                best_weights = weights\n",
    "                best_metric = metric\n",
    "print(\"Best validation score: \", best_val)\n",
    "print(\"Best n: \", best_n)\n",
    "print(\"Best weights method: \", best_weights)\n",
    "print(\"Best distance metric: \", best_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score:  0.46850621207743426\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=best_n, weights=best_weights, metric=best_metric, n_jobs=-1)\n",
    "knn.fit(X_train,y_train)\n",
    "print(\"Test score: \", knn.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "error_rate = []\n",
    "for n in range(1,80):\n",
    "    knn = KNeighborsClassifier(n_neighbors=n, weights=\"uniform\", metric=\"manhattan\", n_jobs=-1)\n",
    "    knn.fit(X_train,y_train)\n",
    "    pred_i = knn.predict(X_val)\n",
    "    error_rate.append(np.mean(pred_i != y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmsAAAGDCAYAAAB0s1eWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAExMrAEATOwHEFcV2fd83KIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f82ed9bb2e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(range(1,len(error_rate)+1),error_rate,color='blue', linestyle='dashed', marker='o',\n",
    "         markerfacecolor='red', markersize=5)\n",
    "plt.title('Error Rate vs. K Value')\n",
    "plt.xlabel('K')\n",
    "plt.ylabel('Error Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
